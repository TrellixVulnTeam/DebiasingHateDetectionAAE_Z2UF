{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "sys.path.insert(0, os.path.abspath('../')) # needed to import src\n",
    "from src.data_cleaning import WaseemTwitterPreparer, DavidsonTwitterPreparer, FountaTwitterPreparer, \\\n",
    "    GolbeckTwitterPreparer\n",
    "OUTPUT_DIRECTORY = '../data'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/21/2020 05:56:28 PM Uncleaned Twitter Davidson Shape: (24783, 6)\n"
     ]
    }
   ],
   "source": [
    "davidson_preparer = DavidsonTwitterPreparer(verbose=True, path_to_raw='../data/twitter_datasets/davidson/davidson_labelled.csv')\n",
    "davidson_preparer.load_data()\n",
    "davidson_preparer.prepare_data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "waseem_preparer = WaseemTwitterPreparer(verbose=True, path_to_raw=['../data/twitter_datasets/waseem/NAACL_SRW_2016.csv', '../data/twitter_datasets/waseem/NLP+CSS_2016.csv'])\n",
    "waseem_preparer.load_data()\n",
    "waseem_preparer.prepare_data()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matan\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3254: DtypeWarning: Columns (47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000,1001,1002,1003,1004,1005,1006,1007,1008,1009,1010,1011,1012,1013,1014,1015,1016,1017,1018,1019,1020,1021,1022,1023,1024,1025,1026,1027,1028,1029,1030,1031,1032,1033,1034,1035,1036,1037,1038,1039,1040,1041,1042,1043,1044,1045,1046,1047,1048,1049,1050,1051,1052,1053,1054,1055,1056,1057,1058,1059,1060,1061,1062,1063,1064,1065,1066,1067,1068,1069,1070,1071,1072,1073,1074,1075,1076,1077,1078,1079,1080,1081,1082,1083,1084,1085,1086,1087,1088,1089,1090,1091) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n",
      "C:\\Users\\matan\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:845: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "C:\\Users\\matan\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "11/21/2020 05:56:30 PM Uncleaned NAACL_SRW_2016 Waseem Hovy Shape: (16907, 3)\n",
      "11/21/2020 05:56:30 PM Uncleaned NLP+CSS 2016 Waseem Shape: (6909, 3)\n",
      "11/21/2020 05:56:30 PM Merged uncleaned Waseem Shape: (23816, 3)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/21/2020 05:56:30 PM Uncleaned Twitter Golbeck Shape: (20360, 2)\n"
     ]
    }
   ],
   "source": [
    "golbeck_preparer = GolbeckTwitterPreparer(verbose=True, path_to_raw='../data/twitter_datasets/golbeck/onlineHarassmentDataset.csv')\n",
    "golbeck_preparer.load_data()\n",
    "golbeck_preparer.prepare_data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/21/2020 05:56:30 PM Uncleaned Twitter Founta Shape: (91951, 3)\n"
     ]
    }
   ],
   "source": [
    "founta_preparer = FountaTwitterPreparer(verbose=True, path_to_raw='../data/twitter_datasets/founta/hatespeechtwitter.csv')\n",
    "founta_preparer.load_data()\n",
    "founta_preparer.prepare_data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "founta = founta_preparer.get_cleaned_data()\n",
    "davidson = davidson_preparer.get_cleaned_data()\n",
    "waseem = waseem_preparer.get_cleaned_data()\n",
    "golbeck = golbeck_preparer.get_cleaned_data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "founta.loc[:,'original_ds'] = 'founta'\n",
    "davidson.loc[:,'original_ds'] = 'davidson'\n",
    "waseem.loc[:,'original_ds'] = 'waseem'\n",
    "golbeck.loc[:,'original_ds'] = 'golbeck'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "founta -  shape: (91951, 11)  - label distribution: 0.045 - columns: Index(['text', 'maj_label', 'majority_votes', 'is_hate', 'is_abusive',\n",
      "       'is_harassment', 'cleaned_tweet', 'dialect_prs', 'is_aae_08',\n",
      "       'is_aae_06', 'original_ds'],\n",
      "      dtype='object')\n",
      "davidson -  shape: (24783, 13)  - label distribution: 0.058 - columns: Index(['count', 'hate_speech', 'offensive_language', 'neither', 'class',\n",
      "       'tweet', 'cleaned_tweet', 'is_hate', 'is_offensive', 'dialect_prs',\n",
      "       'is_aae_08', 'is_aae_06', 'original_ds'],\n",
      "      dtype='object')\n",
      "waseem -  shape: (16631, 12)  - label distribution: 0.204 - columns: Index(['tweet_id', 'label', 'is_racism', 'is_sexism', 'is_hate', 'id', 'text',\n",
      "       'cleaned_tweet', 'dialect_prs', 'is_aae_08', 'is_aae_06',\n",
      "       'original_ds'],\n",
      "      dtype='object')\n",
      "golbeck -  shape: (19718, 8)  - label distribution: 0.241 - columns: Index(['Code', 'Tweet', 'is_hate', 'cleaned_tweet', 'dialect_prs', 'is_aae_08',\n",
      "       'is_aae_06', 'original_ds'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print('founta -  shape:', founta.shape, ' - label distribution:', round((founta[founta['is_hate']==1].shape[0] / founta.shape[0]), 3), '- columns:',founta.columns)\n",
    "print('davidson -  shape:', davidson.shape, ' - label distribution:', round((davidson[davidson['is_hate']==1].shape[0] / davidson.shape[0]), 3), '- columns:', davidson.columns)\n",
    "print('waseem -  shape:', waseem.shape, ' - label distribution:', round((waseem[waseem['is_hate']==1].shape[0] / waseem.shape[0]), 3), '- columns:', waseem.columns)\n",
    "print('golbeck -  shape:', golbeck.shape, ' - label distribution:', round((golbeck[golbeck['is_hate']==1].shape[0] / golbeck.shape[0]), 3), '- columns:', golbeck.columns)\n",
    "# Waiting for Founta to respond to my email as 30k tweets are missing from dataset, many more is_hate"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "founta['is_harassment'] = np.where(((founta['maj_label']=='abusive') | (founta['maj_label']=='hateful')), 1, 0) #in retrieved tweets, maj label was either abusive or hateful, or spam and normal\n",
    "davidson['is_harassment'] = np.where(((davidson['is_offensive']==1) | (davidson['is_hate']==1)), 1, 0)\n",
    "golbeck['is_harassment'] = golbeck['is_hate']\n",
    "# davidson"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matan\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4133: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "data": {
      "text/plain": "                 tweet_id   label  is_racism  is_sexism  is_harassment  \\\n0      572342978255048705  racism          1          0              1   \n1      572341498827522049  racism          1          0              1   \n2      572340476503724032  racism          1          0              1   \n3      572334712804384768  racism          1          0              1   \n4      572332655397629952  racism          1          0              1   \n...                   ...     ...        ...        ...            ...   \n16576  603673068691677185  sexism          0          1              1   \n16602  602697454983749633    both          1          1              1   \n16605  575166549713158144    both          1          1              1   \n16611  575447350258216960  sexism          0          1              1   \n16612  571355947047776256  sexism          0          1              1   \n\n                 id                                               text  \\\n0      5.723430e+17  So Drasko just said he was impressed the girls...   \n1      5.723415e+17  Drasko they didn't cook half a bird you idiot ...   \n2      5.723405e+17  Hopefully someone cooks Drasko in the next ep ...   \n3      5.723347e+17  of course you were born in serbia...you're as ...   \n4      5.723327e+17  These girls are the equivalent of the irritati...   \n...             ...                                                ...   \n16576  6.036731e+17  Failure of men to police their own *is* the co...   \n16602  6.026975e+17  Tokyo Hot n1049 Endless Sex Drive - http://t.c...   \n16605  5.751665e+17  baby you can drive my car http://t.co/gpsW3MvA...   \n16611  5.754474e+17  http://t.co/Ye7qrymd8Y #GamerGate Kristi Think...   \n16612  5.713559e+17  @misterbrilliant what is this gamergate thing?...   \n\n                                           cleaned_tweet  \\\n0      So Drasko just said he was impressed the girls...   \n1      Drasko they didn't cook half a bird you idiot ...   \n2      Hopefully someone cooks Drasko in the next ep ...   \n3      of course you were born in serbia...you're as ...   \n4      These girls are the equivalent of the irritati...   \n...                                                  ...   \n16576  Failure of men to police their own *is* the co...   \n16602  Tokyo Hot n1049 Endless Sex Drive -  #dailyxLo...   \n16605  baby you can drive my car  #asian #asianbabes ...   \n16611   #GamerGate Kristi Thinks: \"Anita Sarkeesian i...   \n16612   what is this gamergate thing? I assume it's s...   \n\n                                         dialect_prs  is_aae_08  is_aae_06  \\\n0      [0.36626887 0.19337914 0.00452145 0.43583054]          0          0   \n1      [0.24003915 0.3097326  0.0082669  0.44196135]          0          0   \n2      [0.0824137  0.40979904 0.03430444 0.47348281]          0          0   \n3      [0.11006174 0.21065121 0.06940961 0.60987744]          0          0   \n4      [0.17378829 0.23829187 0.04043375 0.54748609]          0          0   \n...                                              ...        ...        ...   \n16576  [0.11484565 0.13546993 0.12904452 0.6206399 ]          0          0   \n16602  [0.13804527 0.20214447 0.39042414 0.26938612]          0          0   \n16605  [0.13968198 0.30230298 0.19563981 0.36237523]          0          0   \n16611  [0.12811259 0.22216871 0.07926012 0.57045858]          0          0   \n16612  [0.09021369 0.20377279 0.04671457 0.65929895]          0          0   \n\n      original_ds  \n0          waseem  \n1          waseem  \n2          waseem  \n3          waseem  \n4          waseem  \n...           ...  \n16576      waseem  \n16602      waseem  \n16605      waseem  \n16611      waseem  \n16612      waseem  \n\n[3392 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_id</th>\n      <th>label</th>\n      <th>is_racism</th>\n      <th>is_sexism</th>\n      <th>is_harassment</th>\n      <th>id</th>\n      <th>text</th>\n      <th>cleaned_tweet</th>\n      <th>dialect_prs</th>\n      <th>is_aae_08</th>\n      <th>is_aae_06</th>\n      <th>original_ds</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>572342978255048705</td>\n      <td>racism</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>5.723430e+17</td>\n      <td>So Drasko just said he was impressed the girls...</td>\n      <td>So Drasko just said he was impressed the girls...</td>\n      <td>[0.36626887 0.19337914 0.00452145 0.43583054]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>waseem</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>572341498827522049</td>\n      <td>racism</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>5.723415e+17</td>\n      <td>Drasko they didn't cook half a bird you idiot ...</td>\n      <td>Drasko they didn't cook half a bird you idiot ...</td>\n      <td>[0.24003915 0.3097326  0.0082669  0.44196135]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>waseem</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>572340476503724032</td>\n      <td>racism</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>5.723405e+17</td>\n      <td>Hopefully someone cooks Drasko in the next ep ...</td>\n      <td>Hopefully someone cooks Drasko in the next ep ...</td>\n      <td>[0.0824137  0.40979904 0.03430444 0.47348281]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>waseem</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>572334712804384768</td>\n      <td>racism</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>5.723347e+17</td>\n      <td>of course you were born in serbia...you're as ...</td>\n      <td>of course you were born in serbia...you're as ...</td>\n      <td>[0.11006174 0.21065121 0.06940961 0.60987744]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>waseem</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>572332655397629952</td>\n      <td>racism</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>5.723327e+17</td>\n      <td>These girls are the equivalent of the irritati...</td>\n      <td>These girls are the equivalent of the irritati...</td>\n      <td>[0.17378829 0.23829187 0.04043375 0.54748609]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>waseem</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>16576</th>\n      <td>603673068691677185</td>\n      <td>sexism</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>6.036731e+17</td>\n      <td>Failure of men to police their own *is* the co...</td>\n      <td>Failure of men to police their own *is* the co...</td>\n      <td>[0.11484565 0.13546993 0.12904452 0.6206399 ]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>waseem</td>\n    </tr>\n    <tr>\n      <th>16602</th>\n      <td>602697454983749633</td>\n      <td>both</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>6.026975e+17</td>\n      <td>Tokyo Hot n1049 Endless Sex Drive - http://t.c...</td>\n      <td>Tokyo Hot n1049 Endless Sex Drive -  #dailyxLo...</td>\n      <td>[0.13804527 0.20214447 0.39042414 0.26938612]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>waseem</td>\n    </tr>\n    <tr>\n      <th>16605</th>\n      <td>575166549713158144</td>\n      <td>both</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5.751665e+17</td>\n      <td>baby you can drive my car http://t.co/gpsW3MvA...</td>\n      <td>baby you can drive my car  #asian #asianbabes ...</td>\n      <td>[0.13968198 0.30230298 0.19563981 0.36237523]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>waseem</td>\n    </tr>\n    <tr>\n      <th>16611</th>\n      <td>575447350258216960</td>\n      <td>sexism</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5.754474e+17</td>\n      <td>http://t.co/Ye7qrymd8Y #GamerGate Kristi Think...</td>\n      <td>#GamerGate Kristi Thinks: \"Anita Sarkeesian i...</td>\n      <td>[0.12811259 0.22216871 0.07926012 0.57045858]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>waseem</td>\n    </tr>\n    <tr>\n      <th>16612</th>\n      <td>571355947047776256</td>\n      <td>sexism</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5.713559e+17</td>\n      <td>@misterbrilliant what is this gamergate thing?...</td>\n      <td>what is this gamergate thing? I assume it's s...</td>\n      <td>[0.09021369 0.20377279 0.04671457 0.65929895]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>waseem</td>\n    </tr>\n  </tbody>\n</table>\n<p>3392 rows × 12 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# waseem assume that all sexist + racist tweets are harassment, can't assume the inverse (not harassment when not\n",
    "waseem_harassment = waseem[waseem['is_hate']==1]\n",
    "waseem_harassment.rename(columns={\"is_hate\":\"is_harassment\"}, inplace=True)\n",
    "waseem_harassment"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "['cleaned_tweet',\n 'text',\n 'dialect_prs',\n 'is_aae_08',\n 'is_harassment',\n 'original_ds',\n 'is_aae_06']"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "davidson.rename(columns={\"tweet\":\"text\"},inplace=True)\n",
    "golbeck.rename(columns={\"Tweet\":\"text\"},inplace=True)\n",
    "overlap_cols = list(set(founta.columns).intersection(set(davidson.columns), set(waseem_harassment.columns),set(golbeck.columns)))\n",
    "overlap_cols"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "founta -  shape: (91951, 11)  - label distribution: 0.27 - n is_aae 0.6 | 0.8: 1265 85 - columns: Index(['text', 'maj_label', 'majority_votes', 'is_hate', 'is_abusive',\n",
      "       'is_harassment', 'cleaned_tweet', 'dialect_prs', 'is_aae_08',\n",
      "       'is_aae_06', 'original_ds'],\n",
      "      dtype='object')\n",
      "davidson -  shape: (24783, 14)  - label distribution: 0.832 - n is_aae 0.6 | 0.8: 4878 636 - columns: Index(['count', 'hate_speech', 'offensive_language', 'neither', 'class',\n",
      "       'text', 'cleaned_tweet', 'is_hate', 'is_offensive', 'dialect_prs',\n",
      "       'is_aae_08', 'is_aae_06', 'original_ds', 'is_harassment'],\n",
      "      dtype='object')\n",
      "waseem harassment -  shape: (16631, 12)  - label distribution: 1.0 - n is_aae 0.6 | 0.8: 12 0 - columns: Index(['tweet_id', 'label', 'is_racism', 'is_sexism', 'is_harassment', 'id',\n",
      "       'text', 'cleaned_tweet', 'dialect_prs', 'is_aae_08', 'is_aae_06',\n",
      "       'original_ds'],\n",
      "      dtype='object')\n",
      "golbeck -  shape: (19718, 9)  - label distribution: 0.241 - n is_aae 0.6 | 0.8: 92 20 - columns: Index(['Code', 'text', 'is_hate', 'cleaned_tweet', 'dialect_prs', 'is_aae_08',\n",
      "       'is_aae_06', 'original_ds', 'is_harassment'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "print('founta -  shape:', founta.shape, ' - label distribution:', round((founta[founta['is_harassment']==1].shape[0] / founta.shape[0]), 3),'- n is_aae 0.6 | 0.8:',founta[founta['is_aae_06']==1].shape[0],founta[founta['is_aae_08']==1].shape[0], '- columns:',founta.columns)\n",
    "print('davidson -  shape:', davidson.shape, ' - label distribution:', round((davidson[davidson['is_harassment']==1].shape[0] / davidson.shape[0]), 3), '- n is_aae 0.6 | 0.8:', davidson[davidson['is_aae_06']==1].shape[0],davidson[davidson['is_aae_08']==1].shape[0],'- columns:', davidson.columns)\n",
    "print('waseem harassment -  shape:', waseem.shape, ' - label distribution:', round((waseem_harassment[waseem_harassment['is_harassment']==1].shape[0] / waseem_harassment.shape[0]), 3), '- n is_aae 0.6 | 0.8:', waseem_harassment[waseem_harassment['is_aae_06']==1].shape[0],waseem_harassment[waseem_harassment['is_aae_08']==1].shape[0],'- columns:', waseem_harassment.columns)\n",
    "print('golbeck -  shape:', golbeck.shape, ' - label distribution:', round((golbeck[golbeck['is_harassment']==1].shape[0] / golbeck.shape[0]), 3),'- n is_aae 0.6 | 0.8:',golbeck[golbeck['is_aae_06']==1].shape[0],golbeck[founta['is_aae_08']==1].shape[0], '- columns:', golbeck.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "merged_df = pd.concat([founta, davidson, waseem_harassment, golbeck])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "merged_df = merged_df[overlap_cols]\n",
    "merged_df.drop_duplicates(inplace=True, subset=['cleaned_tweet']) #7338 duplicate tweets\n",
    "merged_df.to_csv('../data/twitter_datasets/cleaned/all_harassment_datasets_merged.csv',index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_df -  shape: (135023, 7)  - label distribution: 0.391 - n is_aae 0.6 | 0.8: 6205 733 - columns: Index(['cleaned_tweet', 'text', 'dialect_prs', 'is_aae_08', 'is_harassment',\n",
      "       'original_ds', 'is_aae_06'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                           cleaned_tweet  \\\n0      Beats by Dr. Dre urBeats Wired In-Ear Headphon...   \n1      RT : Man it would fucking rule if we had a par...   \n2      It is time to draw close to Him &#128591;&#127...   \n3      if you notice me start to act different or dis...   \n4      Forget unfollowers, I believe in growing. 7 ne...   \n...                                                  ...   \n19713  Wise words by Ben Shapiro https: / /t.co /ldBj...   \n19714  Women are much more likely to be liberals than...   \n19715  Would you like me to release to you this King ...   \n19716  You Fucking Nigger You Did It To Yourself You ...   \n19717  Your descendants, the Jews, will be doomed to ...   \n\n                                                    text  \\\n0      Beats by Dr. Dre urBeats Wired In-Ear Headphon...   \n1      RT @Papapishu: Man it would fucking rule if we...   \n2      It is time to draw close to Him &#128591;&#127...   \n3      if you notice me start to act different or dis...   \n4      Forget unfollowers, I believe in growing. 7 ne...   \n...                                                  ...   \n19713  Wise words by Ben Shapiro https: / /t.co /ldBj...   \n19714  Women are much more likely to be liberals than...   \n19715  Would you like me to release to you this King ...   \n19716  You Fucking Nigger You Did It To Yourself You ...   \n19717  Your descendants, the Jews, will be doomed to ...   \n\n                                         dialect_prs  is_aae_08  \\\n0      [0.37906185 0.22220451 0.19361946 0.20511418]          0   \n1      [0.2085863  0.21244729 0.09804209 0.48092432]          0   \n2      [0.13617963 0.40733362 0.00187648 0.45461027]          0   \n3      [0.42431609 0.35141981 0.00202164 0.22224246]          0   \n4      [0.11957159 0.17347329 0.10673621 0.60021892]          0   \n...                                              ...        ...   \n19713  [0.14449078 0.16982948 0.24125604 0.4444237 ]          0   \n19714  [0.05411577 0.10954312 0.01288798 0.82345312]          0   \n19715  [0.17427205 0.34565292 0.09695176 0.38312327]          0   \n19716  [0.09649005 0.69237505 0.00770617 0.20342874]          0   \n19717  [0.1074874  0.1738394  0.03857949 0.68009371]          0   \n\n       is_harassment original_ds  is_aae_06  \n0                  0      founta          0  \n1                  1      founta          0  \n2                  0      founta          0  \n3                  0      founta          0  \n4                  0      founta          0  \n...              ...         ...        ...  \n19713              1     golbeck          0  \n19714              1     golbeck          0  \n19715              1     golbeck          0  \n19716              1     golbeck          0  \n19717              1     golbeck          0  \n\n[135023 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cleaned_tweet</th>\n      <th>text</th>\n      <th>dialect_prs</th>\n      <th>is_aae_08</th>\n      <th>is_harassment</th>\n      <th>original_ds</th>\n      <th>is_aae_06</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Beats by Dr. Dre urBeats Wired In-Ear Headphon...</td>\n      <td>Beats by Dr. Dre urBeats Wired In-Ear Headphon...</td>\n      <td>[0.37906185 0.22220451 0.19361946 0.20511418]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>founta</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>RT : Man it would fucking rule if we had a par...</td>\n      <td>RT @Papapishu: Man it would fucking rule if we...</td>\n      <td>[0.2085863  0.21244729 0.09804209 0.48092432]</td>\n      <td>0</td>\n      <td>1</td>\n      <td>founta</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>It is time to draw close to Him &amp;#128591;&amp;#127...</td>\n      <td>It is time to draw close to Him &amp;#128591;&amp;#127...</td>\n      <td>[0.13617963 0.40733362 0.00187648 0.45461027]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>founta</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>if you notice me start to act different or dis...</td>\n      <td>if you notice me start to act different or dis...</td>\n      <td>[0.42431609 0.35141981 0.00202164 0.22224246]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>founta</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Forget unfollowers, I believe in growing. 7 ne...</td>\n      <td>Forget unfollowers, I believe in growing. 7 ne...</td>\n      <td>[0.11957159 0.17347329 0.10673621 0.60021892]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>founta</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>19713</th>\n      <td>Wise words by Ben Shapiro https: / /t.co /ldBj...</td>\n      <td>Wise words by Ben Shapiro https: / /t.co /ldBj...</td>\n      <td>[0.14449078 0.16982948 0.24125604 0.4444237 ]</td>\n      <td>0</td>\n      <td>1</td>\n      <td>golbeck</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>19714</th>\n      <td>Women are much more likely to be liberals than...</td>\n      <td>Women are much more likely to be liberals than...</td>\n      <td>[0.05411577 0.10954312 0.01288798 0.82345312]</td>\n      <td>0</td>\n      <td>1</td>\n      <td>golbeck</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>19715</th>\n      <td>Would you like me to release to you this King ...</td>\n      <td>Would you like me to release to you this King ...</td>\n      <td>[0.17427205 0.34565292 0.09695176 0.38312327]</td>\n      <td>0</td>\n      <td>1</td>\n      <td>golbeck</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>19716</th>\n      <td>You Fucking Nigger You Did It To Yourself You ...</td>\n      <td>You Fucking Nigger You Did It To Yourself You ...</td>\n      <td>[0.09649005 0.69237505 0.00770617 0.20342874]</td>\n      <td>0</td>\n      <td>1</td>\n      <td>golbeck</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>19717</th>\n      <td>Your descendants, the Jews, will be doomed to ...</td>\n      <td>Your descendants, the Jews, will be doomed to ...</td>\n      <td>[0.1074874  0.1738394  0.03857949 0.68009371]</td>\n      <td>0</td>\n      <td>1</td>\n      <td>golbeck</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>135023 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('merged_df -  shape:', merged_df.shape, ' - label distribution:', round((merged_df[merged_df['is_harassment']==1].shape[0] / merged_df.shape[0]), 3),'- n is_aae 0.6 | 0.8:',merged_df[merged_df['is_aae_06']==1].shape[0],merged_df[merged_df['is_aae_08']==1].shape[0], '- columns:', merged_df.columns)\n",
    "merged_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# 11187/merged_df[merged_df['is_aae']==0].shape[0] # 0.10797428769979152 11187/103608"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# 45/merged_df[merged_df['is_aae08']==1].shape[0] #0.06686478454680535 45/673"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def _create_test_train_dev_splits(clean_data, tr_size=0.8, dev_test_split=0.5, stratify_label='is_harassment'):\n",
    "    train, valid_test = train_test_split(clean_data, train_size=tr_size, random_state=42,\n",
    "                                         stratify=clean_data[[stratify_label]])\n",
    "    test, valid = train_test_split(valid_test, train_size=dev_test_split, random_state=42,\n",
    "                                   stratify=valid_test[stratify_label])\n",
    "\n",
    "    print(f\"Train - # of is_harassment: {train[train['is_harassment'] == 1].shape[0]}, total instances: \" +\n",
    "                f\"{train.shape[0]}, percent of positive: {train[train['is_harassment'] == 1].shape[0] / train.shape[0]}\")\n",
    "    print(f\"Test - # of is_harassment: {test[test['is_harassment'] == 1].shape[0]}, total instances: \" +\n",
    "                f\"{test.shape[0]}, percent of positive: {test[test['is_harassment'] == 1].shape[0] / test.shape[0]}\")\n",
    "    print(f\"Test - # of is_harassment: {valid[valid['is_harassment'] == 1].shape[0]}, total instances: \" +\n",
    "                    f\"{valid.shape[0]}, percent of positive: {valid[valid['is_harassment'] == 1].shape[0] / valid.shape[0]}\")\n",
    "\n",
    "    return train, test, valid\n",
    "\n",
    "def save_test_train_dev_splits(ds):\n",
    "    twitter_train, twitter_valid, twitter_test = _create_test_train_dev_splits(ds, tr_size=0.8,\n",
    "                                                                                    dev_test_split=0.5,\n",
    "                                                                                    stratify_label='is_harassment')\n",
    "    # train: 861 7879 0.1093%   test: 214 1962 0.1091    dev: 121 1103 0.1097%\n",
    "\n",
    "    twitter_train.to_csv('../data/twitter_datasets/combined_harassment/train.csv', index=False)\n",
    "    twitter_valid.to_csv('../data/twitter_datasets/combined_harassment/dev.csv', index=False)\n",
    "    twitter_test.to_csv('../data/twitter_datasets/combined_harassment/test.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matan\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - # of is_harassment: 42273, total instances: 108018, percent of positive: 0.3913514414264289\n",
      "Test - # of is_harassment: 5284, total instances: 13502, percent of positive: 0.3913494297141164\n",
      "Test - # of is_harassment: 5284, total instances: 13503, percent of positive: 0.39132044730800564\n"
     ]
    }
   ],
   "source": [
    "save_test_train_dev_splits(merged_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File ../data/nyt_corpus/nyt_data/nyt_keyword_sample/test.csv does not exist: '../data/nyt_corpus/nyt_data/nyt_keyword_sample/test.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-20-4dd4d2906841>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'../data/nyt_corpus/nyt_data/nyt_keyword_sample/test.csv'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mindex_col\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001B[0m in \u001B[0;36mparser_f\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001B[0m\n\u001B[0;32m    674\u001B[0m         )\n\u001B[0;32m    675\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 676\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0m_read\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    677\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    678\u001B[0m     \u001B[0mparser_f\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__name__\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001B[0m in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    446\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    447\u001B[0m     \u001B[1;31m# Create the parser.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 448\u001B[1;33m     \u001B[0mparser\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mTextFileReader\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfp_or_buf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    449\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    450\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mchunksize\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0miterator\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[0;32m    878\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"has_index_names\"\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mkwds\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"has_index_names\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    879\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 880\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_make_engine\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    881\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    882\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mclose\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001B[0m in \u001B[0;36m_make_engine\u001B[1;34m(self, engine)\u001B[0m\n\u001B[0;32m   1112\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_make_engine\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mengine\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"c\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1113\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mengine\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m\"c\"\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1114\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mCParserWrapper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1115\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1116\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mengine\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m\"python\"\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, src, **kwds)\u001B[0m\n\u001B[0;32m   1889\u001B[0m         \u001B[0mkwds\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"usecols\"\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0musecols\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1890\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1891\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_reader\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mparsers\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mTextReader\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msrc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1892\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0munnamed_cols\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_reader\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0munnamed_cols\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1893\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader.__cinit__\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] File ../data/nyt_corpus/nyt_data/nyt_keyword_sample/test.csv does not exist: '../data/nyt_corpus/nyt_data/nyt_keyword_sample/test.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "x = pd.read_csv('../data/nyt_corpus/nyt_data/nyt_keyword_sample/test.csv', index_col=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x.to_csv('../data/nyt_corpus/nyt_data/nyt_keyword_sample/test.tsv', sep='\\t')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.read_json('../data/gab/majority_gab_dataset_25k/test.jsonl', lines=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.DataFrame({'a':[1,2],'b':[3,4]}).shape == (2,2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import csv\n",
    "pd.read_csv('../data/nyt_corpus/nyt_data/nyt_keyword_sample/test.tsv', delimiter='\\t')\n",
    "\n",
    "f = open('../data/nyt_corpus/nyt_data/nyt_keyword_sample/test.tsv')\n",
    "reader = csv.reader(f, delimiter='\\t')\n",
    "next(reader) # skip header\n",
    "examples = []\n",
    "for i, row in enumerate(reader):\n",
    "    print(row)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "stats\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_twitter =pd.read_csv('../data/twitter_datasets/cleaned/all_datasets_merged.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(all_twitter[all_twitter['is_hate']==1].shape[0])\n",
    "print(all_twitter[all_twitter['is_hate']==0].shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "temp = merged_df.drop(columns=['dialect_prs'])\n",
    "temp[temp.isin([np.nan, np.inf, -np.inf]).any(1)]\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "pycharm-7db20ed5",
   "language": "python",
   "display_name": "PyCharm (DelayedFlights)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}