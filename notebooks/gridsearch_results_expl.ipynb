{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import math\n",
    "import sys\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "root = '../src/baselines/runs/'\n",
    "models = ['bert_oc_gs', 'bert_soc_gs']\n",
    "datasets = ['davidson', 'founta', 'golbeck', 'harassment', 'hate']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "# gridsearch aggregate\n",
    "result = None\n",
    "for model in models:\n",
    "    for dataset in datasets:\n",
    "        for subdir in os.listdir(f'{root}/{model}'):\n",
    "            if os.path.exists(f'{root}/{model}/{subdir}/eval_results_0_dev_{dataset}.txt'):\n",
    "                f = pd.read_csv(\n",
    "                    filepath_or_buffer=f'{root}{model}/{subdir}/eval_results_0_dev_{dataset}.txt',\n",
    "                    delimiter='=',\n",
    "                    # names=['metric','score'],\n",
    "                    header=None,\n",
    "                )\n",
    "                args = pd.read_json(f'{root}{model}/{subdir}/args.json', typ='series')\n",
    "                args = args.to_frame().reset_index().rename(columns={\"index\": 0, 0: 1})\n",
    "                f = pd.concat([f, args], ignore_index=True)\n",
    "                f = f.append([['model', model[:-3]]], ignore_index=True)\n",
    "                f = f.append([['dataset', dataset]], ignore_index=True)\n",
    "                f.set_index(0, inplace=True)\n",
    "                f = f.transpose()\n",
    "                if result is None:\n",
    "                    result = f\n",
    "                else:\n",
    "                    result = pd.concat([result, f], ignore_index=True, sort=False)\n",
    "            else: pass\n",
    "\n",
    "\n",
    "result.to_csv(f'{root}/gs_results/gridsearch_expl_results_raw.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "0       acc   auc_roc  disparate_impact_favorable_06   \\\n0    0.93866  0.972684                       0.236528   \n1    0.94431   0.97097                       0.121867   \n2   0.957627  0.981972                       0.130753   \n3   0.964487  0.987828                      0.0964078   \n4   0.961259  0.986236                       0.131026   \n..       ...       ...                            ...   \n80  0.939866  0.891043                        1.02129   \n81  0.940189  0.890779                        1.02529   \n82   0.94148  0.893815                        1.01529   \n83  0.941561  0.895321                        1.02177   \n84  0.938897  0.885384                        1.01993   \n\n0  disparate_impact_favorable_08  disparate_impact_unfavorable_06   \\\n0                        0.426022                          1.26339   \n1                       0.0864928                          1.30454   \n2                       0.0926209                           1.2745   \n3                        0.103284                          1.25042   \n4                       0.0928088                          1.27366   \n..                            ...                              ...   \n80                        1.02923                         0.292957   \n81                         1.0313                          0.21853   \n82                        1.01515                         0.509598   \n83                        1.03329                         0.362816   \n84                        1.02615                         0.260826   \n\n0  disparate_impact_unfavorable_08  eval_loss  eval_loss_reg        f1   \\\n0                           1.16326   0.168889    4.01722e-05  0.961771   \n1                           1.25488   0.158455    0.000468094  0.965396   \n2                           1.23213    0.13663    0.000138618    0.9739   \n3                           1.20043   0.100869     0.00132101    0.9784   \n4                           1.23149   0.107736     0.00142147  0.976143   \n..                              ...        ...            ...       ...   \n80                                0   0.166691     0.00137342  0.389844   \n81                                0   0.167264     0.00150361  0.404819   \n82                         0.503864   0.164127     0.00110855  0.413905   \n83                                0   0.164603     0.00127491  0.429022   \n84                                0   0.171447     0.00171813  0.361181   \n\n0  fnr_priv_06   ... local_rank seed gradient_accumulation_steps   fp16  \\\n0     0.0704762  ...         -1   42                           1  False   \n1     0.0692063  ...         -1   42                           1  False   \n2     0.0495238  ...         -1   42                           1  False   \n3     0.0285714  ...         -1   42                           1  False   \n4     0.0463492  ...         -1   42                           1  False   \n..          ...  ...        ...  ...                         ...    ...   \n80      0.71875  ...         -1   42                           1  False   \n81     0.701923  ...         -1   42                           1  False   \n82     0.699519  ...         -1   42                           1  False   \n83     0.679087  ...         -1   42                           1  False   \n84      0.74399  ...         -1   42                           1  False   \n\n0  loss_scale server_ip server_port continue_from_checkpoint     model  \\\n0           0                                              0   bert_oc   \n1           0                                              0   bert_oc   \n2           0                                              0   bert_oc   \n3           0                                              0   bert_oc   \n4           0                                              0   bert_oc   \n..        ...       ...         ...                      ...       ...   \n80          0                                              0  bert_soc   \n81          0                                              0  bert_soc   \n82          0                                              0  bert_soc   \n83          0                                              0  bert_soc   \n84          0                                              0  bert_soc   \n\n0    dataset  \n0   davidson  \n1   davidson  \n2   davidson  \n3   davidson  \n4   davidson  \n..       ...  \n80      hate  \n81      hate  \n82      hate  \n83      hate  \n84      hate  \n\n[85 rows x 98 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>acc</th>\n      <th>auc_roc</th>\n      <th>disparate_impact_favorable_06</th>\n      <th>disparate_impact_favorable_08</th>\n      <th>disparate_impact_unfavorable_06</th>\n      <th>disparate_impact_unfavorable_08</th>\n      <th>eval_loss</th>\n      <th>eval_loss_reg</th>\n      <th>f1</th>\n      <th>fnr_priv_06</th>\n      <th>...</th>\n      <th>local_rank</th>\n      <th>seed</th>\n      <th>gradient_accumulation_steps</th>\n      <th>fp16</th>\n      <th>loss_scale</th>\n      <th>server_ip</th>\n      <th>server_port</th>\n      <th>continue_from_checkpoint</th>\n      <th>model</th>\n      <th>dataset</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.93866</td>\n      <td>0.972684</td>\n      <td>0.236528</td>\n      <td>0.426022</td>\n      <td>1.26339</td>\n      <td>1.16326</td>\n      <td>0.168889</td>\n      <td>4.01722e-05</td>\n      <td>0.961771</td>\n      <td>0.0704762</td>\n      <td>...</td>\n      <td>-1</td>\n      <td>42</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n      <td>bert_oc</td>\n      <td>davidson</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.94431</td>\n      <td>0.97097</td>\n      <td>0.121867</td>\n      <td>0.0864928</td>\n      <td>1.30454</td>\n      <td>1.25488</td>\n      <td>0.158455</td>\n      <td>0.000468094</td>\n      <td>0.965396</td>\n      <td>0.0692063</td>\n      <td>...</td>\n      <td>-1</td>\n      <td>42</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n      <td>bert_oc</td>\n      <td>davidson</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.957627</td>\n      <td>0.981972</td>\n      <td>0.130753</td>\n      <td>0.0926209</td>\n      <td>1.2745</td>\n      <td>1.23213</td>\n      <td>0.13663</td>\n      <td>0.000138618</td>\n      <td>0.9739</td>\n      <td>0.0495238</td>\n      <td>...</td>\n      <td>-1</td>\n      <td>42</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n      <td>bert_oc</td>\n      <td>davidson</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.964487</td>\n      <td>0.987828</td>\n      <td>0.0964078</td>\n      <td>0.103284</td>\n      <td>1.25042</td>\n      <td>1.20043</td>\n      <td>0.100869</td>\n      <td>0.00132101</td>\n      <td>0.9784</td>\n      <td>0.0285714</td>\n      <td>...</td>\n      <td>-1</td>\n      <td>42</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n      <td>bert_oc</td>\n      <td>davidson</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.961259</td>\n      <td>0.986236</td>\n      <td>0.131026</td>\n      <td>0.0928088</td>\n      <td>1.27366</td>\n      <td>1.23149</td>\n      <td>0.107736</td>\n      <td>0.00142147</td>\n      <td>0.976143</td>\n      <td>0.0463492</td>\n      <td>...</td>\n      <td>-1</td>\n      <td>42</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n      <td>bert_oc</td>\n      <td>davidson</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>80</th>\n      <td>0.939866</td>\n      <td>0.891043</td>\n      <td>1.02129</td>\n      <td>1.02923</td>\n      <td>0.292957</td>\n      <td>0</td>\n      <td>0.166691</td>\n      <td>0.00137342</td>\n      <td>0.389844</td>\n      <td>0.71875</td>\n      <td>...</td>\n      <td>-1</td>\n      <td>42</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n      <td>bert_soc</td>\n      <td>hate</td>\n    </tr>\n    <tr>\n      <th>81</th>\n      <td>0.940189</td>\n      <td>0.890779</td>\n      <td>1.02529</td>\n      <td>1.0313</td>\n      <td>0.21853</td>\n      <td>0</td>\n      <td>0.167264</td>\n      <td>0.00150361</td>\n      <td>0.404819</td>\n      <td>0.701923</td>\n      <td>...</td>\n      <td>-1</td>\n      <td>42</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n      <td>bert_soc</td>\n      <td>hate</td>\n    </tr>\n    <tr>\n      <th>82</th>\n      <td>0.94148</td>\n      <td>0.893815</td>\n      <td>1.01529</td>\n      <td>1.01515</td>\n      <td>0.509598</td>\n      <td>0.503864</td>\n      <td>0.164127</td>\n      <td>0.00110855</td>\n      <td>0.413905</td>\n      <td>0.699519</td>\n      <td>...</td>\n      <td>-1</td>\n      <td>42</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n      <td>bert_soc</td>\n      <td>hate</td>\n    </tr>\n    <tr>\n      <th>83</th>\n      <td>0.941561</td>\n      <td>0.895321</td>\n      <td>1.02177</td>\n      <td>1.03329</td>\n      <td>0.362816</td>\n      <td>0</td>\n      <td>0.164603</td>\n      <td>0.00127491</td>\n      <td>0.429022</td>\n      <td>0.679087</td>\n      <td>...</td>\n      <td>-1</td>\n      <td>42</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n      <td>bert_soc</td>\n      <td>hate</td>\n    </tr>\n    <tr>\n      <th>84</th>\n      <td>0.938897</td>\n      <td>0.885384</td>\n      <td>1.01993</td>\n      <td>1.02615</td>\n      <td>0.260826</td>\n      <td>0</td>\n      <td>0.171447</td>\n      <td>0.00171813</td>\n      <td>0.361181</td>\n      <td>0.74399</td>\n      <td>...</td>\n      <td>-1</td>\n      <td>42</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n      <td>bert_soc</td>\n      <td>hate</td>\n    </tr>\n  </tbody>\n</table>\n<p>85 rows × 98 columns</p>\n</div>"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "'bert_soc'"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'bert_soc_gs'[:-3]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    for dataset in datasets:\n",
    "        temp = result[(result['dataset']==dataset) & (result['model'] == model[:-3])]\n",
    "        temp = temp.sort_values(by=['f1 '], ascending=False)\n",
    "        temp.to_csv(f'{root}/gs_results/{model[:-3]}_{dataset}.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "best_results_gs = None\n",
    "for model in models:\n",
    "    for dataset in datasets:\n",
    "        if best_results_gs is None:\n",
    "            best_results_gs = pd.read_csv(f'{root}/gs_results/{model[:-3]}_{dataset}.csv').head(1)\n",
    "        else:\n",
    "           best_results_gs = pd.concat([best_results_gs, pd.read_csv(f'{root}/gs_results/{model[:-3]}_{dataset}.csv').head(1)])\n",
    "best_results_gs.to_csv(f'{root}/gs_results/best_hp_results_expl.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "       acc   auc_roc   disparate_impact_favorable_06   \\\n0  0.967312  0.988467                        0.135910   \n0  0.939206  0.972975                        0.185922   \n0  0.791582  0.725867                        0.934984   \n0  0.903094  0.955676                        0.083677   \n0  0.940189  0.889739                        1.022384   \n0  0.970137  0.989351                        0.125620   \n0  0.938880  0.972734                        0.176721   \n0  0.784990  0.725321                        0.583135   \n0  0.908895  0.959597                        0.086479   \n0  0.941561  0.895321                        1.021770   \n\n   disparate_impact_favorable_08   disparate_impact_unfavorable_06   \\\n0                        0.103051                          1.237363   \n0                        0.137582                          3.260271   \n0                        1.068872                          1.948413   \n0                        0.059509                          2.810277   \n0                        1.024954                          0.135665   \n0                        0.102820                          1.241612   \n0                        0.138058                          3.257554   \n0                        1.168346                          3.507143   \n0                        0.019939                          2.775356   \n0                        1.033291                          0.362816   \n\n   disparate_impact_unfavorable_08   eval_loss   eval_loss_reg        f1   \\\n0                          1.201032    0.096138        0.001522  0.980113   \n0                          3.294739    0.177459        0.002693  0.889416   \n0                          0.000000    0.480020        0.000165  0.318408   \n0                          2.658547    0.257533        0.001100  0.872017   \n0                          0.000000    0.167939        0.001446  0.367208   \n0                          1.201639    0.104425        0.000818  0.981827   \n0                          3.264810    0.176269        0.002505  0.889327   \n0                          0.000000    0.515957        0.000545  0.442105   \n0                          2.703913    0.245078        0.000653  0.880219   \n0                          0.000000    0.164603        0.001275  0.429022   \n\n   fnr_priv_06   ...  local_rank  seed  gradient_accumulation_steps   fp16  \\\n0      0.026032  ...          -1    42                            1  False   \n0      0.118084  ...          -1    42                            1  False   \n0      0.798301  ...          -1    42                            1  False   \n0      0.175424  ...          -1    42                            1  False   \n0      0.743990  ...          -1    42                            1  False   \n0      0.024762  ...          -1    42                            1  False   \n0      0.114368  ...          -1    42                            1  False   \n0      0.649682  ...          -1    42                            1  False   \n0      0.162342  ...          -1    42                            1  False   \n0      0.679087  ...          -1    42                            1  False   \n\n   loss_scale  server_ip  server_port  continue_from_checkpoint     model  \\\n0           0        NaN          NaN                         0   bert_oc   \n0           0        NaN          NaN                         0   bert_oc   \n0           0        NaN          NaN                         0   bert_oc   \n0           0        NaN          NaN                         0   bert_oc   \n0           0        NaN          NaN                         0   bert_oc   \n0           0        NaN          NaN                         0  bert_soc   \n0           0        NaN          NaN                         0  bert_soc   \n0           0        NaN          NaN                         0  bert_soc   \n0           0        NaN          NaN                         0  bert_soc   \n0           0        NaN          NaN                         0  bert_soc   \n\n      dataset  \n0    davidson  \n0      founta  \n0     golbeck  \n0  harassment  \n0        hate  \n0    davidson  \n0      founta  \n0     golbeck  \n0  harassment  \n0        hate  \n\n[10 rows x 98 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>acc</th>\n      <th>auc_roc</th>\n      <th>disparate_impact_favorable_06</th>\n      <th>disparate_impact_favorable_08</th>\n      <th>disparate_impact_unfavorable_06</th>\n      <th>disparate_impact_unfavorable_08</th>\n      <th>eval_loss</th>\n      <th>eval_loss_reg</th>\n      <th>f1</th>\n      <th>fnr_priv_06</th>\n      <th>...</th>\n      <th>local_rank</th>\n      <th>seed</th>\n      <th>gradient_accumulation_steps</th>\n      <th>fp16</th>\n      <th>loss_scale</th>\n      <th>server_ip</th>\n      <th>server_port</th>\n      <th>continue_from_checkpoint</th>\n      <th>model</th>\n      <th>dataset</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.967312</td>\n      <td>0.988467</td>\n      <td>0.135910</td>\n      <td>0.103051</td>\n      <td>1.237363</td>\n      <td>1.201032</td>\n      <td>0.096138</td>\n      <td>0.001522</td>\n      <td>0.980113</td>\n      <td>0.026032</td>\n      <td>...</td>\n      <td>-1</td>\n      <td>42</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>bert_oc</td>\n      <td>davidson</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.939206</td>\n      <td>0.972975</td>\n      <td>0.185922</td>\n      <td>0.137582</td>\n      <td>3.260271</td>\n      <td>3.294739</td>\n      <td>0.177459</td>\n      <td>0.002693</td>\n      <td>0.889416</td>\n      <td>0.118084</td>\n      <td>...</td>\n      <td>-1</td>\n      <td>42</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>bert_oc</td>\n      <td>founta</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.791582</td>\n      <td>0.725867</td>\n      <td>0.934984</td>\n      <td>1.068872</td>\n      <td>1.948413</td>\n      <td>0.000000</td>\n      <td>0.480020</td>\n      <td>0.000165</td>\n      <td>0.318408</td>\n      <td>0.798301</td>\n      <td>...</td>\n      <td>-1</td>\n      <td>42</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>bert_oc</td>\n      <td>golbeck</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.903094</td>\n      <td>0.955676</td>\n      <td>0.083677</td>\n      <td>0.059509</td>\n      <td>2.810277</td>\n      <td>2.658547</td>\n      <td>0.257533</td>\n      <td>0.001100</td>\n      <td>0.872017</td>\n      <td>0.175424</td>\n      <td>...</td>\n      <td>-1</td>\n      <td>42</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>bert_oc</td>\n      <td>harassment</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.940189</td>\n      <td>0.889739</td>\n      <td>1.022384</td>\n      <td>1.024954</td>\n      <td>0.135665</td>\n      <td>0.000000</td>\n      <td>0.167939</td>\n      <td>0.001446</td>\n      <td>0.367208</td>\n      <td>0.743990</td>\n      <td>...</td>\n      <td>-1</td>\n      <td>42</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>bert_oc</td>\n      <td>hate</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.970137</td>\n      <td>0.989351</td>\n      <td>0.125620</td>\n      <td>0.102820</td>\n      <td>1.241612</td>\n      <td>1.201639</td>\n      <td>0.104425</td>\n      <td>0.000818</td>\n      <td>0.981827</td>\n      <td>0.024762</td>\n      <td>...</td>\n      <td>-1</td>\n      <td>42</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>bert_soc</td>\n      <td>davidson</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.938880</td>\n      <td>0.972734</td>\n      <td>0.176721</td>\n      <td>0.138058</td>\n      <td>3.257554</td>\n      <td>3.264810</td>\n      <td>0.176269</td>\n      <td>0.002505</td>\n      <td>0.889327</td>\n      <td>0.114368</td>\n      <td>...</td>\n      <td>-1</td>\n      <td>42</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>bert_soc</td>\n      <td>founta</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.784990</td>\n      <td>0.725321</td>\n      <td>0.583135</td>\n      <td>1.168346</td>\n      <td>3.507143</td>\n      <td>0.000000</td>\n      <td>0.515957</td>\n      <td>0.000545</td>\n      <td>0.442105</td>\n      <td>0.649682</td>\n      <td>...</td>\n      <td>-1</td>\n      <td>42</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>bert_soc</td>\n      <td>golbeck</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.908895</td>\n      <td>0.959597</td>\n      <td>0.086479</td>\n      <td>0.019939</td>\n      <td>2.775356</td>\n      <td>2.703913</td>\n      <td>0.245078</td>\n      <td>0.000653</td>\n      <td>0.880219</td>\n      <td>0.162342</td>\n      <td>...</td>\n      <td>-1</td>\n      <td>42</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>bert_soc</td>\n      <td>harassment</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.941561</td>\n      <td>0.895321</td>\n      <td>1.021770</td>\n      <td>1.033291</td>\n      <td>0.362816</td>\n      <td>0.000000</td>\n      <td>0.164603</td>\n      <td>0.001275</td>\n      <td>0.429022</td>\n      <td>0.679087</td>\n      <td>...</td>\n      <td>-1</td>\n      <td>42</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>bert_soc</td>\n      <td>hate</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows × 98 columns</p>\n</div>"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_results_gs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     object\n",
      "1    float64\n",
      "dtype: object\n",
      "0\n",
      "acc                                 float64\n",
      "auc_roc                             float64\n",
      "disparate_impact_favorable_06       float64\n",
      "disparate_impact_favorable_08       float64\n",
      "disparate_impact_unfavorable_06     float64\n",
      "disparate_impact_unfavorable_08     float64\n",
      "f1                                  float64\n",
      "fnr_priv_06                         float64\n",
      "fnr_priv_08                         float64\n",
      "fnr_total_06                        float64\n",
      "fnr_total_08                        float64\n",
      "fnr_unpriv_06                       float64\n",
      "fnr_unpriv_08                       float64\n",
      "fpr_priv_06                         float64\n",
      "fpr_priv_08                         float64\n",
      "fpr_total_06                        float64\n",
      "fpr_total_08                        float64\n",
      "fpr_unpriv_06                       float64\n",
      "fpr_unpriv_08                       float64\n",
      "loss                                float64\n",
      "precision                           float64\n",
      "priv_n_06                           float64\n",
      "priv_n_08                           float64\n",
      "priv_ratio_favorable_06             float64\n",
      "priv_ratio_favorable_08             float64\n",
      "priv_ratio_unfavorable_06           float64\n",
      "priv_ratio_unfavorable_08           float64\n",
      "priv_total_06                       float64\n",
      "priv_total_08                       float64\n",
      "recall                              float64\n",
      "unpriv_n_06                         float64\n",
      "unpriv_n_08                         float64\n",
      "unpriv_ratio_favorable_06           float64\n",
      "unpriv_ratio_favorable_08           float64\n",
      "unpriv_ratio_unfavorable_06         float64\n",
      "unpriv_ratio_unfavorable_08         float64\n",
      "unpriv_total_06                     float64\n",
      "unpriv_total_08                     float64\n",
      "is_local                             object\n",
      "is_gcloud                            object\n",
      "is_gridsearch                        object\n",
      "retrain                              object\n",
      "task_name                            object\n",
      "seed                                 object\n",
      "dataset                              object\n",
      "batch_size                           object\n",
      "epochs                               object\n",
      "max_seq_length                       object\n",
      "learning_rate                        object\n",
      "reg_strength                         object\n",
      "class_weight                         object\n",
      "output_dir                           object\n",
      "do_train                             object\n",
      "do_eval                              object\n",
      "test                                 object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "f = pd.read_csv(\n",
    "                    filepath_or_buffer=f'{root}log_reg_results/glove_davidson_0/eval_results_dev_glove',\n",
    "                    delimiter='=',\n",
    "                    header=None,\n",
    "                )\n",
    "f[1] = f[1].astype(float)\n",
    "print(f.dtypes)\n",
    "args = pd.read_json(f'{root}log_reg_results/glove_davidson_0/args.json', typ='series', dtype=str)\n",
    "args = args.to_frame().reset_index().rename(columns={\"index\": 0, 0: 1})\n",
    "f = pd.concat([f, args], ignore_index=True)\n",
    "f.set_index(0, inplace=True)\n",
    "f = f.transpose()\n",
    "\n",
    "f[['acc ', 'auc_roc ', 'disparate_impact_favorable_06 ',\n",
    "       'disparate_impact_favorable_08 ', 'disparate_impact_unfavorable_06 ',\n",
    "       'disparate_impact_unfavorable_08 ', 'f1 ', 'fnr_priv_06 ',\n",
    "       'fnr_priv_08 ', 'fnr_total_06 ', 'fnr_total_08 ', 'fnr_unpriv_06 ',\n",
    "       'fnr_unpriv_08 ', 'fpr_priv_06 ', 'fpr_priv_08 ', 'fpr_total_06 ',\n",
    "       'fpr_total_08 ', 'fpr_unpriv_06 ', 'fpr_unpriv_08 ', 'loss ',\n",
    "       'precision ', 'priv_n_06 ', 'priv_n_08 ', 'priv_ratio_favorable_06 ',\n",
    "       'priv_ratio_favorable_08 ', 'priv_ratio_unfavorable_06 ',\n",
    "       'priv_ratio_unfavorable_08 ', 'priv_total_06 ', 'priv_total_08 ',\n",
    "       'recall ', 'unpriv_n_06 ', 'unpriv_n_08 ', 'unpriv_ratio_favorable_06 ',\n",
    "       'unpriv_ratio_favorable_08 ', 'unpriv_ratio_unfavorable_06 ',\n",
    "       'unpriv_ratio_unfavorable_08 ', 'unpriv_total_06 ', 'unpriv_total_08 ']] = f[['acc ', 'auc_roc ', 'disparate_impact_favorable_06 ',\n",
    "       'disparate_impact_favorable_08 ', 'disparate_impact_unfavorable_06 ',\n",
    "       'disparate_impact_unfavorable_08 ', 'f1 ', 'fnr_priv_06 ',\n",
    "       'fnr_priv_08 ', 'fnr_total_06 ', 'fnr_total_08 ', 'fnr_unpriv_06 ',\n",
    "       'fnr_unpriv_08 ', 'fpr_priv_06 ', 'fpr_priv_08 ', 'fpr_total_06 ',\n",
    "       'fpr_total_08 ', 'fpr_unpriv_06 ', 'fpr_unpriv_08 ', 'loss ',\n",
    "       'precision ', 'priv_n_06 ', 'priv_n_08 ', 'priv_ratio_favorable_06 ',\n",
    "       'priv_ratio_favorable_08 ', 'priv_ratio_unfavorable_06 ',\n",
    "       'priv_ratio_unfavorable_08 ', 'priv_total_06 ', 'priv_total_08 ',\n",
    "       'recall ', 'unpriv_n_06 ', 'unpriv_n_08 ', 'unpriv_ratio_favorable_06 ',\n",
    "       'unpriv_ratio_favorable_08 ', 'unpriv_ratio_unfavorable_06 ',\n",
    "       'unpriv_ratio_unfavorable_08 ', 'unpriv_total_06 ', 'unpriv_total_08 ',]].astype(float)\n",
    "\n",
    "print(f.dtypes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "                                   0                       1\n0                               acc       0.9419312744671596\n1                           auc_roc       0.9709648815613618\n2     disparate_impact_favorable_06       0.1748234242977409\n3     disparate_impact_favorable_08       0.1967497430626927\n4   disparate_impact_unfavorable_06        3.269320793484362\n5   disparate_impact_unfavorable_08        3.129235484420228\n6                         eval_loss       0.1761298927761938\n7                     eval_loss_reg    0.0011569487572533055\n8                                f1       0.8935831008369869\n9                       fnr_priv_06      0.10521920668058456\n10                      fnr_priv_08      0.10164724789071916\n11                     fnr_total_06      0.10140280561122245\n12                     fnr_total_08      0.10140280561122245\n13                    fnr_unpriv_06                     0.01\n14                    fnr_unpriv_08                      0.0\n15                      fpr_priv_06      0.04159186116098145\n16                      fpr_priv_08     0.041940298507462684\n17                     fpr_total_06     0.041934039695567825\n18                     fpr_total_08     0.041934039695567825\n19                    fpr_unpriv_06      0.17647058823529413\n20                    fpr_unpriv_08                      0.0\n21                      global_step                        0\n22                             loss                     None\n23                        precision       0.8886246531906461\n24                        priv_n_06                     9079\n25                        priv_n_08                     9189\n26          priv_ratio_favorable_06       0.7333406762859346\n27          priv_ratio_favorable_08       0.7260855370551746\n28        priv_ratio_unfavorable_06       0.2666593237140654\n29        priv_ratio_unfavorable_08      0.27391446294482535\n30                    priv_total_06                     9079\n31                    priv_total_08                     9189\n32                           recall       0.8985971943887776\n33                      unpriv_n_06                      117\n34                      unpriv_n_08                        7\n35        unpriv_ratio_favorable_06       0.1282051282051282\n36        unpriv_ratio_favorable_08      0.14285714285714285\n37      unpriv_ratio_unfavorable_06       0.8717948717948718\n38      unpriv_ratio_unfavorable_08       0.8571428571428571\n39                  unpriv_total_06                      117\n40                  unpriv_total_08                        7",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>acc</td>\n      <td>0.9419312744671596</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>auc_roc</td>\n      <td>0.9709648815613618</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>disparate_impact_favorable_06</td>\n      <td>0.1748234242977409</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>disparate_impact_favorable_08</td>\n      <td>0.1967497430626927</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>disparate_impact_unfavorable_06</td>\n      <td>3.269320793484362</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>disparate_impact_unfavorable_08</td>\n      <td>3.129235484420228</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>eval_loss</td>\n      <td>0.1761298927761938</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>eval_loss_reg</td>\n      <td>0.0011569487572533055</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>f1</td>\n      <td>0.8935831008369869</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>fnr_priv_06</td>\n      <td>0.10521920668058456</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>fnr_priv_08</td>\n      <td>0.10164724789071916</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>fnr_total_06</td>\n      <td>0.10140280561122245</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>fnr_total_08</td>\n      <td>0.10140280561122245</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>fnr_unpriv_06</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>fnr_unpriv_08</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>fpr_priv_06</td>\n      <td>0.04159186116098145</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>fpr_priv_08</td>\n      <td>0.041940298507462684</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>fpr_total_06</td>\n      <td>0.041934039695567825</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>fpr_total_08</td>\n      <td>0.041934039695567825</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>fpr_unpriv_06</td>\n      <td>0.17647058823529413</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>fpr_unpriv_08</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>global_step</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>loss</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>precision</td>\n      <td>0.8886246531906461</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>priv_n_06</td>\n      <td>9079</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>priv_n_08</td>\n      <td>9189</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>priv_ratio_favorable_06</td>\n      <td>0.7333406762859346</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>priv_ratio_favorable_08</td>\n      <td>0.7260855370551746</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>priv_ratio_unfavorable_06</td>\n      <td>0.2666593237140654</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>priv_ratio_unfavorable_08</td>\n      <td>0.27391446294482535</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>priv_total_06</td>\n      <td>9079</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>priv_total_08</td>\n      <td>9189</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>recall</td>\n      <td>0.8985971943887776</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>unpriv_n_06</td>\n      <td>117</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>unpriv_n_08</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>unpriv_ratio_favorable_06</td>\n      <td>0.1282051282051282</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>unpriv_ratio_favorable_08</td>\n      <td>0.14285714285714285</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>unpriv_ratio_unfavorable_06</td>\n      <td>0.8717948717948718</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>unpriv_ratio_unfavorable_08</td>\n      <td>0.8571428571428571</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>unpriv_total_06</td>\n      <td>117</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>unpriv_total_08</td>\n      <td>7</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = pd.read_csv(\n",
    "                    filepath_or_buffer=f'{root}bert_oc_results/founta_1/eval_results_0_test_founta.txt',\n",
    "                    delimiter='=',\n",
    "                    header=None,\n",
    "            )\n",
    "f"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "f.replace(' None', 0, inplace=True)\n",
    "f[1] = f[1].astype(float)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# seeds aggregate\n",
    "\n",
    "result_val = None\n",
    "result_test = None\n",
    "pattern_dev = 'eval_results_0_dev'\n",
    "pattern_test = 'eval_results_0_test'\n",
    "for subdir in os.listdir(f'{root}bert_oc_results'):\n",
    "    for file in os.listdir(f'{root}bert_oc_results/{subdir}/'):\n",
    "        if re.match(pattern_dev, file):\n",
    "            # print(f'{root}bert_oc_results/{subdir}/{file}')\n",
    "            f = pd.read_csv(\n",
    "                    filepath_or_buffer=f'{root}bert_oc_results/{subdir}/{file}',\n",
    "                    delimiter='=',\n",
    "                    header=None,\n",
    "                )\n",
    "            f.replace(' None', 0, inplace=True)\n",
    "            f[1] = f[1].astype(float)\n",
    "            args = pd.read_json(f'{root}bert_oc_results/{subdir}/args.json', typ='series', dtype=str)\n",
    "            args = args.to_frame().reset_index().rename(columns={\"index\": 0, 0: 1})\n",
    "            f = pd.concat([f, args], ignore_index=True)\n",
    "            f.set_index(0, inplace=True)\n",
    "            f = f.transpose()\n",
    "            if result_val is None:\n",
    "                result_val = f\n",
    "            else:\n",
    "                result_val = pd.concat([result_val, f], ignore_index=True, sort=False)\n",
    "        elif re.match(pattern_test, file):\n",
    "            # print(f'{root}bert_oc_results/{subdir}/{file}')\n",
    "            f = pd.read_csv(\n",
    "                    filepath_or_buffer=f'{root}bert_oc_results/{subdir}/{file}',\n",
    "                    delimiter='=',\n",
    "                    header=None,\n",
    "            )\n",
    "            f.replace(' None', 0, inplace=True)\n",
    "            f[1] = f[1].astype(float)\n",
    "            args = pd.read_json(f'{root}bert_oc_results/{subdir}/args.json', typ='series', dtype=str)\n",
    "            args = args.to_frame().reset_index().rename(columns={\"index\": 0, 0: 1})\n",
    "            f = pd.concat([f, args], ignore_index=True)\n",
    "            f.set_index(0, inplace=True)\n",
    "            f = f.transpose()\n",
    "            if result_test is None:\n",
    "                result_test = f\n",
    "            else:\n",
    "                result_test = pd.concat([result_test, f], ignore_index=True, sort=False)\n",
    "        else: pass\n",
    "\n",
    "result_test[['acc ', 'auc_roc ', 'disparate_impact_favorable_06 ',\n",
    "       'disparate_impact_favorable_08 ', 'disparate_impact_unfavorable_06 ',\n",
    "       'disparate_impact_unfavorable_08 ', 'f1 ', 'fnr_priv_06 ',\n",
    "       'fnr_priv_08 ', 'fnr_total_06 ', 'fnr_total_08 ', 'fnr_unpriv_06 ',\n",
    "       'fnr_unpriv_08 ', 'fpr_priv_06 ', 'fpr_priv_08 ', 'fpr_total_06 ',\n",
    "       'fpr_total_08 ', 'fpr_unpriv_06 ', 'fpr_unpriv_08 ', 'loss ',\n",
    "       'precision ', 'priv_n_06 ', 'priv_n_08 ', 'priv_ratio_favorable_06 ',\n",
    "       'priv_ratio_favorable_08 ', 'priv_ratio_unfavorable_06 ',\n",
    "       'priv_ratio_unfavorable_08 ', 'priv_total_06 ', 'priv_total_08 ',\n",
    "       'recall ', 'unpriv_n_06 ', 'unpriv_n_08 ', 'unpriv_ratio_favorable_06 ',\n",
    "       'unpriv_ratio_favorable_08 ', 'unpriv_ratio_unfavorable_06 ',\n",
    "       'unpriv_ratio_unfavorable_08 ', 'unpriv_total_06 ', 'unpriv_total_08 ']] = result_test[['acc ', 'auc_roc ', 'disparate_impact_favorable_06 ',\n",
    "       'disparate_impact_favorable_08 ', 'disparate_impact_unfavorable_06 ',\n",
    "       'disparate_impact_unfavorable_08 ', 'f1 ', 'fnr_priv_06 ',\n",
    "       'fnr_priv_08 ', 'fnr_total_06 ', 'fnr_total_08 ', 'fnr_unpriv_06 ',\n",
    "       'fnr_unpriv_08 ', 'fpr_priv_06 ', 'fpr_priv_08 ', 'fpr_total_06 ',\n",
    "       'fpr_total_08 ', 'fpr_unpriv_06 ', 'fpr_unpriv_08 ', 'loss ',\n",
    "       'precision ', 'priv_n_06 ', 'priv_n_08 ', 'priv_ratio_favorable_06 ',\n",
    "       'priv_ratio_favorable_08 ', 'priv_ratio_unfavorable_06 ',\n",
    "       'priv_ratio_unfavorable_08 ', 'priv_total_06 ', 'priv_total_08 ',\n",
    "       'recall ', 'unpriv_n_06 ', 'unpriv_n_08 ', 'unpriv_ratio_favorable_06 ',\n",
    "       'unpriv_ratio_favorable_08 ', 'unpriv_ratio_unfavorable_06 ',\n",
    "       'unpriv_ratio_unfavorable_08 ', 'unpriv_total_06 ', 'unpriv_total_08 ',]].astype(float)\n",
    "\n",
    "result_val[['acc ', 'auc_roc ', 'disparate_impact_favorable_06 ',\n",
    "       'disparate_impact_favorable_08 ', 'disparate_impact_unfavorable_06 ',\n",
    "       'disparate_impact_unfavorable_08 ', 'f1 ', 'fnr_priv_06 ',\n",
    "       'fnr_priv_08 ', 'fnr_total_06 ', 'fnr_total_08 ', 'fnr_unpriv_06 ',\n",
    "       'fnr_unpriv_08 ', 'fpr_priv_06 ', 'fpr_priv_08 ', 'fpr_total_06 ',\n",
    "       'fpr_total_08 ', 'fpr_unpriv_06 ', 'fpr_unpriv_08 ', 'loss ',\n",
    "       'precision ', 'priv_n_06 ', 'priv_n_08 ', 'priv_ratio_favorable_06 ',\n",
    "       'priv_ratio_favorable_08 ', 'priv_ratio_unfavorable_06 ',\n",
    "       'priv_ratio_unfavorable_08 ', 'priv_total_06 ', 'priv_total_08 ',\n",
    "       'recall ', 'unpriv_n_06 ', 'unpriv_n_08 ', 'unpriv_ratio_favorable_06 ',\n",
    "       'unpriv_ratio_favorable_08 ', 'unpriv_ratio_unfavorable_06 ',\n",
    "       'unpriv_ratio_unfavorable_08 ', 'unpriv_total_06 ', 'unpriv_total_08 ']] = result_val[['acc ', 'auc_roc ', 'disparate_impact_favorable_06 ',\n",
    "       'disparate_impact_favorable_08 ', 'disparate_impact_unfavorable_06 ',\n",
    "       'disparate_impact_unfavorable_08 ', 'f1 ', 'fnr_priv_06 ',\n",
    "       'fnr_priv_08 ', 'fnr_total_06 ', 'fnr_total_08 ', 'fnr_unpriv_06 ',\n",
    "       'fnr_unpriv_08 ', 'fpr_priv_06 ', 'fpr_priv_08 ', 'fpr_total_06 ',\n",
    "       'fpr_total_08 ', 'fpr_unpriv_06 ', 'fpr_unpriv_08 ', 'loss ',\n",
    "       'precision ', 'priv_n_06 ', 'priv_n_08 ', 'priv_ratio_favorable_06 ',\n",
    "       'priv_ratio_favorable_08 ', 'priv_ratio_unfavorable_06 ',\n",
    "       'priv_ratio_unfavorable_08 ', 'priv_total_06 ', 'priv_total_08 ',\n",
    "       'recall ', 'unpriv_n_06 ', 'unpriv_n_08 ', 'unpriv_ratio_favorable_06 ',\n",
    "       'unpriv_ratio_favorable_08 ', 'unpriv_ratio_unfavorable_06 ',\n",
    "       'unpriv_ratio_unfavorable_08 ', 'unpriv_total_06 ', 'unpriv_total_08 ',]].astype(float)\n",
    "result_val.to_csv(f'{root}/bert_expl_stats/oc_val_results_raw.csv', index=False)\n",
    "result_test.to_csv(f'{root}/bert_expl_stats/oc_test_results_raw.csv', index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "0       acc   auc_roc   disparate_impact_favorable_06   \\\n0   0.966115  0.987726                        0.103887   \n1   0.967326  0.987629                        0.098906   \n2   0.965309  0.987645                        0.102900   \n3   0.964905  0.987033                        0.097569   \n4   0.965712  0.988146                        0.104639   \n5   0.966519  0.986875                        0.092665   \n6   0.963292  0.986479                        0.100746   \n7   0.966519  0.987424                        0.092665   \n8   0.966922  0.988082                        0.108392   \n9   0.966922  0.988119                        0.094669   \n10  0.942584  0.970476                        0.173935   \n11  0.941931  0.970965                        0.174823   \n12  0.942040  0.969229                        0.174955   \n13  0.943454  0.972278                        0.151060   \n14  0.942801  0.972270                        0.163095   \n15  0.941496  0.969844                        0.162802   \n16  0.943236  0.971196                        0.162315   \n17  0.943127  0.971430                        0.161856   \n18  0.942910  0.971802                        0.151264   \n19  0.943345  0.971342                        0.162534   \n20  0.783976  0.712576                        0.596970   \n21  0.796146  0.730093                        0.584402   \n22  0.790061  0.725043                        0.658045   \n23  0.791582  0.729048                        0.581503   \n24  0.794118  0.727370                        0.588314   \n25  0.797667  0.730059                        0.590619   \n26  0.789047  0.727936                        0.591613   \n27  0.794625  0.731095                        0.587986   \n28  0.789554  0.730490                        0.746823   \n29  0.793103  0.726402                        0.665308   \n30  0.911572  0.962585                        0.058094   \n31  0.911126  0.962389                        0.053104   \n32  0.911275  0.961748                        0.058189   \n33  0.911870  0.962238                        0.056207   \n34  0.911052  0.962237                        0.050552   \n35  0.910159  0.961517                        0.054963   \n36  0.910828  0.962539                        0.053254   \n37  0.910680  0.962241                        0.053204   \n38  0.911944  0.962261                        0.050683   \n39  0.910605  0.961182                        0.043156   \n40  0.939624  0.881073                        0.997749   \n41  0.938978  0.881115                        0.994188   \n42  0.938897  0.866282                        0.987238   \n43  0.939140  0.879836                        0.982287   \n44  0.938978  0.888573                        0.974288   \n45  0.936637  0.872322                        0.949854   \n46  0.940350  0.885010                        0.976692   \n47  0.933893  0.877909                        0.998346   \n48  0.937687  0.861113                        0.956426   \n49  0.938817  0.874007                        0.973861   \n\n0   disparate_impact_favorable_08   disparate_impact_unfavorable_06   \\\n0                         0.000000                          1.239538   \n1                         0.000000                          1.256452   \n2                         0.000000                          1.242724   \n3                         0.000000                          1.261369   \n4                         0.000000                          1.237159   \n5                         0.000000                          1.248465   \n6                         0.000000                          1.249954   \n7                         0.000000                          1.248465   \n8                         0.000000                          1.252265   \n9                         0.000000                          1.241267   \n10                        0.195752                          3.315888   \n11                        0.196750                          3.269321   \n12                        0.196897                          3.262583   \n13                        0.196220                          3.361192   \n14                        0.196691                          3.305469   \n15                        0.196338                          3.321955   \n16                        0.195752                          3.349800   \n17                        0.195199                          3.376689   \n18                        0.196485                          3.348640   \n19                        0.196015                          3.337212   \n20                             NaN                          4.709135   \n21                             NaN                          5.871129   \n22                             NaN                          5.932768   \n23                             NaN                          6.235544   \n24                             NaN                          5.446710   \n25                             NaN                          5.226323   \n26                             NaN                          5.137238   \n27                             NaN                          5.479720   \n28                             NaN                          4.215169   \n29                             NaN                          5.125589   \n30                        0.044662                          2.863725   \n31                        0.022360                          2.867075   \n32                        0.022365                          2.854462   \n33                        0.045179                          2.805638   \n34                        0.000000                          2.874720   \n35                        0.022088                          2.932623   \n36                        0.022423                          2.851249   \n37                        0.022402                          2.856505   \n38                        0.022409                          2.860155   \n39                        0.000000                          2.865153   \n40                        1.005742                          1.106773   \n41                        0.980157                          1.217978   \n42                        0.959800                          1.597945   \n43                        0.986900                          1.534702   \n44                        0.958626                          1.710149   \n45                        0.941327                          2.501495   \n46                        0.969446                          1.750558   \n47                        0.993150                          1.040927   \n48                        0.938566                          2.419616   \n49                        0.952852                          1.872011   \n\n0   disparate_impact_unfavorable_08  eval_loss  eval_loss_reg        f1   \\\n0                           1.216490  0.0999714     0.00195325  0.979532   \n1                           1.229550  0.0964696     0.00170301  0.980162   \n2                           1.218956   0.096135     0.00170339  0.979024   \n3                           1.233333  0.0976723     0.00068454  0.978661   \n4                           1.214646   0.101506      0.0051132  0.979304   \n5                           1.220812  0.0953438     0.00208066  0.979741   \n6                           1.224542  0.0974008     0.00114924  0.977756   \n7                           1.220812   0.097387     0.00125022  0.979741   \n8                           1.228922  0.0980797     0.00166617  0.979922   \n9                           1.215260  0.0974377     0.00107183  0.980029   \n10                          3.172084   0.181003     0.00156332  0.894061   \n11                          3.129235    0.17613     0.00115695  0.893583   \n12                          3.123032   0.187289     0.00251295  0.893888   \n13                          3.151775   0.172325     0.00207807  0.896000   \n14                          3.131724   0.172687     0.00163858  0.895136   \n15                          3.146738   0.191186     0.00237609  0.892486   \n16                          3.172084    0.17529     0.00173104  0.895265   \n17                          3.196545    0.17495     0.00148337  0.894663   \n18                          3.140465   0.176015      0.0038408  0.895189   \n19                          3.160628   0.175518     0.00196004  0.895654   \n20                               NaN   0.512302    0.000125708  0.367953   \n21                               NaN   0.478205    0.000227692  0.367925   \n22                               NaN   0.486663    0.000135331  0.319079   \n23                               NaN   0.481449    0.000191416  0.344498   \n24                               NaN   0.482666    0.000228928  0.373457   \n25                               NaN    0.47589     0.00024718  0.390840   \n26                               NaN   0.481363    0.000336029  0.367781   \n27                               NaN   0.485075    0.000222666  0.374034   \n28                               NaN   0.487585    0.000171349  0.333868   \n29                               NaN    0.48176    0.000180984  0.350318   \n30                          2.696374   0.236641    0.000604048  0.882915   \n31                          2.729796   0.237011    0.000637262  0.882463   \n32                          2.728666   0.239062     0.00071701  0.882683   \n33                          2.642633   0.236905    0.000770397  0.884424   \n34                          2.771654   0.236357    0.000759042  0.882330   \n35                          2.790458    0.24161    0.000737302  0.879944   \n36                          2.716299   0.237943    0.000798692  0.882347   \n37                          2.720783   0.237766     0.00070964  0.882058   \n38                          2.719100   0.236717    0.000704622  0.883762   \n39                          2.748870   0.241357    0.000962357  0.882203   \n40                          0.729344   0.173504     0.00124599  0.336879   \n41                          1.739554   0.175904     0.00139798  0.367893   \n42                          2.850567   0.185621      0.0013526  0.334213   \n43                          1.386476   0.176066     0.00145537  0.410016   \n44                          2.112128   0.170157    0.000918041  0.426404   \n45                          2.654675   0.182556     0.00281355  0.395689   \n46                          1.955101   0.170997     0.00209113  0.412092   \n47                          1.169387   0.179844     0.00189796  0.394678   \n48                          2.894762   0.188343     0.00255009  0.389241   \n49                          2.523137   0.180435        0.00152  0.391653   \n\n0   fnr_priv_06   ...  warmup_proportion  no_cuda  local_rank  seed  \\\n0       0.026854  ...                0.1    False          -1     0   \n1       0.032609  ...                0.1    False          -1     1   \n2       0.028772  ...                0.1    False          -1     2   \n3       0.036445  ...                0.1    False          -1     3   \n4       0.026215  ...                0.1    False          -1     4   \n5       0.028772  ...                0.1    False          -1     5   \n6       0.033248  ...                0.1    False          -1     6   \n7       0.028772  ...                0.1    False          -1     7   \n8       0.032609  ...                0.1    False          -1     8   \n9       0.026215  ...                0.1    False          -1     9   \n10      0.110647  ...                0.1    False          -1     0   \n11      0.105219  ...                0.1    False          -1     1   \n12      0.103967  ...                0.1    False          -1     2   \n13      0.106472  ...                0.1    False          -1     3   \n14      0.104384  ...                0.1    False          -1     4   \n15      0.108977  ...                0.1    False          -1     5   \n16      0.109812  ...                0.1    False          -1     6   \n17      0.114405  ...                0.1    False          -1     7   \n18      0.105637  ...                0.1    False          -1     8   \n19      0.108142  ...                0.1    False          -1     9   \n20      0.748936  ...                0.1    False          -1     0   \n21      0.763830  ...                0.1    False          -1     1   \n22      0.804255  ...                0.1    False          -1     2   \n23      0.782979  ...                0.1    False          -1     3   \n24      0.755319  ...                0.1    False          -1     4   \n25      0.740426  ...                0.1    False          -1     5   \n26      0.755319  ...                0.1    False          -1     6   \n27      0.755319  ...                0.1    False          -1     7   \n28      0.787234  ...                0.1    False          -1     8   \n29      0.776596  ...                0.1    False          -1     9   \n30      0.166028  ...                0.1    False          -1     0   \n31      0.165177  ...                0.1    False          -1     1   \n32      0.164751  ...                0.1    False          -1     2   \n33      0.155172  ...                0.1    False          -1     3   \n34      0.165815  ...                0.1    False          -1     4   \n35      0.177948  ...                0.1    False          -1     5   \n36      0.163261  ...                0.1    False          -1     6   \n37      0.164325  ...                0.1    False          -1     7   \n38      0.162197  ...                0.1    False          -1     8   \n39      0.162197  ...                0.1    False          -1     9   \n40      0.778046  ...                0.1    False          -1     0   \n41      0.746683  ...                0.1    False          -1     1   \n42      0.782871  ...                0.1    False          -1     2   \n43      0.702051  ...                0.1    False          -1     3   \n44      0.679131  ...                0.1    False          -1     4   \n45      0.712907  ...                0.1    False          -1     5   \n46      0.705669  ...                0.1    False          -1     6   \n47      0.691194  ...                0.1    False          -1     7   \n48      0.722557  ...                0.1    False          -1     8   \n49      0.721351  ...                0.1    False          -1     9   \n\n0   gradient_accumulation_steps   fp16  loss_scale  server_ip  server_port  \\\n0                             1  False           0                           \n1                             1  False           0                           \n2                             1  False           0                           \n3                             1  False           0                           \n4                             1  False           0                           \n5                             1  False           0                           \n6                             1  False           0                           \n7                             1  False           0                           \n8                             1  False           0                           \n9                             1  False           0                           \n10                            1  False           0                           \n11                            1  False           0                           \n12                            1  False           0                           \n13                            1  False           0                           \n14                            1  False           0                           \n15                            1  False           0                           \n16                            1  False           0                           \n17                            1  False           0                           \n18                            1  False           0                           \n19                            1  False           0                           \n20                            1  False           0                           \n21                            1  False           0                           \n22                            1  False           0                           \n23                            1  False           0                           \n24                            1  False           0                           \n25                            1  False           0                           \n26                            1  False           0                           \n27                            1  False           0                           \n28                            1  False           0                           \n29                            1  False           0                           \n30                            1  False           0                           \n31                            1  False           0                           \n32                            1  False           0                           \n33                            1  False           0                           \n34                            1  False           0                           \n35                            1  False           0                           \n36                            1  False           0                           \n37                            1  False           0                           \n38                            1  False           0                           \n39                            1  False           0                           \n40                            1  False           0                           \n41                            1  False           0                           \n42                            1  False           0                           \n43                            1  False           0                           \n44                            1  False           0                           \n45                            1  False           0                           \n46                            1  False           0                           \n47                            1  False           0                           \n48                            1  False           0                           \n49                            1  False           0                           \n\n0   continue_from_checkpoint  \n0                          0  \n1                          0  \n2                          0  \n3                          0  \n4                          0  \n5                          0  \n6                          0  \n7                          0  \n8                          0  \n9                          0  \n10                         0  \n11                         0  \n12                         0  \n13                         0  \n14                         0  \n15                         0  \n16                         0  \n17                         0  \n18                         0  \n19                         0  \n20                         0  \n21                         0  \n22                         0  \n23                         0  \n24                         0  \n25                         0  \n26                         0  \n27                         0  \n28                         0  \n29                         0  \n30                         0  \n31                         0  \n32                         0  \n33                         0  \n34                         0  \n35                         0  \n36                         0  \n37                         0  \n38                         0  \n39                         0  \n40                         0  \n41                         0  \n42                         0  \n43                         0  \n44                         0  \n45                         0  \n46                         0  \n47                         0  \n48                         0  \n49                         0  \n\n[50 rows x 96 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>acc</th>\n      <th>auc_roc</th>\n      <th>disparate_impact_favorable_06</th>\n      <th>disparate_impact_favorable_08</th>\n      <th>disparate_impact_unfavorable_06</th>\n      <th>disparate_impact_unfavorable_08</th>\n      <th>eval_loss</th>\n      <th>eval_loss_reg</th>\n      <th>f1</th>\n      <th>fnr_priv_06</th>\n      <th>...</th>\n      <th>warmup_proportion</th>\n      <th>no_cuda</th>\n      <th>local_rank</th>\n      <th>seed</th>\n      <th>gradient_accumulation_steps</th>\n      <th>fp16</th>\n      <th>loss_scale</th>\n      <th>server_ip</th>\n      <th>server_port</th>\n      <th>continue_from_checkpoint</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.966115</td>\n      <td>0.987726</td>\n      <td>0.103887</td>\n      <td>0.000000</td>\n      <td>1.239538</td>\n      <td>1.216490</td>\n      <td>0.0999714</td>\n      <td>0.00195325</td>\n      <td>0.979532</td>\n      <td>0.026854</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.967326</td>\n      <td>0.987629</td>\n      <td>0.098906</td>\n      <td>0.000000</td>\n      <td>1.256452</td>\n      <td>1.229550</td>\n      <td>0.0964696</td>\n      <td>0.00170301</td>\n      <td>0.980162</td>\n      <td>0.032609</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.965309</td>\n      <td>0.987645</td>\n      <td>0.102900</td>\n      <td>0.000000</td>\n      <td>1.242724</td>\n      <td>1.218956</td>\n      <td>0.096135</td>\n      <td>0.00170339</td>\n      <td>0.979024</td>\n      <td>0.028772</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.964905</td>\n      <td>0.987033</td>\n      <td>0.097569</td>\n      <td>0.000000</td>\n      <td>1.261369</td>\n      <td>1.233333</td>\n      <td>0.0976723</td>\n      <td>0.00068454</td>\n      <td>0.978661</td>\n      <td>0.036445</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.965712</td>\n      <td>0.988146</td>\n      <td>0.104639</td>\n      <td>0.000000</td>\n      <td>1.237159</td>\n      <td>1.214646</td>\n      <td>0.101506</td>\n      <td>0.0051132</td>\n      <td>0.979304</td>\n      <td>0.026215</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>4</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.966519</td>\n      <td>0.986875</td>\n      <td>0.092665</td>\n      <td>0.000000</td>\n      <td>1.248465</td>\n      <td>1.220812</td>\n      <td>0.0953438</td>\n      <td>0.00208066</td>\n      <td>0.979741</td>\n      <td>0.028772</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>5</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.963292</td>\n      <td>0.986479</td>\n      <td>0.100746</td>\n      <td>0.000000</td>\n      <td>1.249954</td>\n      <td>1.224542</td>\n      <td>0.0974008</td>\n      <td>0.00114924</td>\n      <td>0.977756</td>\n      <td>0.033248</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>6</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.966519</td>\n      <td>0.987424</td>\n      <td>0.092665</td>\n      <td>0.000000</td>\n      <td>1.248465</td>\n      <td>1.220812</td>\n      <td>0.097387</td>\n      <td>0.00125022</td>\n      <td>0.979741</td>\n      <td>0.028772</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>7</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.966922</td>\n      <td>0.988082</td>\n      <td>0.108392</td>\n      <td>0.000000</td>\n      <td>1.252265</td>\n      <td>1.228922</td>\n      <td>0.0980797</td>\n      <td>0.00166617</td>\n      <td>0.979922</td>\n      <td>0.032609</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>8</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.966922</td>\n      <td>0.988119</td>\n      <td>0.094669</td>\n      <td>0.000000</td>\n      <td>1.241267</td>\n      <td>1.215260</td>\n      <td>0.0974377</td>\n      <td>0.00107183</td>\n      <td>0.980029</td>\n      <td>0.026215</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>9</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.942584</td>\n      <td>0.970476</td>\n      <td>0.173935</td>\n      <td>0.195752</td>\n      <td>3.315888</td>\n      <td>3.172084</td>\n      <td>0.181003</td>\n      <td>0.00156332</td>\n      <td>0.894061</td>\n      <td>0.110647</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.941931</td>\n      <td>0.970965</td>\n      <td>0.174823</td>\n      <td>0.196750</td>\n      <td>3.269321</td>\n      <td>3.129235</td>\n      <td>0.17613</td>\n      <td>0.00115695</td>\n      <td>0.893583</td>\n      <td>0.105219</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.942040</td>\n      <td>0.969229</td>\n      <td>0.174955</td>\n      <td>0.196897</td>\n      <td>3.262583</td>\n      <td>3.123032</td>\n      <td>0.187289</td>\n      <td>0.00251295</td>\n      <td>0.893888</td>\n      <td>0.103967</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0.943454</td>\n      <td>0.972278</td>\n      <td>0.151060</td>\n      <td>0.196220</td>\n      <td>3.361192</td>\n      <td>3.151775</td>\n      <td>0.172325</td>\n      <td>0.00207807</td>\n      <td>0.896000</td>\n      <td>0.106472</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.942801</td>\n      <td>0.972270</td>\n      <td>0.163095</td>\n      <td>0.196691</td>\n      <td>3.305469</td>\n      <td>3.131724</td>\n      <td>0.172687</td>\n      <td>0.00163858</td>\n      <td>0.895136</td>\n      <td>0.104384</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>4</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0.941496</td>\n      <td>0.969844</td>\n      <td>0.162802</td>\n      <td>0.196338</td>\n      <td>3.321955</td>\n      <td>3.146738</td>\n      <td>0.191186</td>\n      <td>0.00237609</td>\n      <td>0.892486</td>\n      <td>0.108977</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>5</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0.943236</td>\n      <td>0.971196</td>\n      <td>0.162315</td>\n      <td>0.195752</td>\n      <td>3.349800</td>\n      <td>3.172084</td>\n      <td>0.17529</td>\n      <td>0.00173104</td>\n      <td>0.895265</td>\n      <td>0.109812</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>6</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>0.943127</td>\n      <td>0.971430</td>\n      <td>0.161856</td>\n      <td>0.195199</td>\n      <td>3.376689</td>\n      <td>3.196545</td>\n      <td>0.17495</td>\n      <td>0.00148337</td>\n      <td>0.894663</td>\n      <td>0.114405</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>7</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>0.942910</td>\n      <td>0.971802</td>\n      <td>0.151264</td>\n      <td>0.196485</td>\n      <td>3.348640</td>\n      <td>3.140465</td>\n      <td>0.176015</td>\n      <td>0.0038408</td>\n      <td>0.895189</td>\n      <td>0.105637</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>8</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>0.943345</td>\n      <td>0.971342</td>\n      <td>0.162534</td>\n      <td>0.196015</td>\n      <td>3.337212</td>\n      <td>3.160628</td>\n      <td>0.175518</td>\n      <td>0.00196004</td>\n      <td>0.895654</td>\n      <td>0.108142</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>9</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>0.783976</td>\n      <td>0.712576</td>\n      <td>0.596970</td>\n      <td>NaN</td>\n      <td>4.709135</td>\n      <td>NaN</td>\n      <td>0.512302</td>\n      <td>0.000125708</td>\n      <td>0.367953</td>\n      <td>0.748936</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>0.796146</td>\n      <td>0.730093</td>\n      <td>0.584402</td>\n      <td>NaN</td>\n      <td>5.871129</td>\n      <td>NaN</td>\n      <td>0.478205</td>\n      <td>0.000227692</td>\n      <td>0.367925</td>\n      <td>0.763830</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>0.790061</td>\n      <td>0.725043</td>\n      <td>0.658045</td>\n      <td>NaN</td>\n      <td>5.932768</td>\n      <td>NaN</td>\n      <td>0.486663</td>\n      <td>0.000135331</td>\n      <td>0.319079</td>\n      <td>0.804255</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>0.791582</td>\n      <td>0.729048</td>\n      <td>0.581503</td>\n      <td>NaN</td>\n      <td>6.235544</td>\n      <td>NaN</td>\n      <td>0.481449</td>\n      <td>0.000191416</td>\n      <td>0.344498</td>\n      <td>0.782979</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>0.794118</td>\n      <td>0.727370</td>\n      <td>0.588314</td>\n      <td>NaN</td>\n      <td>5.446710</td>\n      <td>NaN</td>\n      <td>0.482666</td>\n      <td>0.000228928</td>\n      <td>0.373457</td>\n      <td>0.755319</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>4</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>0.797667</td>\n      <td>0.730059</td>\n      <td>0.590619</td>\n      <td>NaN</td>\n      <td>5.226323</td>\n      <td>NaN</td>\n      <td>0.47589</td>\n      <td>0.00024718</td>\n      <td>0.390840</td>\n      <td>0.740426</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>5</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>0.789047</td>\n      <td>0.727936</td>\n      <td>0.591613</td>\n      <td>NaN</td>\n      <td>5.137238</td>\n      <td>NaN</td>\n      <td>0.481363</td>\n      <td>0.000336029</td>\n      <td>0.367781</td>\n      <td>0.755319</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>6</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>0.794625</td>\n      <td>0.731095</td>\n      <td>0.587986</td>\n      <td>NaN</td>\n      <td>5.479720</td>\n      <td>NaN</td>\n      <td>0.485075</td>\n      <td>0.000222666</td>\n      <td>0.374034</td>\n      <td>0.755319</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>7</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>0.789554</td>\n      <td>0.730490</td>\n      <td>0.746823</td>\n      <td>NaN</td>\n      <td>4.215169</td>\n      <td>NaN</td>\n      <td>0.487585</td>\n      <td>0.000171349</td>\n      <td>0.333868</td>\n      <td>0.787234</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>8</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>0.793103</td>\n      <td>0.726402</td>\n      <td>0.665308</td>\n      <td>NaN</td>\n      <td>5.125589</td>\n      <td>NaN</td>\n      <td>0.48176</td>\n      <td>0.000180984</td>\n      <td>0.350318</td>\n      <td>0.776596</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>9</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>0.911572</td>\n      <td>0.962585</td>\n      <td>0.058094</td>\n      <td>0.044662</td>\n      <td>2.863725</td>\n      <td>2.696374</td>\n      <td>0.236641</td>\n      <td>0.000604048</td>\n      <td>0.882915</td>\n      <td>0.166028</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>0.911126</td>\n      <td>0.962389</td>\n      <td>0.053104</td>\n      <td>0.022360</td>\n      <td>2.867075</td>\n      <td>2.729796</td>\n      <td>0.237011</td>\n      <td>0.000637262</td>\n      <td>0.882463</td>\n      <td>0.165177</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>0.911275</td>\n      <td>0.961748</td>\n      <td>0.058189</td>\n      <td>0.022365</td>\n      <td>2.854462</td>\n      <td>2.728666</td>\n      <td>0.239062</td>\n      <td>0.00071701</td>\n      <td>0.882683</td>\n      <td>0.164751</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>0.911870</td>\n      <td>0.962238</td>\n      <td>0.056207</td>\n      <td>0.045179</td>\n      <td>2.805638</td>\n      <td>2.642633</td>\n      <td>0.236905</td>\n      <td>0.000770397</td>\n      <td>0.884424</td>\n      <td>0.155172</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>0.911052</td>\n      <td>0.962237</td>\n      <td>0.050552</td>\n      <td>0.000000</td>\n      <td>2.874720</td>\n      <td>2.771654</td>\n      <td>0.236357</td>\n      <td>0.000759042</td>\n      <td>0.882330</td>\n      <td>0.165815</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>4</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>0.910159</td>\n      <td>0.961517</td>\n      <td>0.054963</td>\n      <td>0.022088</td>\n      <td>2.932623</td>\n      <td>2.790458</td>\n      <td>0.24161</td>\n      <td>0.000737302</td>\n      <td>0.879944</td>\n      <td>0.177948</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>5</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>0.910828</td>\n      <td>0.962539</td>\n      <td>0.053254</td>\n      <td>0.022423</td>\n      <td>2.851249</td>\n      <td>2.716299</td>\n      <td>0.237943</td>\n      <td>0.000798692</td>\n      <td>0.882347</td>\n      <td>0.163261</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>6</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>0.910680</td>\n      <td>0.962241</td>\n      <td>0.053204</td>\n      <td>0.022402</td>\n      <td>2.856505</td>\n      <td>2.720783</td>\n      <td>0.237766</td>\n      <td>0.00070964</td>\n      <td>0.882058</td>\n      <td>0.164325</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>7</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>0.911944</td>\n      <td>0.962261</td>\n      <td>0.050683</td>\n      <td>0.022409</td>\n      <td>2.860155</td>\n      <td>2.719100</td>\n      <td>0.236717</td>\n      <td>0.000704622</td>\n      <td>0.883762</td>\n      <td>0.162197</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>8</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>0.910605</td>\n      <td>0.961182</td>\n      <td>0.043156</td>\n      <td>0.000000</td>\n      <td>2.865153</td>\n      <td>2.748870</td>\n      <td>0.241357</td>\n      <td>0.000962357</td>\n      <td>0.882203</td>\n      <td>0.162197</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>9</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>0.939624</td>\n      <td>0.881073</td>\n      <td>0.997749</td>\n      <td>1.005742</td>\n      <td>1.106773</td>\n      <td>0.729344</td>\n      <td>0.173504</td>\n      <td>0.00124599</td>\n      <td>0.336879</td>\n      <td>0.778046</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>0.938978</td>\n      <td>0.881115</td>\n      <td>0.994188</td>\n      <td>0.980157</td>\n      <td>1.217978</td>\n      <td>1.739554</td>\n      <td>0.175904</td>\n      <td>0.00139798</td>\n      <td>0.367893</td>\n      <td>0.746683</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>0.938897</td>\n      <td>0.866282</td>\n      <td>0.987238</td>\n      <td>0.959800</td>\n      <td>1.597945</td>\n      <td>2.850567</td>\n      <td>0.185621</td>\n      <td>0.0013526</td>\n      <td>0.334213</td>\n      <td>0.782871</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>0.939140</td>\n      <td>0.879836</td>\n      <td>0.982287</td>\n      <td>0.986900</td>\n      <td>1.534702</td>\n      <td>1.386476</td>\n      <td>0.176066</td>\n      <td>0.00145537</td>\n      <td>0.410016</td>\n      <td>0.702051</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>0.938978</td>\n      <td>0.888573</td>\n      <td>0.974288</td>\n      <td>0.958626</td>\n      <td>1.710149</td>\n      <td>2.112128</td>\n      <td>0.170157</td>\n      <td>0.000918041</td>\n      <td>0.426404</td>\n      <td>0.679131</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>4</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>0.936637</td>\n      <td>0.872322</td>\n      <td>0.949854</td>\n      <td>0.941327</td>\n      <td>2.501495</td>\n      <td>2.654675</td>\n      <td>0.182556</td>\n      <td>0.00281355</td>\n      <td>0.395689</td>\n      <td>0.712907</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>5</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>0.940350</td>\n      <td>0.885010</td>\n      <td>0.976692</td>\n      <td>0.969446</td>\n      <td>1.750558</td>\n      <td>1.955101</td>\n      <td>0.170997</td>\n      <td>0.00209113</td>\n      <td>0.412092</td>\n      <td>0.705669</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>6</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>0.933893</td>\n      <td>0.877909</td>\n      <td>0.998346</td>\n      <td>0.993150</td>\n      <td>1.040927</td>\n      <td>1.169387</td>\n      <td>0.179844</td>\n      <td>0.00189796</td>\n      <td>0.394678</td>\n      <td>0.691194</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>7</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>0.937687</td>\n      <td>0.861113</td>\n      <td>0.956426</td>\n      <td>0.938566</td>\n      <td>2.419616</td>\n      <td>2.894762</td>\n      <td>0.188343</td>\n      <td>0.00255009</td>\n      <td>0.389241</td>\n      <td>0.722557</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>8</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>0.938817</td>\n      <td>0.874007</td>\n      <td>0.973861</td>\n      <td>0.952852</td>\n      <td>1.872011</td>\n      <td>2.523137</td>\n      <td>0.180435</td>\n      <td>0.00152</td>\n      <td>0.391653</td>\n      <td>0.721351</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>9</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>50 rows × 96 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "0       acc   auc_roc   disparate_impact_favorable_06   \\\n0   0.965295  0.987758                        0.106294   \n1   0.964487  0.987087                        0.096408   \n2   0.966505  0.987930                        0.104129   \n3   0.963680  0.987147                        0.105321   \n4   0.966102  0.987733                        0.126203   \n5   0.964084  0.987243                        0.124755   \n6   0.965295  0.987755                        0.103894   \n7   0.964487  0.987062                        0.131339   \n8   0.964084  0.986975                        0.103195   \n9   0.964891  0.988663                        0.104129   \n10  0.938010  0.970347                        0.165680   \n11  0.939424  0.971938                        0.185643   \n12  0.937575  0.971353                        0.184895   \n13  0.939315  0.972198                        0.185338   \n14  0.938227  0.972311                        0.167534   \n15  0.937575  0.971030                        0.184784   \n16  0.938989  0.971537                        0.175899   \n17  0.939097  0.971100                        0.185449   \n18  0.939097  0.971429                        0.194772   \n19  0.938771  0.972070                        0.185922   \n20  0.787018  0.716490                        0.798807   \n21  0.787525  0.715662                        0.806240   \n22  0.784990  0.711523                        0.787701   \n23  0.787018  0.719421                        0.927415   \n24  0.787525  0.715189                        0.799240   \n25  0.794118  0.719366                        0.804039   \n26  0.786004  0.719816                        0.792788   \n27  0.789047  0.714468                        0.925417   \n28  0.786511  0.713584                        0.784763   \n29  0.788540  0.720048                        0.931941   \n30  0.906366  0.958538                        0.077737   \n31  0.906069  0.958360                        0.079855   \n32  0.905251  0.957898                        0.077139   \n33  0.906515  0.958258                        0.086418   \n34  0.906292  0.957965                        0.072396   \n35  0.905102  0.957635                        0.079562   \n36  0.905474  0.957827                        0.072731   \n37  0.906961  0.957603                        0.084152   \n38  0.906292  0.958108                        0.077212   \n39  0.904581  0.956643                        0.073061   \n40  0.941561  0.890262                        1.018049   \n41  0.939462  0.889733                        1.019387   \n42  0.939705  0.881891                        1.019798   \n43  0.940431  0.888950                        1.017898   \n44  0.942045  0.897334                        1.016724   \n45  0.940189  0.886554                        1.020964   \n46  0.941561  0.890775                        1.016152   \n47  0.939624  0.890483                        1.017114   \n48  0.940512  0.883947                        1.016948   \n49  0.940512  0.886373                        1.020151   \n\n0   disparate_impact_favorable_08   disparate_impact_unfavorable_06   \\\n0                         0.103284                          1.246953   \n1                         0.103284                          1.250421   \n2                         0.101227                          1.254156   \n3                         0.102360                          1.250144   \n4                         0.103284                          1.240030   \n5                         0.102131                          1.243994   \n6                         0.101004                          1.254961   \n7                         0.099683                          1.249307   \n8                         0.100339                          1.257384   \n9                         0.101227                          1.254156   \n10                        0.137069                          3.352354   \n11                        0.137377                          3.273924   \n12                        0.136824                          3.311364   \n13                        0.137151                          3.289074   \n14                        0.138600                          3.250892   \n15                        0.136743                          3.316983   \n16                        0.137418                          3.299824   \n17                        0.137233                          3.283549   \n18                        0.136906                          3.276829   \n19                        0.137582                          3.260271   \n20                        1.065982                          4.091667   \n21                        1.075873                          3.583942   \n22                        1.051200                          5.223404   \n23                        1.060247                          2.211712   \n24                        1.066558                          4.057851   \n25                        1.072945                          3.719697   \n26                        1.057971                          4.632075   \n27                        1.057971                          2.294393   \n28                        1.047290                          5.643678   \n29                        1.065405                          2.045833   \n30                        0.020105                          2.751756   \n31                        0.020043                          2.762930   \n32                        0.019951                          2.792883   \n33                        0.019925                          2.779192   \n34                        0.019937                          2.807130   \n35                        0.019970                          2.782584   \n36                        0.020029                          2.782135   \n37                        0.019944                          2.779260   \n38                        0.019970                          2.787755   \n39                        0.020119                          2.758205   \n40                        1.020794                          0.162362   \n41                        1.023847                          0.213529   \n42                        1.020709                          0.081181   \n43                        1.024188                          0.281729   \n44                        1.018296                          0.514352   \n45                        1.023592                          0.143362   \n46                        1.026064                          0.395063   \n47                        1.025210                          0.339162   \n48                        1.026833                          0.383811   \n49                        1.021047                          0.079897   \n\n0   disparate_impact_unfavorable_08  eval_loss  eval_loss_reg        f1   \\\n0                           1.200426    0.10094     0.00204131  0.978891   \n1                           1.200426   0.099727    0.000982749  0.978400   \n2                           1.205902  0.0993027     0.00160624  0.979582   \n3                           1.202854  0.0998649     0.00103324  0.977887   \n4                           1.200426   0.101016    0.000921663  0.979381   \n5                           1.203462   0.106123     0.00130386  0.978127   \n6                           1.206514  0.0975835    0.000807614  0.978839   \n7                           1.210196   0.105875     0.00120875  0.978314   \n8                           1.208352   0.099333    0.000871331  0.978084   \n9                           1.205902  0.0984128     0.00103632  0.978598   \n10                          3.327899   0.181464     0.00174177  0.886680   \n11                          3.307923   0.178799     0.00145987  0.889594   \n12                          3.344053   0.181092     0.00290538  0.885612   \n13                          3.322548   0.175996     0.00169562  0.889154   \n14                          3.231626   0.178759     0.00236014  0.888715   \n15                          3.349473   0.183639     0.00231261  0.885521   \n16                          3.305278   0.181213     0.00279381  0.888845   \n17                          3.317215   0.179498      0.0020573  0.888845   \n18                          3.338651   0.178631     0.00367405  0.888491   \n19                          3.294739   0.179011     0.00152345  0.888625   \n20                          0.000000   0.487529    0.000172956  0.297659   \n21                          0.000000   0.485205     0.00022638  0.318699   \n22                          0.000000   0.492457     0.00011621  0.258741   \n23                          0.000000   0.485857    0.000155651  0.285714   \n24                          0.000000   0.488415    0.000152862  0.300501   \n25                          0.000000   0.481753    0.000181665  0.334426   \n26                          0.000000   0.486377    0.000164636  0.277397   \n27                          0.000000   0.487352    0.000162637  0.287671   \n28                          0.000000   0.490745    0.000130564  0.254867   \n29                          0.000000   0.485248    0.000129208  0.301508   \n30                          2.665683   0.250352    0.000700025  0.877731   \n31                          2.679756   0.249929    0.000664875  0.877032   \n32                          2.701146   0.251445    0.000693232  0.875489   \n33                          2.707241   0.250515    0.000669489  0.877018   \n34                          2.704467    0.24986    0.000899872  0.876785   \n35                          2.696730   0.251632    0.000789373  0.875391   \n36                          2.683024   0.251656    0.000837393  0.876181   \n37                          2.702805   0.250375    0.000881897  0.877701   \n38                          2.696730   0.250065    0.000742273  0.876953   \n39                          2.662457   0.254926     0.00103504  0.875473   \n40                          0.000000    0.16842     0.00137646  0.354724   \n41                          0.000000   0.169288     0.00119978  0.352332   \n42                          0.000000   0.173054      0.0014121  0.333631   \n43                          0.000000   0.169068    0.000914111  0.364888   \n44                          0.457489   0.161934     0.00129005  0.436421   \n45                          0.000000   0.170917     0.00115452  0.358442   \n46                          0.000000   0.165857     0.00091965  0.388514   \n47                          0.000000     0.1684       0.001359  0.362862   \n48                          0.000000   0.172867     0.00126273  0.382230   \n49                          0.000000   0.170974     0.00102733  0.344889   \n\n0   fnr_priv_06   ...  warmup_proportion  no_cuda  local_rank  seed  \\\n0       0.027937  ...                0.1    False          -1     0   \n1       0.028571  ...                0.1    False          -1     1   \n2       0.029841  ...                0.1    False          -1     2   \n3       0.030476  ...                0.1    False          -1     3   \n4       0.027302  ...                0.1    False          -1     4   \n5       0.029841  ...                0.1    False          -1     5   \n6       0.031111  ...                0.1    False          -1     6   \n7       0.033016  ...                0.1    False          -1     7   \n8       0.033016  ...                0.1    False          -1     8   \n9       0.031111  ...                0.1    False          -1     9   \n10      0.126755  ...                0.1    False          -1     0   \n11      0.120149  ...                0.1    False          -1     1   \n12      0.128819  ...                0.1    False          -1     2   \n13      0.122213  ...                0.1    False          -1     3   \n14      0.110652  ...                0.1    False          -1     4   \n15      0.129645  ...                0.1    False          -1     5   \n16      0.120562  ...                0.1    False          -1     6   \n17      0.122213  ...                0.1    False          -1     7   \n18      0.125516  ...                0.1    False          -1     8   \n19      0.118910  ...                0.1    False          -1     9   \n20      0.815287  ...                0.1    False          -1     0   \n21      0.796178  ...                0.1    False          -1     1   \n22      0.847134  ...                0.1    False          -1     2   \n23      0.823779  ...                0.1    False          -1     3   \n24      0.813163  ...                0.1    False          -1     4   \n25      0.787686  ...                0.1    False          -1     5   \n26      0.832272  ...                0.1    False          -1     6   \n27      0.823779  ...                0.1    False          -1     7   \n28      0.851380  ...                0.1    False          -1     8   \n29      0.811040  ...                0.1    False          -1     9   \n30      0.158696  ...                0.1    False          -1     0   \n31      0.162127  ...                0.1    False          -1     1   \n32      0.167489  ...                0.1    False          -1     2   \n33      0.166631  ...                0.1    False          -1     3   \n34      0.166845  ...                0.1    False          -1     4   \n35      0.166631  ...                0.1    False          -1     5   \n36      0.163843  ...                0.1    False          -1     6   \n37      0.165130  ...                0.1    False          -1     7   \n38      0.165130  ...                0.1    False          -1     8   \n39      0.161055  ...                0.1    False          -1     9   \n40      0.763221  ...                0.1    False          -1     0   \n41      0.757212  ...                0.1    False          -1     1   \n42      0.775240  ...                0.1    False          -1     2   \n43      0.747596  ...                0.1    False          -1     3   \n44      0.673077  ...                0.1    False          -1     4   \n45      0.753606  ...                0.1    False          -1     5   \n46      0.727163  ...                0.1    False          -1     6   \n47      0.747596  ...                0.1    False          -1     7   \n48      0.730769  ...                0.1    False          -1     8   \n49      0.768029  ...                0.1    False          -1     9   \n\n0   gradient_accumulation_steps   fp16  loss_scale  server_ip  server_port  \\\n0                             1  False           0                           \n1                             1  False           0                           \n2                             1  False           0                           \n3                             1  False           0                           \n4                             1  False           0                           \n5                             1  False           0                           \n6                             1  False           0                           \n7                             1  False           0                           \n8                             1  False           0                           \n9                             1  False           0                           \n10                            1  False           0                           \n11                            1  False           0                           \n12                            1  False           0                           \n13                            1  False           0                           \n14                            1  False           0                           \n15                            1  False           0                           \n16                            1  False           0                           \n17                            1  False           0                           \n18                            1  False           0                           \n19                            1  False           0                           \n20                            1  False           0                           \n21                            1  False           0                           \n22                            1  False           0                           \n23                            1  False           0                           \n24                            1  False           0                           \n25                            1  False           0                           \n26                            1  False           0                           \n27                            1  False           0                           \n28                            1  False           0                           \n29                            1  False           0                           \n30                            1  False           0                           \n31                            1  False           0                           \n32                            1  False           0                           \n33                            1  False           0                           \n34                            1  False           0                           \n35                            1  False           0                           \n36                            1  False           0                           \n37                            1  False           0                           \n38                            1  False           0                           \n39                            1  False           0                           \n40                            1  False           0                           \n41                            1  False           0                           \n42                            1  False           0                           \n43                            1  False           0                           \n44                            1  False           0                           \n45                            1  False           0                           \n46                            1  False           0                           \n47                            1  False           0                           \n48                            1  False           0                           \n49                            1  False           0                           \n\n0   continue_from_checkpoint  \n0                          0  \n1                          0  \n2                          0  \n3                          0  \n4                          0  \n5                          0  \n6                          0  \n7                          0  \n8                          0  \n9                          0  \n10                         0  \n11                         0  \n12                         0  \n13                         0  \n14                         0  \n15                         0  \n16                         0  \n17                         0  \n18                         0  \n19                         0  \n20                         0  \n21                         0  \n22                         0  \n23                         0  \n24                         0  \n25                         0  \n26                         0  \n27                         0  \n28                         0  \n29                         0  \n30                         0  \n31                         0  \n32                         0  \n33                         0  \n34                         0  \n35                         0  \n36                         0  \n37                         0  \n38                         0  \n39                         0  \n40                         0  \n41                         0  \n42                         0  \n43                         0  \n44                         0  \n45                         0  \n46                         0  \n47                         0  \n48                         0  \n49                         0  \n\n[50 rows x 96 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>acc</th>\n      <th>auc_roc</th>\n      <th>disparate_impact_favorable_06</th>\n      <th>disparate_impact_favorable_08</th>\n      <th>disparate_impact_unfavorable_06</th>\n      <th>disparate_impact_unfavorable_08</th>\n      <th>eval_loss</th>\n      <th>eval_loss_reg</th>\n      <th>f1</th>\n      <th>fnr_priv_06</th>\n      <th>...</th>\n      <th>warmup_proportion</th>\n      <th>no_cuda</th>\n      <th>local_rank</th>\n      <th>seed</th>\n      <th>gradient_accumulation_steps</th>\n      <th>fp16</th>\n      <th>loss_scale</th>\n      <th>server_ip</th>\n      <th>server_port</th>\n      <th>continue_from_checkpoint</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.965295</td>\n      <td>0.987758</td>\n      <td>0.106294</td>\n      <td>0.103284</td>\n      <td>1.246953</td>\n      <td>1.200426</td>\n      <td>0.10094</td>\n      <td>0.00204131</td>\n      <td>0.978891</td>\n      <td>0.027937</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.964487</td>\n      <td>0.987087</td>\n      <td>0.096408</td>\n      <td>0.103284</td>\n      <td>1.250421</td>\n      <td>1.200426</td>\n      <td>0.099727</td>\n      <td>0.000982749</td>\n      <td>0.978400</td>\n      <td>0.028571</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.966505</td>\n      <td>0.987930</td>\n      <td>0.104129</td>\n      <td>0.101227</td>\n      <td>1.254156</td>\n      <td>1.205902</td>\n      <td>0.0993027</td>\n      <td>0.00160624</td>\n      <td>0.979582</td>\n      <td>0.029841</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.963680</td>\n      <td>0.987147</td>\n      <td>0.105321</td>\n      <td>0.102360</td>\n      <td>1.250144</td>\n      <td>1.202854</td>\n      <td>0.0998649</td>\n      <td>0.00103324</td>\n      <td>0.977887</td>\n      <td>0.030476</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.966102</td>\n      <td>0.987733</td>\n      <td>0.126203</td>\n      <td>0.103284</td>\n      <td>1.240030</td>\n      <td>1.200426</td>\n      <td>0.101016</td>\n      <td>0.000921663</td>\n      <td>0.979381</td>\n      <td>0.027302</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>4</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.964084</td>\n      <td>0.987243</td>\n      <td>0.124755</td>\n      <td>0.102131</td>\n      <td>1.243994</td>\n      <td>1.203462</td>\n      <td>0.106123</td>\n      <td>0.00130386</td>\n      <td>0.978127</td>\n      <td>0.029841</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>5</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.965295</td>\n      <td>0.987755</td>\n      <td>0.103894</td>\n      <td>0.101004</td>\n      <td>1.254961</td>\n      <td>1.206514</td>\n      <td>0.0975835</td>\n      <td>0.000807614</td>\n      <td>0.978839</td>\n      <td>0.031111</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>6</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.964487</td>\n      <td>0.987062</td>\n      <td>0.131339</td>\n      <td>0.099683</td>\n      <td>1.249307</td>\n      <td>1.210196</td>\n      <td>0.105875</td>\n      <td>0.00120875</td>\n      <td>0.978314</td>\n      <td>0.033016</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>7</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.964084</td>\n      <td>0.986975</td>\n      <td>0.103195</td>\n      <td>0.100339</td>\n      <td>1.257384</td>\n      <td>1.208352</td>\n      <td>0.099333</td>\n      <td>0.000871331</td>\n      <td>0.978084</td>\n      <td>0.033016</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>8</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.964891</td>\n      <td>0.988663</td>\n      <td>0.104129</td>\n      <td>0.101227</td>\n      <td>1.254156</td>\n      <td>1.205902</td>\n      <td>0.0984128</td>\n      <td>0.00103632</td>\n      <td>0.978598</td>\n      <td>0.031111</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>9</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.938010</td>\n      <td>0.970347</td>\n      <td>0.165680</td>\n      <td>0.137069</td>\n      <td>3.352354</td>\n      <td>3.327899</td>\n      <td>0.181464</td>\n      <td>0.00174177</td>\n      <td>0.886680</td>\n      <td>0.126755</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.939424</td>\n      <td>0.971938</td>\n      <td>0.185643</td>\n      <td>0.137377</td>\n      <td>3.273924</td>\n      <td>3.307923</td>\n      <td>0.178799</td>\n      <td>0.00145987</td>\n      <td>0.889594</td>\n      <td>0.120149</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.937575</td>\n      <td>0.971353</td>\n      <td>0.184895</td>\n      <td>0.136824</td>\n      <td>3.311364</td>\n      <td>3.344053</td>\n      <td>0.181092</td>\n      <td>0.00290538</td>\n      <td>0.885612</td>\n      <td>0.128819</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0.939315</td>\n      <td>0.972198</td>\n      <td>0.185338</td>\n      <td>0.137151</td>\n      <td>3.289074</td>\n      <td>3.322548</td>\n      <td>0.175996</td>\n      <td>0.00169562</td>\n      <td>0.889154</td>\n      <td>0.122213</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.938227</td>\n      <td>0.972311</td>\n      <td>0.167534</td>\n      <td>0.138600</td>\n      <td>3.250892</td>\n      <td>3.231626</td>\n      <td>0.178759</td>\n      <td>0.00236014</td>\n      <td>0.888715</td>\n      <td>0.110652</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>4</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0.937575</td>\n      <td>0.971030</td>\n      <td>0.184784</td>\n      <td>0.136743</td>\n      <td>3.316983</td>\n      <td>3.349473</td>\n      <td>0.183639</td>\n      <td>0.00231261</td>\n      <td>0.885521</td>\n      <td>0.129645</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>5</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0.938989</td>\n      <td>0.971537</td>\n      <td>0.175899</td>\n      <td>0.137418</td>\n      <td>3.299824</td>\n      <td>3.305278</td>\n      <td>0.181213</td>\n      <td>0.00279381</td>\n      <td>0.888845</td>\n      <td>0.120562</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>6</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>0.939097</td>\n      <td>0.971100</td>\n      <td>0.185449</td>\n      <td>0.137233</td>\n      <td>3.283549</td>\n      <td>3.317215</td>\n      <td>0.179498</td>\n      <td>0.0020573</td>\n      <td>0.888845</td>\n      <td>0.122213</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>7</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>0.939097</td>\n      <td>0.971429</td>\n      <td>0.194772</td>\n      <td>0.136906</td>\n      <td>3.276829</td>\n      <td>3.338651</td>\n      <td>0.178631</td>\n      <td>0.00367405</td>\n      <td>0.888491</td>\n      <td>0.125516</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>8</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>0.938771</td>\n      <td>0.972070</td>\n      <td>0.185922</td>\n      <td>0.137582</td>\n      <td>3.260271</td>\n      <td>3.294739</td>\n      <td>0.179011</td>\n      <td>0.00152345</td>\n      <td>0.888625</td>\n      <td>0.118910</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>9</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>0.787018</td>\n      <td>0.716490</td>\n      <td>0.798807</td>\n      <td>1.065982</td>\n      <td>4.091667</td>\n      <td>0.000000</td>\n      <td>0.487529</td>\n      <td>0.000172956</td>\n      <td>0.297659</td>\n      <td>0.815287</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>0.787525</td>\n      <td>0.715662</td>\n      <td>0.806240</td>\n      <td>1.075873</td>\n      <td>3.583942</td>\n      <td>0.000000</td>\n      <td>0.485205</td>\n      <td>0.00022638</td>\n      <td>0.318699</td>\n      <td>0.796178</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>0.784990</td>\n      <td>0.711523</td>\n      <td>0.787701</td>\n      <td>1.051200</td>\n      <td>5.223404</td>\n      <td>0.000000</td>\n      <td>0.492457</td>\n      <td>0.00011621</td>\n      <td>0.258741</td>\n      <td>0.847134</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>0.787018</td>\n      <td>0.719421</td>\n      <td>0.927415</td>\n      <td>1.060247</td>\n      <td>2.211712</td>\n      <td>0.000000</td>\n      <td>0.485857</td>\n      <td>0.000155651</td>\n      <td>0.285714</td>\n      <td>0.823779</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>0.787525</td>\n      <td>0.715189</td>\n      <td>0.799240</td>\n      <td>1.066558</td>\n      <td>4.057851</td>\n      <td>0.000000</td>\n      <td>0.488415</td>\n      <td>0.000152862</td>\n      <td>0.300501</td>\n      <td>0.813163</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>4</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>0.794118</td>\n      <td>0.719366</td>\n      <td>0.804039</td>\n      <td>1.072945</td>\n      <td>3.719697</td>\n      <td>0.000000</td>\n      <td>0.481753</td>\n      <td>0.000181665</td>\n      <td>0.334426</td>\n      <td>0.787686</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>5</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>0.786004</td>\n      <td>0.719816</td>\n      <td>0.792788</td>\n      <td>1.057971</td>\n      <td>4.632075</td>\n      <td>0.000000</td>\n      <td>0.486377</td>\n      <td>0.000164636</td>\n      <td>0.277397</td>\n      <td>0.832272</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>6</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>0.789047</td>\n      <td>0.714468</td>\n      <td>0.925417</td>\n      <td>1.057971</td>\n      <td>2.294393</td>\n      <td>0.000000</td>\n      <td>0.487352</td>\n      <td>0.000162637</td>\n      <td>0.287671</td>\n      <td>0.823779</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>7</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>0.786511</td>\n      <td>0.713584</td>\n      <td>0.784763</td>\n      <td>1.047290</td>\n      <td>5.643678</td>\n      <td>0.000000</td>\n      <td>0.490745</td>\n      <td>0.000130564</td>\n      <td>0.254867</td>\n      <td>0.851380</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>8</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>0.788540</td>\n      <td>0.720048</td>\n      <td>0.931941</td>\n      <td>1.065405</td>\n      <td>2.045833</td>\n      <td>0.000000</td>\n      <td>0.485248</td>\n      <td>0.000129208</td>\n      <td>0.301508</td>\n      <td>0.811040</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>9</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>0.906366</td>\n      <td>0.958538</td>\n      <td>0.077737</td>\n      <td>0.020105</td>\n      <td>2.751756</td>\n      <td>2.665683</td>\n      <td>0.250352</td>\n      <td>0.000700025</td>\n      <td>0.877731</td>\n      <td>0.158696</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>0.906069</td>\n      <td>0.958360</td>\n      <td>0.079855</td>\n      <td>0.020043</td>\n      <td>2.762930</td>\n      <td>2.679756</td>\n      <td>0.249929</td>\n      <td>0.000664875</td>\n      <td>0.877032</td>\n      <td>0.162127</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>0.905251</td>\n      <td>0.957898</td>\n      <td>0.077139</td>\n      <td>0.019951</td>\n      <td>2.792883</td>\n      <td>2.701146</td>\n      <td>0.251445</td>\n      <td>0.000693232</td>\n      <td>0.875489</td>\n      <td>0.167489</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>0.906515</td>\n      <td>0.958258</td>\n      <td>0.086418</td>\n      <td>0.019925</td>\n      <td>2.779192</td>\n      <td>2.707241</td>\n      <td>0.250515</td>\n      <td>0.000669489</td>\n      <td>0.877018</td>\n      <td>0.166631</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>0.906292</td>\n      <td>0.957965</td>\n      <td>0.072396</td>\n      <td>0.019937</td>\n      <td>2.807130</td>\n      <td>2.704467</td>\n      <td>0.24986</td>\n      <td>0.000899872</td>\n      <td>0.876785</td>\n      <td>0.166845</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>4</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>0.905102</td>\n      <td>0.957635</td>\n      <td>0.079562</td>\n      <td>0.019970</td>\n      <td>2.782584</td>\n      <td>2.696730</td>\n      <td>0.251632</td>\n      <td>0.000789373</td>\n      <td>0.875391</td>\n      <td>0.166631</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>5</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>0.905474</td>\n      <td>0.957827</td>\n      <td>0.072731</td>\n      <td>0.020029</td>\n      <td>2.782135</td>\n      <td>2.683024</td>\n      <td>0.251656</td>\n      <td>0.000837393</td>\n      <td>0.876181</td>\n      <td>0.163843</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>6</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>0.906961</td>\n      <td>0.957603</td>\n      <td>0.084152</td>\n      <td>0.019944</td>\n      <td>2.779260</td>\n      <td>2.702805</td>\n      <td>0.250375</td>\n      <td>0.000881897</td>\n      <td>0.877701</td>\n      <td>0.165130</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>7</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>0.906292</td>\n      <td>0.958108</td>\n      <td>0.077212</td>\n      <td>0.019970</td>\n      <td>2.787755</td>\n      <td>2.696730</td>\n      <td>0.250065</td>\n      <td>0.000742273</td>\n      <td>0.876953</td>\n      <td>0.165130</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>8</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>0.904581</td>\n      <td>0.956643</td>\n      <td>0.073061</td>\n      <td>0.020119</td>\n      <td>2.758205</td>\n      <td>2.662457</td>\n      <td>0.254926</td>\n      <td>0.00103504</td>\n      <td>0.875473</td>\n      <td>0.161055</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>9</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>0.941561</td>\n      <td>0.890262</td>\n      <td>1.018049</td>\n      <td>1.020794</td>\n      <td>0.162362</td>\n      <td>0.000000</td>\n      <td>0.16842</td>\n      <td>0.00137646</td>\n      <td>0.354724</td>\n      <td>0.763221</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>0.939462</td>\n      <td>0.889733</td>\n      <td>1.019387</td>\n      <td>1.023847</td>\n      <td>0.213529</td>\n      <td>0.000000</td>\n      <td>0.169288</td>\n      <td>0.00119978</td>\n      <td>0.352332</td>\n      <td>0.757212</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>0.939705</td>\n      <td>0.881891</td>\n      <td>1.019798</td>\n      <td>1.020709</td>\n      <td>0.081181</td>\n      <td>0.000000</td>\n      <td>0.173054</td>\n      <td>0.0014121</td>\n      <td>0.333631</td>\n      <td>0.775240</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>0.940431</td>\n      <td>0.888950</td>\n      <td>1.017898</td>\n      <td>1.024188</td>\n      <td>0.281729</td>\n      <td>0.000000</td>\n      <td>0.169068</td>\n      <td>0.000914111</td>\n      <td>0.364888</td>\n      <td>0.747596</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>0.942045</td>\n      <td>0.897334</td>\n      <td>1.016724</td>\n      <td>1.018296</td>\n      <td>0.514352</td>\n      <td>0.457489</td>\n      <td>0.161934</td>\n      <td>0.00129005</td>\n      <td>0.436421</td>\n      <td>0.673077</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>4</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>0.940189</td>\n      <td>0.886554</td>\n      <td>1.020964</td>\n      <td>1.023592</td>\n      <td>0.143362</td>\n      <td>0.000000</td>\n      <td>0.170917</td>\n      <td>0.00115452</td>\n      <td>0.358442</td>\n      <td>0.753606</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>5</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>0.941561</td>\n      <td>0.890775</td>\n      <td>1.016152</td>\n      <td>1.026064</td>\n      <td>0.395063</td>\n      <td>0.000000</td>\n      <td>0.165857</td>\n      <td>0.00091965</td>\n      <td>0.388514</td>\n      <td>0.727163</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>6</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>0.939624</td>\n      <td>0.890483</td>\n      <td>1.017114</td>\n      <td>1.025210</td>\n      <td>0.339162</td>\n      <td>0.000000</td>\n      <td>0.1684</td>\n      <td>0.001359</td>\n      <td>0.362862</td>\n      <td>0.747596</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>7</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>0.940512</td>\n      <td>0.883947</td>\n      <td>1.016948</td>\n      <td>1.026833</td>\n      <td>0.383811</td>\n      <td>0.000000</td>\n      <td>0.172867</td>\n      <td>0.00126273</td>\n      <td>0.382230</td>\n      <td>0.730769</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>8</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>0.940512</td>\n      <td>0.886373</td>\n      <td>1.020151</td>\n      <td>1.021047</td>\n      <td>0.079897</td>\n      <td>0.000000</td>\n      <td>0.170974</td>\n      <td>0.00102733</td>\n      <td>0.344889</td>\n      <td>0.768029</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>-1</td>\n      <td>9</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>50 rows × 96 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_val"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def ci_sample(series):\n",
    "    pop_mean = series.mean()\n",
    "    pop_std = series.std(ddof=0)\n",
    "    pop_n =  len(series) - 1\n",
    "    return pop_mean - (1.96*pop_std/math.sqrt(pop_n)), pop_mean + (1.96*pop_std/math.sqrt(pop_n))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "0\nacc                                 float64\nauc_roc                             float64\ndisparate_impact_favorable_06       float64\ndisparate_impact_favorable_08       float64\ndisparate_impact_unfavorable_06     float64\n                                     ...   \nfp16                                 object\nloss_scale                           object\nserver_ip                            object\nserver_port                          object\ncontinue_from_checkpoint             object\nLength: 96, dtype: object"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_val.dtypes\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['acc ', 'auc_roc ', 'disparate_impact_favorable_06 ',\n       'disparate_impact_favorable_08 ',\n       'disparate_impact_unfavorable_06 ',\n       'disparate_impact_unfavorable_08 ', 'eval_loss ', 'eval_loss_reg ',\n       'f1 ', 'fnr_priv_06 ', 'fnr_priv_08 ', 'fnr_total_06 ',\n       'fnr_total_08 ', 'fnr_unpriv_06 ', 'fnr_unpriv_08 ',\n       'fpr_priv_06 ', 'fpr_priv_08 ', 'fpr_total_06 ', 'fpr_total_08 ',\n       'fpr_unpriv_06 ', 'fpr_unpriv_08 ', 'global_step ', 'loss ',\n       'precision ', 'priv_n_06 ', 'priv_n_08 ',\n       'priv_ratio_favorable_06 ', 'priv_ratio_favorable_08 ',\n       'priv_ratio_unfavorable_06 ', 'priv_ratio_unfavorable_08 ',\n       'priv_total_06 ', 'priv_total_08 ', 'recall ', 'unpriv_n_06 ',\n       'unpriv_n_08 ', 'unpriv_ratio_favorable_06 ',\n       'unpriv_ratio_favorable_08 ', 'unpriv_ratio_unfavorable_06 ',\n       'unpriv_ratio_unfavorable_08 ', 'unpriv_total_06 ',\n       'unpriv_total_08 ', 'raw_data_path', 'data_dir', 'label_groups',\n       'gab_label', 'do_lower_case', 'bert_model', 'lm_model_dir',\n       'lm_d_hidden', 'lm_d_embed', 'batch_size', 'nb_range', 'sample_n',\n       'max_seq_length', 'mask_outside_nb', 'use_padding_variant',\n       'neutral_words_file', 'reg_mse', 'reg_strength', 'keep_other_nw',\n       'remove_nw', 'task_name', 'output_dir', 'is_gridsearch',\n       'negative_weight', 'test', 'explain', 'debug', 'output_filename',\n       'reg_explanations', 'hiex', 'hiex_tree_height', 'hiex_add_itself',\n       'lm_dir', 'hiex_abs', 'only_positive', 'only_negative', 'stop',\n       'early_stop', 'cache_dir', 'do_train', 'do_eval',\n       'train_batch_size', 'eval_batch_size', 'learning_rate',\n       'num_train_epochs', 'warmup_proportion', 'no_cuda', 'local_rank',\n       'seed', 'gradient_accumulation_steps', 'fp16', 'loss_scale',\n       'server_ip', 'server_port', 'continue_from_checkpoint'],\n      dtype=object)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_val.columns.values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "    task_name  acc_mean   acc_std                                    acc_ci  \\\n0    davidson  0.964891  0.000912  (0.9643255674367032, 0.9654565148877517)   \n1      founta  0.938608  0.000703  (0.9381719600949064, 0.9390439180997646)   \n2     golbeck  0.787830  0.002498  (0.7862813177800356, 0.7893779114288895)   \n3  harassment  0.905890  0.000748  (0.9054266121976088, 0.9063538429563406)   \n4        hate  0.940560  0.000893  (0.9400064824536417, 0.9411138662427826)   \n\n   auc_roc_mean  auc_roc_std                                auc_roc_ci  \\\n0      0.987535     0.000531    (0.98720603990394, 0.9878644677511768)   \n1      0.971531     0.000614  (0.9711507809760194, 0.9719114592977873)   \n2      0.716557     0.002984  (0.7147074630110294, 0.7184060497737638)   \n3      0.957883     0.000531  (0.9575544396961145, 0.9582122648892007)   \n4      0.888630     0.004276  (0.8859801829504511, 0.8912802284975913)   \n\n    f1_mean    f1_std                                     f1_ci  ...  \\\n0  0.978610  0.000561  (0.9782624372862306, 0.9789580984206189)  ...   \n1  0.888008  0.001492  (0.8870832458020063, 0.8889327158800272)  ...   \n2  0.291718  0.024638  (0.2764477266267267, 0.3069890625798135)  ...   \n3  0.876575  0.000891  (0.8760229889945704, 0.8771277709502489)  ...   \n4  0.367893  0.029000    (0.3499184885440008, 0.38586760965339)  ...   \n\n   fpr_unpriv_06_mean  fpr_unpriv_06_std  \\\n0            0.276923           0.074315   \n1            0.312500           0.029463   \n2            0.000000           0.000000   \n3            0.413953           0.032521   \n4            0.002752           0.002484   \n\n                                fpr_unpriv_06_ci  fpr_unpriv_08_mean  \\\n0     (0.23086231609172592, 0.32298383775442796)                 0.0   \n1       (0.2942387781837517, 0.3307612218162483)                 0.0   \n2                                     (0.0, 0.0)                 0.0   \n3       (0.3937966369330339, 0.4341103398111522)                 0.8   \n4  (0.0012124369508144555, 0.004292150205148847)                 0.0   \n\n   fpr_unpriv_08_std fpr_unpriv_08_ci  priv_n_06  priv_n_08 unpriv_n_06  \\\n0                0.0       (0.0, 0.0)     2000.0     2425.0       478.0   \n1                0.0       (0.0, 0.0)     9056.0     9185.0       139.0   \n2                0.0       (0.0, 0.0)     1964.0     1971.0         8.0   \n3                0.0       (0.8, 0.8)    12798.0    13367.0       648.0   \n4                0.0       (0.0, 0.0)    11805.0    12322.0       584.0   \n\n   unpriv_n_08  \n0         53.0  \n1         10.0  \n2          1.0  \n3         79.0  \n4         67.0  \n\n[5 rows x 68 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>task_name</th>\n      <th>acc_mean</th>\n      <th>acc_std</th>\n      <th>acc_ci</th>\n      <th>auc_roc_mean</th>\n      <th>auc_roc_std</th>\n      <th>auc_roc_ci</th>\n      <th>f1_mean</th>\n      <th>f1_std</th>\n      <th>f1_ci</th>\n      <th>...</th>\n      <th>fpr_unpriv_06_mean</th>\n      <th>fpr_unpriv_06_std</th>\n      <th>fpr_unpriv_06_ci</th>\n      <th>fpr_unpriv_08_mean</th>\n      <th>fpr_unpriv_08_std</th>\n      <th>fpr_unpriv_08_ci</th>\n      <th>priv_n_06</th>\n      <th>priv_n_08</th>\n      <th>unpriv_n_06</th>\n      <th>unpriv_n_08</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>davidson</td>\n      <td>0.964891</td>\n      <td>0.000912</td>\n      <td>(0.9643255674367032, 0.9654565148877517)</td>\n      <td>0.987535</td>\n      <td>0.000531</td>\n      <td>(0.98720603990394, 0.9878644677511768)</td>\n      <td>0.978610</td>\n      <td>0.000561</td>\n      <td>(0.9782624372862306, 0.9789580984206189)</td>\n      <td>...</td>\n      <td>0.276923</td>\n      <td>0.074315</td>\n      <td>(0.23086231609172592, 0.32298383775442796)</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>(0.0, 0.0)</td>\n      <td>2000.0</td>\n      <td>2425.0</td>\n      <td>478.0</td>\n      <td>53.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>founta</td>\n      <td>0.938608</td>\n      <td>0.000703</td>\n      <td>(0.9381719600949064, 0.9390439180997646)</td>\n      <td>0.971531</td>\n      <td>0.000614</td>\n      <td>(0.9711507809760194, 0.9719114592977873)</td>\n      <td>0.888008</td>\n      <td>0.001492</td>\n      <td>(0.8870832458020063, 0.8889327158800272)</td>\n      <td>...</td>\n      <td>0.312500</td>\n      <td>0.029463</td>\n      <td>(0.2942387781837517, 0.3307612218162483)</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>(0.0, 0.0)</td>\n      <td>9056.0</td>\n      <td>9185.0</td>\n      <td>139.0</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>golbeck</td>\n      <td>0.787830</td>\n      <td>0.002498</td>\n      <td>(0.7862813177800356, 0.7893779114288895)</td>\n      <td>0.716557</td>\n      <td>0.002984</td>\n      <td>(0.7147074630110294, 0.7184060497737638)</td>\n      <td>0.291718</td>\n      <td>0.024638</td>\n      <td>(0.2764477266267267, 0.3069890625798135)</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>(0.0, 0.0)</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>(0.0, 0.0)</td>\n      <td>1964.0</td>\n      <td>1971.0</td>\n      <td>8.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>harassment</td>\n      <td>0.905890</td>\n      <td>0.000748</td>\n      <td>(0.9054266121976088, 0.9063538429563406)</td>\n      <td>0.957883</td>\n      <td>0.000531</td>\n      <td>(0.9575544396961145, 0.9582122648892007)</td>\n      <td>0.876575</td>\n      <td>0.000891</td>\n      <td>(0.8760229889945704, 0.8771277709502489)</td>\n      <td>...</td>\n      <td>0.413953</td>\n      <td>0.032521</td>\n      <td>(0.3937966369330339, 0.4341103398111522)</td>\n      <td>0.8</td>\n      <td>0.0</td>\n      <td>(0.8, 0.8)</td>\n      <td>12798.0</td>\n      <td>13367.0</td>\n      <td>648.0</td>\n      <td>79.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>hate</td>\n      <td>0.940560</td>\n      <td>0.000893</td>\n      <td>(0.9400064824536417, 0.9411138662427826)</td>\n      <td>0.888630</td>\n      <td>0.004276</td>\n      <td>(0.8859801829504511, 0.8912802284975913)</td>\n      <td>0.367893</td>\n      <td>0.029000</td>\n      <td>(0.3499184885440008, 0.38586760965339)</td>\n      <td>...</td>\n      <td>0.002752</td>\n      <td>0.002484</td>\n      <td>(0.0012124369508144555, 0.004292150205148847)</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>(0.0, 0.0)</td>\n      <td>11805.0</td>\n      <td>12322.0</td>\n      <td>584.0</td>\n      <td>67.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 68 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_dev = result_val.groupby(['task_name']).agg(\n",
    "    acc_mean=('acc ', 'mean'),\n",
    "    acc_std=('acc ', 'std'),\n",
    "    acc_ci=('acc ', ci_sample),\n",
    "    auc_roc_mean=('auc_roc ', 'mean'),\n",
    "    auc_roc_std=('auc_roc ', 'std'),\n",
    "    auc_roc_ci=('auc_roc ', ci_sample),\n",
    "    f1_mean=('f1 ', 'mean'),\n",
    "    f1_std=('f1 ', 'std'),\n",
    "    f1_ci=('f1 ', ci_sample),\n",
    "    precision_mean=('precision ', 'mean'),\n",
    "    precision_std=('precision ', 'std'),\n",
    "    precision_ci=('precision ', ci_sample),\n",
    "    recall_mean=('recall ', 'mean'),\n",
    "    recall_std=('recall ', 'std'),\n",
    "    recall_ci=('recall ', ci_sample),\n",
    "    disparate_impact_favorable_06_mean=('disparate_impact_favorable_06 ', np.mean),\n",
    "    disparate_impact_favorable_06_std=('disparate_impact_favorable_06 ', np.std),\n",
    "    disparate_impact_favorable_06_ci=('disparate_impact_favorable_06 ',ci_sample),\n",
    "    disparate_impact_favorable_08_mean=('disparate_impact_favorable_08 ', np.mean),\n",
    "    disparate_impact_favorable_08_std=('disparate_impact_favorable_08 ',np.std),\n",
    "    disparate_impact_favorable_08_ci=('disparate_impact_favorable_08 ', ci_sample),\n",
    "    disparate_impact_unfavorable_06_mean=('disparate_impact_unfavorable_06 ', np.mean),\n",
    "    disparate_impact_unfavorable_06_std=('disparate_impact_unfavorable_06 ', np.std),\n",
    "    disparate_impact_unfavorable_06_ci=('disparate_impact_unfavorable_06 ',ci_sample),\n",
    "    disparate_impact_unfavorable_08_mean=('disparate_impact_unfavorable_08 ', np.mean),\n",
    "    disparate_impact_unfavorable_08_std=('disparate_impact_unfavorable_08 ',np.std),\n",
    "    disparate_impact_unfavorable_08_ci=('disparate_impact_unfavorable_08 ', ci_sample),\n",
    "    fnr_priv_06_mean=('fnr_priv_06 ', np.mean),\n",
    "    fnr_priv_06_std=('fnr_priv_06 ', np.std),\n",
    "    fnr_priv_06_ci=('fnr_priv_06 ', ci_sample),\n",
    "    fnr_priv_08_mean=('fnr_priv_08 ', np.mean),\n",
    "    fnr_priv_08_std=('fnr_priv_08 ', np.std),\n",
    "    fnr_priv_08_ci=('fnr_priv_08 ', ci_sample),\n",
    "    fnr_total_06_mean=('fnr_total_06 ', np.mean),\n",
    "    fnr_total_06_std=('fnr_total_06 ', np.std),\n",
    "    fnr_total_06_ci=('fnr_total_06 ', ci_sample),\n",
    "    fnr_total_08_mean=('fnr_total_08 ', np.mean),\n",
    "    fnr_total_08_std=('fnr_total_08 ', np.std),\n",
    "    fnr_total_08_ci=('fnr_total_08 ', ci_sample),\n",
    "    fnr_unpriv_06_mean=('fnr_unpriv_06 ', np.mean),\n",
    "    fnr_unpriv_06_std=('fnr_unpriv_06 ', np.std),\n",
    "    fnr_unpriv_06_ci=('fnr_unpriv_06 ', ci_sample),\n",
    "    fnr_unpriv_08_mean=('fnr_unpriv_08 ', np.mean),\n",
    "    fnr_unpriv_08_std=('fnr_unpriv_08 ', np.std),\n",
    "    fnr_unpriv_08_ci=('fnr_unpriv_08 ', ci_sample),\n",
    "    fpr_priv_06_mean=('fpr_priv_06 ', np.mean),\n",
    "    fpr_priv_06_std=('fpr_priv_06 ', np.std),\n",
    "    fpr_priv_06_ci=('fpr_priv_06 ', ci_sample),\n",
    "    fpr_priv_08_mean=('fpr_priv_08 ', np.mean),\n",
    "    fpr_priv_08_std=('fpr_priv_08 ', np.std),\n",
    "    fpr_priv_08_ci=('fpr_priv_08 ', ci_sample),\n",
    "    fpr_total_06_mean=('fpr_total_06 ', np.mean),\n",
    "    fpr_total_06_std=('fpr_total_06 ', np.std),\n",
    "    fpr_total_06_ci=('fpr_total_06 ', ci_sample),\n",
    "    fpr_total_08_mean=('fpr_total_08 ', np.mean),\n",
    "    fpr_total_08_std=('fpr_total_08 ', np.std),\n",
    "    fpr_total_08_ci=('fpr_total_08 ', ci_sample),\n",
    "    fpr_unpriv_06_mean=('fpr_unpriv_06 ', np.mean),\n",
    "    fpr_unpriv_06_std=('fpr_unpriv_06 ', np.std),\n",
    "    fpr_unpriv_06_ci=('fpr_unpriv_06 ', ci_sample),\n",
    "    fpr_unpriv_08_mean=('fpr_unpriv_08 ', np.mean),\n",
    "    fpr_unpriv_08_std=('fpr_unpriv_08 ', np.std),\n",
    "    fpr_unpriv_08_ci=('fpr_unpriv_08 ', ci_sample),\n",
    "    priv_n_06=('priv_n_06 ', np.median),\n",
    "    priv_n_08=('priv_n_08 ', np.median),\n",
    "    unpriv_n_06=('unpriv_n_06 ', np.median),\n",
    "    unpriv_n_08=('unpriv_n_08 ', np.median),\n",
    ").reset_index().sort_values(by=['task_name'])\n",
    "temp_dev.to_csv(f'{root}/bert_expl_stats/bert_oc_dev_agg_seed_results.csv', index=False)\n",
    "temp_dev"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "data": {
      "text/plain": "       dataset task_name  acc_mean   acc_std  \\\n0     davidson     glove  0.887328  0.001309   \n1     davidson     ngram  0.939312  0.000982   \n2     davidson    tf_idf  0.871943  0.000333   \n3       founta     glove  0.899826  0.000561   \n4       founta     ngram  0.935095  0.000388   \n5       founta    tf_idf  0.895674  0.000542   \n6      golbeck     glove  0.759383  0.000939   \n7      golbeck     ngram  0.779177  0.000737   \n8      golbeck    tf_idf  0.776555  0.000434   \n9   harassment     glove  0.839305  0.000563   \n10  harassment     ngram  0.900022  0.000316   \n11  harassment    tf_idf  0.844452  0.000553   \n12        hate     glove  0.931770  0.000121   \n13        hate     ngram  0.938413  0.000126   \n14        hate    tf_idf  0.936387  0.000172   \n\n                                      acc_ci  auc_roc_mean  auc_roc_std  \\\n0   (0.8865165472814914, 0.8881393312623623)      0.907370     0.001982   \n1    (0.9387033864172455, 0.939920111068869)      0.977848     0.000251   \n2    (0.871736729002732, 0.8721499086849511)      0.885099     0.000678   \n3   (0.8994781086922924, 0.9001732518194875)      0.935428     0.000305   \n4   (0.9348543425436208, 0.9353352526788524)      0.959789     0.000147   \n5    (0.8953386787548121, 0.896010207735056)      0.914075     0.000249   \n6   (0.7588012211568581, 0.7599648244135154)      0.587727     0.004376   \n7   (0.7787204922927863, 0.7796342550025933)      0.683468     0.000562   \n8   (0.7762865351041158, 0.7768239928881328)      0.639059     0.000607   \n9   (0.8389562937668006, 0.8396544364044031)      0.902648     0.000171   \n10  (0.8998266913462144, 0.9002179406117935)      0.944787     0.000152   \n11  (0.8441088246050079, 0.8447949482259551)      0.891626     0.000082   \n12  (0.9316953591971178, 0.9318448849053602)      0.756342     0.000862   \n13  (0.9383348847680312, 0.9384913300223131)      0.841897     0.000265   \n14  (0.9362804639135192, 0.9364937794412782)      0.723379     0.000534   \n\n                                  auc_roc_ci   f1_mean    f1_std  ...  \\\n0   (0.9061414733989916, 0.9085987910167492)  0.932861  0.000617  ...   \n1   (0.9776921062772947, 0.9780029387170595)  0.963891  0.000545  ...   \n2       (0.8846788297635392, 0.885519479658)  0.926375  0.000190  ...   \n3    (0.9352383406918522, 0.935616776152325)  0.808424  0.002534  ...   \n4   (0.9596976988256661, 0.9598804242669853)  0.877733  0.000623  ...   \n5   (0.9139211009213997, 0.9142291595270562)  0.787913  0.001371  ...   \n6    (0.5850141425823744, 0.590439031531853)  0.048368  0.006537  ...   \n7   (0.6831197540509362, 0.6838166554224829)  0.272135  0.005568  ...   \n8   (0.6386833417438993, 0.6394356262660494)  0.261335  0.006933  ...   \n9   (0.9025419199844602, 0.9027544176200626)  0.786571  0.001216  ...   \n10     (0.94469346987638, 0.944881439333825)  0.866759  0.000603  ...   \n11  (0.8915750930635723, 0.8916773011357991)  0.780454  0.001552  ...   \n12  (0.7558075653299694, 0.7568761242642994)  0.148105  0.006397  ...   \n13  (0.8417321095648744, 0.8420611729439758)  0.306105  0.003005  ...   \n14  (0.7230483734468918, 0.7237105167050857)  0.234180  0.002997  ...   \n\n   fpr_unpriv_06_mean  fpr_unpriv_06_std  \\\n0            0.446154           0.079446   \n1            0.392308           0.024325   \n2            0.846154           0.000000   \n3            0.294118           0.000000   \n4            0.235294           0.000000   \n5            0.294118           0.000000   \n6            0.000000           0.000000   \n7            0.000000           0.000000   \n8            0.000000           0.000000   \n9            0.607692           0.016217   \n10           0.384615           0.000000   \n11           0.473077           0.018579   \n12           0.001518           0.000800   \n13           0.017647           0.000917   \n14           0.011385           0.000000   \n\n                                fpr_unpriv_06_ci fpr_unpriv_08_mean  \\\n0     (0.39691282158097413, 0.49539487072671834)           0.000000   \n1     (0.37723076923076926, 0.40738461538461546)           0.000000   \n2       (0.8461538461538461, 0.8461538461538461)           0.000000   \n3     (0.29411764705882343, 0.29411764705882354)           0.000000   \n4       (0.2352941176470588, 0.2352941176470588)           0.000000   \n5     (0.29411764705882343, 0.29411764705882354)           0.000000   \n6                                     (0.0, 0.0)                NaN   \n7                                     (0.0, 0.0)                NaN   \n8                                     (0.0, 0.0)                NaN   \n9       (0.5976410256410256, 0.6177435897435897)           1.000000   \n10    (0.38461538461538464, 0.38461538461538464)           0.500000   \n11     (0.4615617328690854, 0.48459211328476093)           1.000000   \n12   (0.00102213788741303, 0.002013915243516762)           0.000000   \n13    (0.01707894697266835, 0.01821517067439048)           0.021311   \n14  (0.011385199240986715, 0.011385199240986715)           0.016393   \n\n    fpr_unpriv_08_std                              fpr_unpriv_08_ci priv_n_06  \\\n0            0.000000                                    (0.0, 0.0)     502.0   \n1            0.000000                                    (0.0, 0.0)     502.0   \n2            0.000000                                    (0.0, 0.0)     502.0   \n3            0.000000                                    (0.0, 0.0)     117.0   \n4            0.000000                                    (0.0, 0.0)     117.0   \n5            0.000000                                    (0.0, 0.0)     117.0   \n6                 NaN                                    (nan, nan)      13.0   \n7                 NaN                                    (nan, nan)      13.0   \n8                 NaN                                    (nan, nan)      13.0   \n9            0.000000                                    (1.0, 1.0)     596.0   \n10           0.000000                                    (0.5, 0.5)     596.0   \n11           0.000000                                    (1.0, 1.0)     596.0   \n12           0.000000                                    (0.0, 0.0)     569.0   \n13           0.007919   (0.016403361550757674, 0.02621958926891444)     569.0   \n14           0.000000  (0.016393442622950817, 0.016393442622950817)     569.0   \n\n    priv_n_08  unpriv_n_06 unpriv_n_08  \n0        74.0       1968.0      2396.0  \n1        74.0       1968.0      2396.0  \n2        74.0       1968.0      2396.0  \n3         7.0       9061.0      9171.0  \n4         7.0       9061.0      9171.0  \n5         7.0       9061.0      9171.0  \n6         NaN       1932.0         NaN  \n7         NaN       1932.0         NaN  \n8         NaN       1932.0         NaN  \n9        70.0      12850.0     13376.0  \n10       70.0      12850.0     13376.0  \n11       70.0      12850.0     13376.0  \n12       66.0      11820.0     12323.0  \n13       66.0      11820.0     12323.0  \n14       66.0      11820.0     12323.0  \n\n[15 rows x 69 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>task_name</th>\n      <th>acc_mean</th>\n      <th>acc_std</th>\n      <th>acc_ci</th>\n      <th>auc_roc_mean</th>\n      <th>auc_roc_std</th>\n      <th>auc_roc_ci</th>\n      <th>f1_mean</th>\n      <th>f1_std</th>\n      <th>...</th>\n      <th>fpr_unpriv_06_mean</th>\n      <th>fpr_unpriv_06_std</th>\n      <th>fpr_unpriv_06_ci</th>\n      <th>fpr_unpriv_08_mean</th>\n      <th>fpr_unpriv_08_std</th>\n      <th>fpr_unpriv_08_ci</th>\n      <th>priv_n_06</th>\n      <th>priv_n_08</th>\n      <th>unpriv_n_06</th>\n      <th>unpriv_n_08</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>davidson</td>\n      <td>glove</td>\n      <td>0.887328</td>\n      <td>0.001309</td>\n      <td>(0.8865165472814914, 0.8881393312623623)</td>\n      <td>0.907370</td>\n      <td>0.001982</td>\n      <td>(0.9061414733989916, 0.9085987910167492)</td>\n      <td>0.932861</td>\n      <td>0.000617</td>\n      <td>...</td>\n      <td>0.446154</td>\n      <td>0.079446</td>\n      <td>(0.39691282158097413, 0.49539487072671834)</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>(0.0, 0.0)</td>\n      <td>502.0</td>\n      <td>74.0</td>\n      <td>1968.0</td>\n      <td>2396.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>davidson</td>\n      <td>ngram</td>\n      <td>0.939312</td>\n      <td>0.000982</td>\n      <td>(0.9387033864172455, 0.939920111068869)</td>\n      <td>0.977848</td>\n      <td>0.000251</td>\n      <td>(0.9776921062772947, 0.9780029387170595)</td>\n      <td>0.963891</td>\n      <td>0.000545</td>\n      <td>...</td>\n      <td>0.392308</td>\n      <td>0.024325</td>\n      <td>(0.37723076923076926, 0.40738461538461546)</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>(0.0, 0.0)</td>\n      <td>502.0</td>\n      <td>74.0</td>\n      <td>1968.0</td>\n      <td>2396.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>davidson</td>\n      <td>tf_idf</td>\n      <td>0.871943</td>\n      <td>0.000333</td>\n      <td>(0.871736729002732, 0.8721499086849511)</td>\n      <td>0.885099</td>\n      <td>0.000678</td>\n      <td>(0.8846788297635392, 0.885519479658)</td>\n      <td>0.926375</td>\n      <td>0.000190</td>\n      <td>...</td>\n      <td>0.846154</td>\n      <td>0.000000</td>\n      <td>(0.8461538461538461, 0.8461538461538461)</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>(0.0, 0.0)</td>\n      <td>502.0</td>\n      <td>74.0</td>\n      <td>1968.0</td>\n      <td>2396.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>founta</td>\n      <td>glove</td>\n      <td>0.899826</td>\n      <td>0.000561</td>\n      <td>(0.8994781086922924, 0.9001732518194875)</td>\n      <td>0.935428</td>\n      <td>0.000305</td>\n      <td>(0.9352383406918522, 0.935616776152325)</td>\n      <td>0.808424</td>\n      <td>0.002534</td>\n      <td>...</td>\n      <td>0.294118</td>\n      <td>0.000000</td>\n      <td>(0.29411764705882343, 0.29411764705882354)</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>(0.0, 0.0)</td>\n      <td>117.0</td>\n      <td>7.0</td>\n      <td>9061.0</td>\n      <td>9171.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>founta</td>\n      <td>ngram</td>\n      <td>0.935095</td>\n      <td>0.000388</td>\n      <td>(0.9348543425436208, 0.9353352526788524)</td>\n      <td>0.959789</td>\n      <td>0.000147</td>\n      <td>(0.9596976988256661, 0.9598804242669853)</td>\n      <td>0.877733</td>\n      <td>0.000623</td>\n      <td>...</td>\n      <td>0.235294</td>\n      <td>0.000000</td>\n      <td>(0.2352941176470588, 0.2352941176470588)</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>(0.0, 0.0)</td>\n      <td>117.0</td>\n      <td>7.0</td>\n      <td>9061.0</td>\n      <td>9171.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>founta</td>\n      <td>tf_idf</td>\n      <td>0.895674</td>\n      <td>0.000542</td>\n      <td>(0.8953386787548121, 0.896010207735056)</td>\n      <td>0.914075</td>\n      <td>0.000249</td>\n      <td>(0.9139211009213997, 0.9142291595270562)</td>\n      <td>0.787913</td>\n      <td>0.001371</td>\n      <td>...</td>\n      <td>0.294118</td>\n      <td>0.000000</td>\n      <td>(0.29411764705882343, 0.29411764705882354)</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>(0.0, 0.0)</td>\n      <td>117.0</td>\n      <td>7.0</td>\n      <td>9061.0</td>\n      <td>9171.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>golbeck</td>\n      <td>glove</td>\n      <td>0.759383</td>\n      <td>0.000939</td>\n      <td>(0.7588012211568581, 0.7599648244135154)</td>\n      <td>0.587727</td>\n      <td>0.004376</td>\n      <td>(0.5850141425823744, 0.590439031531853)</td>\n      <td>0.048368</td>\n      <td>0.006537</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>(0.0, 0.0)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>13.0</td>\n      <td>NaN</td>\n      <td>1932.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>golbeck</td>\n      <td>ngram</td>\n      <td>0.779177</td>\n      <td>0.000737</td>\n      <td>(0.7787204922927863, 0.7796342550025933)</td>\n      <td>0.683468</td>\n      <td>0.000562</td>\n      <td>(0.6831197540509362, 0.6838166554224829)</td>\n      <td>0.272135</td>\n      <td>0.005568</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>(0.0, 0.0)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>13.0</td>\n      <td>NaN</td>\n      <td>1932.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>golbeck</td>\n      <td>tf_idf</td>\n      <td>0.776555</td>\n      <td>0.000434</td>\n      <td>(0.7762865351041158, 0.7768239928881328)</td>\n      <td>0.639059</td>\n      <td>0.000607</td>\n      <td>(0.6386833417438993, 0.6394356262660494)</td>\n      <td>0.261335</td>\n      <td>0.006933</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>(0.0, 0.0)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>13.0</td>\n      <td>NaN</td>\n      <td>1932.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>harassment</td>\n      <td>glove</td>\n      <td>0.839305</td>\n      <td>0.000563</td>\n      <td>(0.8389562937668006, 0.8396544364044031)</td>\n      <td>0.902648</td>\n      <td>0.000171</td>\n      <td>(0.9025419199844602, 0.9027544176200626)</td>\n      <td>0.786571</td>\n      <td>0.001216</td>\n      <td>...</td>\n      <td>0.607692</td>\n      <td>0.016217</td>\n      <td>(0.5976410256410256, 0.6177435897435897)</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>(1.0, 1.0)</td>\n      <td>596.0</td>\n      <td>70.0</td>\n      <td>12850.0</td>\n      <td>13376.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>harassment</td>\n      <td>ngram</td>\n      <td>0.900022</td>\n      <td>0.000316</td>\n      <td>(0.8998266913462144, 0.9002179406117935)</td>\n      <td>0.944787</td>\n      <td>0.000152</td>\n      <td>(0.94469346987638, 0.944881439333825)</td>\n      <td>0.866759</td>\n      <td>0.000603</td>\n      <td>...</td>\n      <td>0.384615</td>\n      <td>0.000000</td>\n      <td>(0.38461538461538464, 0.38461538461538464)</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>(0.5, 0.5)</td>\n      <td>596.0</td>\n      <td>70.0</td>\n      <td>12850.0</td>\n      <td>13376.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>harassment</td>\n      <td>tf_idf</td>\n      <td>0.844452</td>\n      <td>0.000553</td>\n      <td>(0.8441088246050079, 0.8447949482259551)</td>\n      <td>0.891626</td>\n      <td>0.000082</td>\n      <td>(0.8915750930635723, 0.8916773011357991)</td>\n      <td>0.780454</td>\n      <td>0.001552</td>\n      <td>...</td>\n      <td>0.473077</td>\n      <td>0.018579</td>\n      <td>(0.4615617328690854, 0.48459211328476093)</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>(1.0, 1.0)</td>\n      <td>596.0</td>\n      <td>70.0</td>\n      <td>12850.0</td>\n      <td>13376.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>hate</td>\n      <td>glove</td>\n      <td>0.931770</td>\n      <td>0.000121</td>\n      <td>(0.9316953591971178, 0.9318448849053602)</td>\n      <td>0.756342</td>\n      <td>0.000862</td>\n      <td>(0.7558075653299694, 0.7568761242642994)</td>\n      <td>0.148105</td>\n      <td>0.006397</td>\n      <td>...</td>\n      <td>0.001518</td>\n      <td>0.000800</td>\n      <td>(0.00102213788741303, 0.002013915243516762)</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>(0.0, 0.0)</td>\n      <td>569.0</td>\n      <td>66.0</td>\n      <td>11820.0</td>\n      <td>12323.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>hate</td>\n      <td>ngram</td>\n      <td>0.938413</td>\n      <td>0.000126</td>\n      <td>(0.9383348847680312, 0.9384913300223131)</td>\n      <td>0.841897</td>\n      <td>0.000265</td>\n      <td>(0.8417321095648744, 0.8420611729439758)</td>\n      <td>0.306105</td>\n      <td>0.003005</td>\n      <td>...</td>\n      <td>0.017647</td>\n      <td>0.000917</td>\n      <td>(0.01707894697266835, 0.01821517067439048)</td>\n      <td>0.021311</td>\n      <td>0.007919</td>\n      <td>(0.016403361550757674, 0.02621958926891444)</td>\n      <td>569.0</td>\n      <td>66.0</td>\n      <td>11820.0</td>\n      <td>12323.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>hate</td>\n      <td>tf_idf</td>\n      <td>0.936387</td>\n      <td>0.000172</td>\n      <td>(0.9362804639135192, 0.9364937794412782)</td>\n      <td>0.723379</td>\n      <td>0.000534</td>\n      <td>(0.7230483734468918, 0.7237105167050857)</td>\n      <td>0.234180</td>\n      <td>0.002997</td>\n      <td>...</td>\n      <td>0.011385</td>\n      <td>0.000000</td>\n      <td>(0.011385199240986715, 0.011385199240986715)</td>\n      <td>0.016393</td>\n      <td>0.000000</td>\n      <td>(0.016393442622950817, 0.016393442622950817)</td>\n      <td>569.0</td>\n      <td>66.0</td>\n      <td>11820.0</td>\n      <td>12323.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>15 rows × 69 columns</p>\n</div>"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "    task_name  acc_mean   acc_std                                    acc_ci  \\\n0    davidson  0.965954  0.001206  (0.9652067286302982, 0.9667012988001175)   \n1      founta  0.942692  0.000666  (0.9422794329993714, 0.9431055169788799)   \n2     golbeck  0.791988  0.004013  (0.7895006142134495, 0.7944750450157594)   \n3  harassment  0.911111  0.000572  (0.9107568412591425, 0.9114653809630797)   \n4        hate  0.938300  0.001849  (0.9371541172516699, 0.9394460926119185)   \n\n   auc_roc_mean  auc_roc_std                                auc_roc_ci  \\\n0      0.987516     0.000566  (0.9871649244780194, 0.9878665764287036)   \n1      0.971083     0.000995  (0.9704664748981281, 0.9716997677498301)   \n2      0.727011     0.005430   (0.7236457853103337, 0.730376284747636)   \n3      0.962094     0.000460  (0.9618088859054217, 0.9623786137347967)   \n4      0.876724     0.008419   (0.871506052268978, 0.8819418032216243)   \n\n    f1_mean    f1_std                                      f1_ci  ...  \\\n0  0.979387  0.000738   (0.9789300471167732, 0.9798443682459512)  ...   \n1  0.894592  0.001078   (0.8939245199526668, 0.8952602500368506)  ...   \n2  0.358975  0.021594     (0.345591184609725, 0.372359235113698)  ...   \n3  0.882513  0.001172   (0.8817863663321444, 0.8832394629391607)  ...   \n4  0.385876  0.030775  (0.36680103211291665, 0.4049505889270881)  ...   \n\n   fpr_unpriv_06_mean  fpr_unpriv_06_std  \\\n0            0.238462           0.043665   \n1            0.205882           0.031003   \n2            0.000000           0.000000   \n3            0.392308           0.064867   \n4            0.029032           0.013118   \n\n                               fpr_unpriv_06_ci  fpr_unpriv_08_mean  \\\n0    (0.21139763327696504, 0.26552544364611186)            0.000000   \n1    (0.18666666666666665, 0.22509803921568627)            0.000000   \n2                                    (0.0, 0.0)                 NaN   \n3     (0.3521025641025641, 0.43251282051282053)            0.500000   \n4  (0.020901914037480984, 0.037162602091551276)            0.054098   \n\n   fpr_unpriv_08_std                            fpr_unpriv_08_ci  priv_n_06  \\\n0           0.000000                                  (0.0, 0.0)     1977.0   \n1           0.000000                                  (0.0, 0.0)     9079.0   \n2                NaN                                  (nan, nan)     1959.0   \n3           0.333333    (0.2933978595356659, 0.7066021404643341)    12850.0   \n4           0.019008  (0.04231693989071039, 0.06587978142076503)    11820.0   \n\n   priv_n_08 unpriv_n_06  unpriv_n_08  \n0     2405.0       502.0         74.0  \n1     9189.0       117.0          7.0  \n2        NaN        13.0          NaN  \n3    13376.0       596.0         70.0  \n4    12323.0       569.0         66.0  \n\n[5 rows x 68 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>task_name</th>\n      <th>acc_mean</th>\n      <th>acc_std</th>\n      <th>acc_ci</th>\n      <th>auc_roc_mean</th>\n      <th>auc_roc_std</th>\n      <th>auc_roc_ci</th>\n      <th>f1_mean</th>\n      <th>f1_std</th>\n      <th>f1_ci</th>\n      <th>...</th>\n      <th>fpr_unpriv_06_mean</th>\n      <th>fpr_unpriv_06_std</th>\n      <th>fpr_unpriv_06_ci</th>\n      <th>fpr_unpriv_08_mean</th>\n      <th>fpr_unpriv_08_std</th>\n      <th>fpr_unpriv_08_ci</th>\n      <th>priv_n_06</th>\n      <th>priv_n_08</th>\n      <th>unpriv_n_06</th>\n      <th>unpriv_n_08</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>davidson</td>\n      <td>0.965954</td>\n      <td>0.001206</td>\n      <td>(0.9652067286302982, 0.9667012988001175)</td>\n      <td>0.987516</td>\n      <td>0.000566</td>\n      <td>(0.9871649244780194, 0.9878665764287036)</td>\n      <td>0.979387</td>\n      <td>0.000738</td>\n      <td>(0.9789300471167732, 0.9798443682459512)</td>\n      <td>...</td>\n      <td>0.238462</td>\n      <td>0.043665</td>\n      <td>(0.21139763327696504, 0.26552544364611186)</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>(0.0, 0.0)</td>\n      <td>1977.0</td>\n      <td>2405.0</td>\n      <td>502.0</td>\n      <td>74.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>founta</td>\n      <td>0.942692</td>\n      <td>0.000666</td>\n      <td>(0.9422794329993714, 0.9431055169788799)</td>\n      <td>0.971083</td>\n      <td>0.000995</td>\n      <td>(0.9704664748981281, 0.9716997677498301)</td>\n      <td>0.894592</td>\n      <td>0.001078</td>\n      <td>(0.8939245199526668, 0.8952602500368506)</td>\n      <td>...</td>\n      <td>0.205882</td>\n      <td>0.031003</td>\n      <td>(0.18666666666666665, 0.22509803921568627)</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>(0.0, 0.0)</td>\n      <td>9079.0</td>\n      <td>9189.0</td>\n      <td>117.0</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>golbeck</td>\n      <td>0.791988</td>\n      <td>0.004013</td>\n      <td>(0.7895006142134495, 0.7944750450157594)</td>\n      <td>0.727011</td>\n      <td>0.005430</td>\n      <td>(0.7236457853103337, 0.730376284747636)</td>\n      <td>0.358975</td>\n      <td>0.021594</td>\n      <td>(0.345591184609725, 0.372359235113698)</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>(0.0, 0.0)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>1959.0</td>\n      <td>NaN</td>\n      <td>13.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>harassment</td>\n      <td>0.911111</td>\n      <td>0.000572</td>\n      <td>(0.9107568412591425, 0.9114653809630797)</td>\n      <td>0.962094</td>\n      <td>0.000460</td>\n      <td>(0.9618088859054217, 0.9623786137347967)</td>\n      <td>0.882513</td>\n      <td>0.001172</td>\n      <td>(0.8817863663321444, 0.8832394629391607)</td>\n      <td>...</td>\n      <td>0.392308</td>\n      <td>0.064867</td>\n      <td>(0.3521025641025641, 0.43251282051282053)</td>\n      <td>0.500000</td>\n      <td>0.333333</td>\n      <td>(0.2933978595356659, 0.7066021404643341)</td>\n      <td>12850.0</td>\n      <td>13376.0</td>\n      <td>596.0</td>\n      <td>70.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>hate</td>\n      <td>0.938300</td>\n      <td>0.001849</td>\n      <td>(0.9371541172516699, 0.9394460926119185)</td>\n      <td>0.876724</td>\n      <td>0.008419</td>\n      <td>(0.871506052268978, 0.8819418032216243)</td>\n      <td>0.385876</td>\n      <td>0.030775</td>\n      <td>(0.36680103211291665, 0.4049505889270881)</td>\n      <td>...</td>\n      <td>0.029032</td>\n      <td>0.013118</td>\n      <td>(0.020901914037480984, 0.037162602091551276)</td>\n      <td>0.054098</td>\n      <td>0.019008</td>\n      <td>(0.04231693989071039, 0.06587978142076503)</td>\n      <td>11820.0</td>\n      <td>12323.0</td>\n      <td>569.0</td>\n      <td>66.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 68 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_test = result_test.groupby(['task_name']).agg(\n",
    "    acc_mean=('acc ', 'mean'),\n",
    "    acc_std=('acc ', 'std'),\n",
    "    acc_ci=('acc ', ci_sample),\n",
    "    auc_roc_mean=('auc_roc ', 'mean'),\n",
    "    auc_roc_std=('auc_roc ', 'std'),\n",
    "    auc_roc_ci=('auc_roc ', ci_sample),\n",
    "    f1_mean=('f1 ', 'mean'),\n",
    "    f1_std=('f1 ', 'std'),\n",
    "    f1_ci=('f1 ', ci_sample),\n",
    "    precision_mean=('precision ', 'mean'),\n",
    "    precision_std=('precision ', 'std'),\n",
    "    precision_ci=('precision ', ci_sample),\n",
    "    recall_mean=('recall ', 'mean'),\n",
    "    recall_std=('recall ', 'std'),\n",
    "    recall_ci=('recall ', ci_sample),\n",
    "    disparate_impact_favorable_06_mean=('disparate_impact_favorable_06 ', np.mean),\n",
    "    disparate_impact_favorable_06_std=('disparate_impact_favorable_06 ', np.std),\n",
    "    disparate_impact_favorable_06_ci=('disparate_impact_favorable_06 ',ci_sample),\n",
    "    disparate_impact_favorable_08_mean=('disparate_impact_favorable_08 ', np.mean),\n",
    "    disparate_impact_favorable_08_std=('disparate_impact_favorable_08 ',np.std),\n",
    "    disparate_impact_favorable_08_ci=('disparate_impact_favorable_08 ', ci_sample),\n",
    "    disparate_impact_unfavorable_06_mean=('disparate_impact_unfavorable_06 ', np.mean),\n",
    "    disparate_impact_unfavorable_06_std=('disparate_impact_unfavorable_06 ', np.std),\n",
    "    disparate_impact_unfavorable_06_ci=('disparate_impact_unfavorable_06 ',ci_sample),\n",
    "    disparate_impact_unfavorable_08_mean=('disparate_impact_unfavorable_08 ', np.mean),\n",
    "    disparate_impact_unfavorable_08_std=('disparate_impact_unfavorable_08 ',np.std),\n",
    "    disparate_impact_unfavorable_08_ci=('disparate_impact_unfavorable_08 ', ci_sample),\n",
    "    fnr_priv_06_mean=('fnr_priv_06 ', np.mean),\n",
    "    fnr_priv_06_std=('fnr_priv_06 ', np.std),\n",
    "    fnr_priv_06_ci=('fnr_priv_06 ', ci_sample),\n",
    "    fnr_priv_08_mean=('fnr_priv_08 ', np.mean),\n",
    "    fnr_priv_08_std=('fnr_priv_08 ', np.std),\n",
    "    fnr_priv_08_ci=('fnr_priv_08 ', ci_sample),\n",
    "    fnr_total_06_mean=('fnr_total_06 ', np.mean),\n",
    "    fnr_total_06_std=('fnr_total_06 ', np.std),\n",
    "    fnr_total_06_ci=('fnr_total_06 ', ci_sample),\n",
    "    fnr_total_08_mean=('fnr_total_08 ', np.mean),\n",
    "    fnr_total_08_std=('fnr_total_08 ', np.std),\n",
    "    fnr_total_08_ci=('fnr_total_08 ', ci_sample),\n",
    "    fnr_unpriv_06_mean=('fnr_unpriv_06 ', np.mean),\n",
    "    fnr_unpriv_06_std=('fnr_unpriv_06 ', np.std),\n",
    "    fnr_unpriv_06_ci=('fnr_unpriv_06 ', ci_sample),\n",
    "    fnr_unpriv_08_mean=('fnr_unpriv_08 ', np.mean),\n",
    "    fnr_unpriv_08_std=('fnr_unpriv_08 ', np.std),\n",
    "    fnr_unpriv_08_ci=('fnr_unpriv_08 ', ci_sample),\n",
    "    fpr_priv_06_mean=('fpr_priv_06 ', np.mean),\n",
    "    fpr_priv_06_std=('fpr_priv_06 ', np.std),\n",
    "    fpr_priv_06_ci=('fpr_priv_06 ', ci_sample),\n",
    "    fpr_priv_08_mean=('fpr_priv_08 ', np.mean),\n",
    "    fpr_priv_08_std=('fpr_priv_08 ', np.std),\n",
    "    fpr_priv_08_ci=('fpr_priv_08 ', ci_sample),\n",
    "    fpr_total_06_mean=('fpr_total_06 ', np.mean),\n",
    "    fpr_total_06_std=('fpr_total_06 ', np.std),\n",
    "    fpr_total_06_ci=('fpr_total_06 ', ci_sample),\n",
    "    fpr_total_08_mean=('fpr_total_08 ', np.mean),\n",
    "    fpr_total_08_std=('fpr_total_08 ', np.std),\n",
    "    fpr_total_08_ci=('fpr_total_08 ', ci_sample),\n",
    "    fpr_unpriv_06_mean=('fpr_unpriv_06 ', np.mean),\n",
    "    fpr_unpriv_06_std=('fpr_unpriv_06 ', np.std),\n",
    "    fpr_unpriv_06_ci=('fpr_unpriv_06 ', ci_sample),\n",
    "    fpr_unpriv_08_mean=('fpr_unpriv_08 ', np.mean),\n",
    "    fpr_unpriv_08_std=('fpr_unpriv_08 ', np.std),\n",
    "    fpr_unpriv_08_ci=('fpr_unpriv_08 ', ci_sample),\n",
    "    priv_n_06=('priv_n_06 ', np.median),\n",
    "    priv_n_08=('priv_n_08 ', np.median),\n",
    "    unpriv_n_06=('unpriv_n_06 ', np.median),\n",
    "    unpriv_n_08=('unpriv_n_08 ', np.median),\n",
    ").reset_index().sort_values(by=['task_name'])\n",
    "temp_test.to_csv(f'{root}/bert_expl_stats/bert_oc_test_agg_seed_results.csv', index=False)\n",
    "temp_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'temp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-62-5edb318809fa>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mtemp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto_csv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'../data/contextualize_results/stats_on_tasks.csv'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mindex\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'temp' is not defined"
     ]
    }
   ],
   "source": [
    "temp.to_csv('../data/contextualize_results/stats_on_tasks.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "models_dict = {'twitter': {'twitter_es_reg_nb5_h5_is_bal_pos_seed_', 'twitter_es_reg_nb0_h1_bal_seed_', 'twitter_es_vanilla_bal_seed_'},\n",
    "                'twitter_harass': {'twitter_harass_es_reg_nb5_h5_is_bal_pos_seed_','twitter_harass_es_reg_nb0_h1_bal_seed_','twitter_harass_es_vanilla_bal_seed_'},\n",
    "               'gab': {'majority_gab_es_vanilla_bal_seed_', 'majority_gab_es_reg_nb0_h1_bal_seed_', 'majority_gab_es_reg_nb5_h5_is_bal_pos_seed_'},\n",
    "               'ws': {'ws_es_vanilla_bal_seed_', 'ws_es_reg_nb0_h1_bal_seed_','ws_es_reg_nb5_h5_is_bal_pos_seed_'},\n",
    "               'nyt': {},\n",
    "               }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "                                            model            task  acc_mean  \\\n14                twitter_es_reg_nb0_h1_bal_seed_         twitter  0.740416   \n18         twitter_es_reg_nb5_h5_is_bal_pos_seed_         twitter  0.780775   \n22                   twitter_es_vanilla_bal_seed_         twitter  0.797047   \n27         twitter_harass_es_reg_nb0_h1_bal_seed_  twitter_harass  0.699126   \n32  twitter_harass_es_reg_nb5_h5_is_bal_pos_seed_  twitter_harass  0.798674   \n37            twitter_harass_es_vanilla_bal_seed_  twitter_harass  0.802177   \n0            majority_gab_es_reg_nb0_h1_bal_seed_             gab  0.862108   \n4     majority_gab_es_reg_nb5_h5_is_bal_pos_seed_             gab  0.881928   \n8               majority_gab_es_vanilla_bal_seed_             gab  0.882831   \n42                     ws_es_reg_nb0_h1_bal_seed_              ws  0.895282   \n46              ws_es_reg_nb5_h5_is_bal_pos_seed_              ws  0.898782   \n50                        ws_es_vanilla_bal_seed_              ws  0.908676   \n\n     acc_std                                    acc_ci  auc_roc_mean  \\\n14  0.013804  (0.7318604701540944, 0.7489718244091427)      0.851023   \n18  0.020300  (0.7681924281851983, 0.7933570971767733)      0.861636   \n22  0.016549   (0.786789594562518, 0.8073037988596702)      0.867681   \n27  0.108810  (0.6316849387126151, 0.7665673015302938)      0.913960   \n32  0.010532  (0.7921467442694817, 0.8052019930481517)      0.951445   \n37  0.013758  (0.7936501224867812, 0.8107044653825811)      0.951767   \n0   0.012026  (0.8546544856593332, 0.8695623818105465)      0.874507   \n4   0.020701  (0.8690969473006679, 0.8947584743860789)      0.886380   \n8   0.015758  (0.8730642575235151, 0.8925983930788944)      0.891738   \n42  0.012831  (0.8873287167761869, 0.9032344491294447)      0.880330   \n46  0.010888  (0.8920342011868992, 0.9055304867887476)      0.882531   \n50  0.006214  (0.9048244305638931, 0.9125271676096227)      0.876880   \n\n    auc_roc_std                                auc_roc_ci   f1_mean    f1_std  \\\n14     0.005828  (0.8474105131000839, 0.8546345486463854)  0.400923  0.009749   \n18     0.006482  (0.8576180444353265, 0.8656529654302911)  0.434504  0.012329   \n22     0.012040  (0.8602187635615669, 0.8751441492098829)  0.452028  0.014638   \n27     0.096742  (0.8539989489968628, 0.9739213422284224)  0.724786  0.059479   \n32     0.004280  (0.9487928326630026, 0.9540978517512333)  0.790119  0.007984   \n37     0.005010  (0.9486616697289599, 0.9548716952451467)  0.793076  0.010919   \n0      0.007422  (0.8699068385251156, 0.8791072046781914)  0.449921  0.018215   \n4      0.010175  (0.8800729619505216, 0.8926863453965002)  0.480698  0.030686   \n8      0.007496  (0.8870917266629993, 0.8963837414831942)  0.488232  0.021547   \n42     0.009994  (0.8741355728690714, 0.8865244461242809)  0.547665  0.020910   \n46     0.007200   (0.8780681767780336, 0.886993551617028)  0.553661  0.019914   \n50     0.011693   (0.869632653017099, 0.8841280307435848)  0.563915  0.026242   \n\n    ... disparate_impact_06_mean  disparate_impact_06_std  \\\n14  ...                 0.857148                 0.044112   \n18  ...                 0.826937                 0.060878   \n22  ...                 0.840683                 0.035621   \n27  ...                      inf                      NaN   \n32  ...                41.367705                 8.509532   \n37  ...                35.196131                11.226862   \n0   ...                 1.581563                 0.638837   \n4   ...                 1.286723                 0.038792   \n8   ...                 1.582046                 0.701131   \n42  ...                      NaN                      NaN   \n46  ...                      NaN                      NaN   \n50  ...                      NaN                      NaN   \n\n                      disparate_impact_06_ci disparate_impact_08_mean  \\\n14   (0.8298066061381789, 0.884489005007136)                 0.962671   \n18  (0.7892042012454198, 0.8646696652235802)                 0.866940   \n22  (0.8186045992182596, 0.8627610571687874)                 0.874632   \n27                                (nan, nan)                      inf   \n32    (36.09344237057658, 46.64196711913195)                      inf   \n37    (28.23764979208232, 42.15461160470309)                      inf   \n0   (1.1856077090048187, 1.9775184225582472)                      inf   \n4   (1.2626797696530172, 1.3107662170699763)                      inf   \n8   (1.1474801485394046, 2.0166115835064615)                      inf   \n42                                (nan, nan)                      NaN   \n46                                (nan, nan)                      NaN   \n50                                (nan, nan)                      NaN   \n\n    disparate_impact_08_std                    disparate_impact_08_ci  \\\n14                 0.097553    (0.902206724586391, 1.023134586881783)   \n18                 0.114318  (0.7960850410549574, 0.9377945217594896)   \n22                 0.077094  (0.8268481619460178, 0.9224149791085426)   \n27                      NaN                                (nan, nan)   \n32                      NaN                                (nan, nan)   \n37                      NaN                                (nan, nan)   \n0                       NaN                                (nan, nan)   \n4                       NaN                                (nan, nan)   \n8                       NaN                                (nan, nan)   \n42                      NaN                                (nan, nan)   \n46                      NaN                                (nan, nan)   \n50                      NaN                                (nan, nan)   \n\n   priv_n_06  priv_n_08  unpriv_n_06 unpriv_n_08  \n14     525.0       64.0       9904.0     10365.0  \n18     525.0       64.0       9904.0     10365.0  \n22     525.0       64.0       9904.0     10365.0  \n27     656.0       77.0      12847.0     13426.0  \n32     656.0       77.0      12847.0     13426.0  \n37     656.0       77.0      12847.0     13426.0  \n0        3.0        1.0       1657.0      1659.0  \n4        3.0        1.0       1657.0      1659.0  \n8        3.0        1.0       1657.0      1659.0  \n42       NaN        NaN          NaN         NaN  \n46       NaN        NaN          NaN         NaN  \n50       NaN        NaN          NaN         NaN  \n\n[12 rows x 36 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>task</th>\n      <th>acc_mean</th>\n      <th>acc_std</th>\n      <th>acc_ci</th>\n      <th>auc_roc_mean</th>\n      <th>auc_roc_std</th>\n      <th>auc_roc_ci</th>\n      <th>f1_mean</th>\n      <th>f1_std</th>\n      <th>...</th>\n      <th>disparate_impact_06_mean</th>\n      <th>disparate_impact_06_std</th>\n      <th>disparate_impact_06_ci</th>\n      <th>disparate_impact_08_mean</th>\n      <th>disparate_impact_08_std</th>\n      <th>disparate_impact_08_ci</th>\n      <th>priv_n_06</th>\n      <th>priv_n_08</th>\n      <th>unpriv_n_06</th>\n      <th>unpriv_n_08</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>14</th>\n      <td>twitter_es_reg_nb0_h1_bal_seed_</td>\n      <td>twitter</td>\n      <td>0.740416</td>\n      <td>0.013804</td>\n      <td>(0.7318604701540944, 0.7489718244091427)</td>\n      <td>0.851023</td>\n      <td>0.005828</td>\n      <td>(0.8474105131000839, 0.8546345486463854)</td>\n      <td>0.400923</td>\n      <td>0.009749</td>\n      <td>...</td>\n      <td>0.857148</td>\n      <td>0.044112</td>\n      <td>(0.8298066061381789, 0.884489005007136)</td>\n      <td>0.962671</td>\n      <td>0.097553</td>\n      <td>(0.902206724586391, 1.023134586881783)</td>\n      <td>525.0</td>\n      <td>64.0</td>\n      <td>9904.0</td>\n      <td>10365.0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>twitter_es_reg_nb5_h5_is_bal_pos_seed_</td>\n      <td>twitter</td>\n      <td>0.780775</td>\n      <td>0.020300</td>\n      <td>(0.7681924281851983, 0.7933570971767733)</td>\n      <td>0.861636</td>\n      <td>0.006482</td>\n      <td>(0.8576180444353265, 0.8656529654302911)</td>\n      <td>0.434504</td>\n      <td>0.012329</td>\n      <td>...</td>\n      <td>0.826937</td>\n      <td>0.060878</td>\n      <td>(0.7892042012454198, 0.8646696652235802)</td>\n      <td>0.866940</td>\n      <td>0.114318</td>\n      <td>(0.7960850410549574, 0.9377945217594896)</td>\n      <td>525.0</td>\n      <td>64.0</td>\n      <td>9904.0</td>\n      <td>10365.0</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>twitter_es_vanilla_bal_seed_</td>\n      <td>twitter</td>\n      <td>0.797047</td>\n      <td>0.016549</td>\n      <td>(0.786789594562518, 0.8073037988596702)</td>\n      <td>0.867681</td>\n      <td>0.012040</td>\n      <td>(0.8602187635615669, 0.8751441492098829)</td>\n      <td>0.452028</td>\n      <td>0.014638</td>\n      <td>...</td>\n      <td>0.840683</td>\n      <td>0.035621</td>\n      <td>(0.8186045992182596, 0.8627610571687874)</td>\n      <td>0.874632</td>\n      <td>0.077094</td>\n      <td>(0.8268481619460178, 0.9224149791085426)</td>\n      <td>525.0</td>\n      <td>64.0</td>\n      <td>9904.0</td>\n      <td>10365.0</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>twitter_harass_es_reg_nb0_h1_bal_seed_</td>\n      <td>twitter_harass</td>\n      <td>0.699126</td>\n      <td>0.108810</td>\n      <td>(0.6316849387126151, 0.7665673015302938)</td>\n      <td>0.913960</td>\n      <td>0.096742</td>\n      <td>(0.8539989489968628, 0.9739213422284224)</td>\n      <td>0.724786</td>\n      <td>0.059479</td>\n      <td>...</td>\n      <td>inf</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>inf</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>656.0</td>\n      <td>77.0</td>\n      <td>12847.0</td>\n      <td>13426.0</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>twitter_harass_es_reg_nb5_h5_is_bal_pos_seed_</td>\n      <td>twitter_harass</td>\n      <td>0.798674</td>\n      <td>0.010532</td>\n      <td>(0.7921467442694817, 0.8052019930481517)</td>\n      <td>0.951445</td>\n      <td>0.004280</td>\n      <td>(0.9487928326630026, 0.9540978517512333)</td>\n      <td>0.790119</td>\n      <td>0.007984</td>\n      <td>...</td>\n      <td>41.367705</td>\n      <td>8.509532</td>\n      <td>(36.09344237057658, 46.64196711913195)</td>\n      <td>inf</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>656.0</td>\n      <td>77.0</td>\n      <td>12847.0</td>\n      <td>13426.0</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>twitter_harass_es_vanilla_bal_seed_</td>\n      <td>twitter_harass</td>\n      <td>0.802177</td>\n      <td>0.013758</td>\n      <td>(0.7936501224867812, 0.8107044653825811)</td>\n      <td>0.951767</td>\n      <td>0.005010</td>\n      <td>(0.9486616697289599, 0.9548716952451467)</td>\n      <td>0.793076</td>\n      <td>0.010919</td>\n      <td>...</td>\n      <td>35.196131</td>\n      <td>11.226862</td>\n      <td>(28.23764979208232, 42.15461160470309)</td>\n      <td>inf</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>656.0</td>\n      <td>77.0</td>\n      <td>12847.0</td>\n      <td>13426.0</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>majority_gab_es_reg_nb0_h1_bal_seed_</td>\n      <td>gab</td>\n      <td>0.862108</td>\n      <td>0.012026</td>\n      <td>(0.8546544856593332, 0.8695623818105465)</td>\n      <td>0.874507</td>\n      <td>0.007422</td>\n      <td>(0.8699068385251156, 0.8791072046781914)</td>\n      <td>0.449921</td>\n      <td>0.018215</td>\n      <td>...</td>\n      <td>1.581563</td>\n      <td>0.638837</td>\n      <td>(1.1856077090048187, 1.9775184225582472)</td>\n      <td>inf</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>1657.0</td>\n      <td>1659.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>majority_gab_es_reg_nb5_h5_is_bal_pos_seed_</td>\n      <td>gab</td>\n      <td>0.881928</td>\n      <td>0.020701</td>\n      <td>(0.8690969473006679, 0.8947584743860789)</td>\n      <td>0.886380</td>\n      <td>0.010175</td>\n      <td>(0.8800729619505216, 0.8926863453965002)</td>\n      <td>0.480698</td>\n      <td>0.030686</td>\n      <td>...</td>\n      <td>1.286723</td>\n      <td>0.038792</td>\n      <td>(1.2626797696530172, 1.3107662170699763)</td>\n      <td>inf</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>1657.0</td>\n      <td>1659.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>majority_gab_es_vanilla_bal_seed_</td>\n      <td>gab</td>\n      <td>0.882831</td>\n      <td>0.015758</td>\n      <td>(0.8730642575235151, 0.8925983930788944)</td>\n      <td>0.891738</td>\n      <td>0.007496</td>\n      <td>(0.8870917266629993, 0.8963837414831942)</td>\n      <td>0.488232</td>\n      <td>0.021547</td>\n      <td>...</td>\n      <td>1.582046</td>\n      <td>0.701131</td>\n      <td>(1.1474801485394046, 2.0166115835064615)</td>\n      <td>inf</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>1657.0</td>\n      <td>1659.0</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>ws_es_reg_nb0_h1_bal_seed_</td>\n      <td>ws</td>\n      <td>0.895282</td>\n      <td>0.012831</td>\n      <td>(0.8873287167761869, 0.9032344491294447)</td>\n      <td>0.880330</td>\n      <td>0.009994</td>\n      <td>(0.8741355728690714, 0.8865244461242809)</td>\n      <td>0.547665</td>\n      <td>0.020910</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>ws_es_reg_nb5_h5_is_bal_pos_seed_</td>\n      <td>ws</td>\n      <td>0.898782</td>\n      <td>0.010888</td>\n      <td>(0.8920342011868992, 0.9055304867887476)</td>\n      <td>0.882531</td>\n      <td>0.007200</td>\n      <td>(0.8780681767780336, 0.886993551617028)</td>\n      <td>0.553661</td>\n      <td>0.019914</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>ws_es_vanilla_bal_seed_</td>\n      <td>ws</td>\n      <td>0.908676</td>\n      <td>0.006214</td>\n      <td>(0.9048244305638931, 0.9125271676096227)</td>\n      <td>0.876880</td>\n      <td>0.011693</td>\n      <td>(0.869632653017099, 0.8841280307435848)</td>\n      <td>0.563915</td>\n      <td>0.026242</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>12 rows × 36 columns</p>\n</div>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_to_learner_results = None\n",
    "for task in models_dict.keys():\n",
    "    if task_to_learner_results is None:\n",
    "        task_to_learner_results = temp[(temp['model'].isin(models_dict[task])) & (temp['task'] == task)]\n",
    "    else:\n",
    "        task_to_learner_results = pd.concat([task_to_learner_results, temp[(temp['model'].isin(models_dict[task])) & (temp['task'] == task)]])\n",
    "task_to_learner_results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "other_tasks_results = temp[(temp['model'].isin(models_dict['twitter'])) & (temp['task'].isin({'gab', 'ws', 'twitter_harass', 'nyt'}))]\n",
    "other_tasks_results = pd.concat([other_tasks_results, temp[(temp['model'].isin(models_dict['gab'])) & (temp['task'].isin({'twitter', 'twitter_harass','ws', 'nyt'}))]])\n",
    "other_tasks_results = pd.concat([other_tasks_results, temp[(temp['model'].isin(models_dict['twitter_harass'])) & (temp['task'].isin({'twitter', 'gab', 'ws', 'nyt'}))]])\n",
    "other_tasks_results = pd.concat([other_tasks_results, temp[(temp['model'].isin(models_dict['ws'])) & (temp['task'].isin({'twitter', 'twitter_harass','gab', 'nyt'}))]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "                                            model     task  acc_mean  \\\n12                twitter_es_reg_nb0_h1_bal_seed_      gab  0.628976   \n13                twitter_es_reg_nb0_h1_bal_seed_      nyt  0.692862   \n15                twitter_es_reg_nb0_h1_bal_seed_       ws  0.742009   \n16         twitter_es_reg_nb5_h5_is_bal_pos_seed_      gab  0.697771   \n17         twitter_es_reg_nb5_h5_is_bal_pos_seed_      nyt  0.794993   \n19         twitter_es_reg_nb5_h5_is_bal_pos_seed_       ws  0.771081   \n20                   twitter_es_vanilla_bal_seed_      gab  0.766506   \n21                   twitter_es_vanilla_bal_seed_      nyt  0.639087   \n23                   twitter_es_vanilla_bal_seed_       ws  0.770015   \n1            majority_gab_es_reg_nb0_h1_bal_seed_      nyt  0.917362   \n2            majority_gab_es_reg_nb0_h1_bal_seed_  twitter  0.799079   \n3            majority_gab_es_reg_nb0_h1_bal_seed_       ws  0.872146   \n5     majority_gab_es_reg_nb5_h5_is_bal_pos_seed_      nyt  0.872833   \n6     majority_gab_es_reg_nb5_h5_is_bal_pos_seed_  twitter  0.827117   \n7     majority_gab_es_reg_nb5_h5_is_bal_pos_seed_       ws  0.866667   \n9               majority_gab_es_vanilla_bal_seed_      nyt  0.783710   \n10              majority_gab_es_vanilla_bal_seed_  twitter  0.826139   \n11              majority_gab_es_vanilla_bal_seed_       ws  0.855251   \n24         twitter_harass_es_reg_nb0_h1_bal_seed_      gab  0.379699   \n25         twitter_harass_es_reg_nb0_h1_bal_seed_      nyt  0.514942   \n26         twitter_harass_es_reg_nb0_h1_bal_seed_  twitter  0.406118   \n28         twitter_harass_es_reg_nb0_h1_bal_seed_       ws  0.446119   \n29  twitter_harass_es_reg_nb5_h5_is_bal_pos_seed_      gab  0.560843   \n30  twitter_harass_es_reg_nb5_h5_is_bal_pos_seed_      nyt  0.788420   \n31  twitter_harass_es_reg_nb5_h5_is_bal_pos_seed_  twitter  0.509243   \n33  twitter_harass_es_reg_nb5_h5_is_bal_pos_seed_       ws  0.638661   \n34            twitter_harass_es_vanilla_bal_seed_      gab  0.602169   \n35            twitter_harass_es_vanilla_bal_seed_      nyt  0.670174   \n36            twitter_harass_es_vanilla_bal_seed_  twitter  0.517413   \n38            twitter_harass_es_vanilla_bal_seed_       ws  0.645662   \n39                     ws_es_reg_nb0_h1_bal_seed_      gab  0.864157   \n40                     ws_es_reg_nb0_h1_bal_seed_      nyt  0.950290   \n41                     ws_es_reg_nb0_h1_bal_seed_  twitter  0.837789   \n43              ws_es_reg_nb5_h5_is_bal_pos_seed_      gab  0.876506   \n44              ws_es_reg_nb5_h5_is_bal_pos_seed_      nyt  0.946913   \n45              ws_es_reg_nb5_h5_is_bal_pos_seed_  twitter  0.839908   \n47                        ws_es_vanilla_bal_seed_      gab  0.886506   \n48                        ws_es_vanilla_bal_seed_      nyt  0.925312   \n49                        ws_es_vanilla_bal_seed_  twitter  0.852622   \n\n     acc_std                                    acc_ci  auc_roc_mean  \\\n12  0.036343   (0.6064502124205815, 0.651501594808334)      0.818889   \n13  0.067703  (0.6508996380141923, 0.7348249996669673)      0.000000   \n15  0.025167  (0.7264106936761919, 0.7576075711639908)      0.748519   \n16  0.047310  (0.6684477917724448, 0.7270943769022539)      0.821897   \n17  0.068235  (0.7527000530041628, 0.8372854542422141)      0.000000   \n19  0.030103  (0.7524226540514041, 0.7897386853702091)      0.750957   \n20  0.026450  (0.7501121545689884, 0.7828998936237828)      0.856527   \n21  0.088046  (0.5845155413088085, 0.6936583717346699)      0.000000   \n23  0.025544  (0.7541827073545508, 0.7858477340457535)      0.781363   \n1   0.024158  (0.9023890204927413, 0.9323356171884182)      0.000000   \n2   0.017829  (0.7880290003327614, 0.8101299794351934)      0.739081   \n3   0.009383  (0.8663306797820927, 0.8779615576608297)      0.828538   \n5   0.039768   (0.848184690859489, 0.8974819758071777)      0.000000   \n6   0.020782  (0.8142356392423945, 0.8399977484266054)      0.742117   \n7   0.012307   (0.8590387528229122, 0.874294580510421)      0.831201   \n9   0.082726  (0.7324361957562131, 0.8349840940988593)      0.000000   \n10  0.024281  (0.8110894393905235, 0.8411878642819284)      0.765980   \n11  0.019379  (0.8432400574146646, 0.8672622256903582)      0.817381   \n24  0.095714  (0.3203747184857717, 0.4390228718756741)      0.742436   \n25  0.152156  (0.4206346927711272, 0.6092493651998875)      0.000000   \n26  0.105845  (0.3405144276676427, 0.4717206859578248)      0.632587   \n28  0.117335  (0.3733935018879902, 0.5188439410343842)      0.675195   \n29  0.039372  (0.5364404975067922, 0.5852462494811594)      0.777038   \n30  0.074252  (0.7423986963211718, 0.8344418833889732)      0.000000   \n31  0.014008   (0.5005610762980869, 0.517925835198701)      0.665595   \n33  0.030009  (0.6200609537697843, 0.6572602030034271)      0.700591   \n34  0.036257  (0.5796961682181324, 0.6246411811794578)      0.804706   \n35  0.136414  (0.5856235273886329, 0.7547242986983235)      0.000000   \n36  0.016805  (0.5069968279531226, 0.5278291381030668)      0.671612   \n38  0.045367  (0.6175434173891281, 0.6737807835241136)      0.752339   \n39  0.015398  (0.8546125512364103, 0.8737007017756379)      0.831959   \n40  0.018182    (0.9390205514168576, 0.96155915872807)      0.000000   \n41  0.016418  (0.8276130445855631, 0.8479646713987116)      0.703172   \n43  0.017684   (0.8655451389050631, 0.887466909287708)      0.820443   \n44  0.021891    (0.933344683125569, 0.960481403830953)      0.000000   \n45  0.015874  (0.8300692747146365, 0.8497466232621589)      0.668893   \n47  0.009150   (0.880834729090929, 0.8921773191018424)      0.824919   \n48  0.032900  (0.9049199483400787, 0.9457032400657184)      0.000000   \n49  0.011199  (0.8456814051444388, 0.8595635847874818)      0.682889   \n\n    auc_roc_std                                auc_roc_ci   f1_mean    f1_std  \\\n12     0.007008  (0.8145454343478087, 0.8232331002209861)  0.276995  0.014425   \n13     0.000000                                (0.0, 0.0)  0.000000  0.000000   \n15     0.014860   (0.739308099673421, 0.7577289373636157)  0.333568  0.027191   \n16     0.006244  (0.8180272449425315, 0.8257673052161579)  0.310001  0.022413   \n17     0.000000                                (0.0, 0.0)  0.000000  0.000000   \n19     0.017452   (0.740140144293877, 0.7617734359530367)  0.336322  0.026036   \n20     0.003998  (0.8540483260302403, 0.8590049000279665)  0.365528  0.015665   \n21     0.000000                                (0.0, 0.0)  0.000000  0.000000   \n23     0.007915  (0.7764569630741037, 0.7862685829847756)  0.367121  0.020248   \n1      0.000000                                (0.0, 0.0)  0.000000  0.000000   \n2      0.009118  (0.7334297289437248, 0.7447327526196015)  0.310914  0.016020   \n3      0.010412   (0.822084203132161, 0.8349908206095297)  0.462081  0.043819   \n5      0.000000                                (0.0, 0.0)  0.000000  0.000000   \n6      0.008340  (0.7369475537143811, 0.7472862318210093)  0.338319  0.016135   \n7      0.010391  (0.8247609941413466, 0.8376416649279793)  0.456342  0.021947   \n9      0.000000                                (0.0, 0.0)  0.000000  0.000000   \n10     0.012306  (0.7583530118646027, 0.7736074387796548)  0.364111  0.023082   \n11     0.014362  (0.8084793695094268, 0.8262832135864895)  0.444361  0.033555   \n24     0.068906   (0.6997275726981227, 0.785144647868619)  0.206410  0.020160   \n25     0.000000                                (0.0, 0.0)  0.000000  0.000000   \n26     0.054127  (0.5990382481337116, 0.6661351030052333)  0.258826  0.024589   \n28     0.030385  (0.6563619978598194, 0.6940273658628775)  0.249156  0.021532   \n29     0.012195  (0.7694790245808799, 0.7845960585478834)  0.247210  0.010643   \n30     0.000000                                (0.0, 0.0)  0.000000  0.000000   \n31     0.009027   (0.6600004388941796, 0.671190202289641)  0.283021  0.006467   \n33     0.027587  (0.6834927972414768, 0.7176895389408593)  0.277852  0.022509   \n34     0.014344  (0.7958156887433998, 0.8135964265347919)  0.274922  0.013678   \n35     0.000000                                (0.0, 0.0)  0.000000  0.000000   \n36     0.005114  (0.6684420221495045, 0.6747810040427719)  0.290563  0.006767   \n38     0.027014  (0.7355953062433136, 0.7690818067671328)  0.310706  0.014215   \n39     0.009972  (0.8257782144034154, 0.8381394088943963)  0.389587  0.016350   \n40     0.000000                                (0.0, 0.0)  0.000000  0.000000   \n41     0.011715  (0.6959110560752069, 0.7104336283354482)  0.240423  0.018180   \n43     0.007849  (0.8155782147433719, 0.8253083659329152)  0.404088  0.018860   \n44     0.000000                                (0.0, 0.0)  0.000000  0.000000   \n45     0.013680  (0.6604144330821795, 0.6773719489549745)  0.236558  0.030968   \n47     0.014433  (0.8159736343584921, 0.8338643650644545)  0.411479  0.013811   \n48     0.000000                                (0.0, 0.0)  0.000000  0.000000   \n49     0.021370  (0.6696437944150544, 0.6961348786190702)  0.254986  0.025921   \n\n    ... disparate_impact_06_mean  disparate_impact_06_std  \\\n12  ...                 0.856639                 0.060978   \n13  ...                      NaN                      NaN   \n15  ...                      NaN                      NaN   \n16  ...                 1.219403                 0.461532   \n17  ...                      NaN                      NaN   \n19  ...                      NaN                      NaN   \n20  ...                 1.142336                 0.538762   \n21  ...                      NaN                      NaN   \n23  ...                      NaN                      NaN   \n1   ...                      NaN                      NaN   \n2   ...                 1.757463                 0.192340   \n3   ...                      NaN                      NaN   \n5   ...                      NaN                      NaN   \n6   ...                 1.484461                 0.201475   \n7   ...                      NaN                      NaN   \n9   ...                      NaN                      NaN   \n10  ...                 1.395322                 0.214769   \n11  ...                      NaN                      NaN   \n24  ...                      inf                      NaN   \n25  ...                      NaN                      NaN   \n26  ...                      inf                      NaN   \n28  ...                      NaN                      NaN   \n29  ...                 1.503440                 0.136999   \n30  ...                      NaN                      NaN   \n31  ...                53.686251                13.176558   \n33  ...                      NaN                      NaN   \n34  ...                 1.608087                 0.125840   \n35  ...                      NaN                      NaN   \n36  ...                47.484888                12.397625   \n38  ...                      NaN                      NaN   \n39  ...                 1.422269                 0.652811   \n40  ...                      NaN                      NaN   \n41  ...                 1.312394                 0.111740   \n43  ...                 1.184882                 0.219707   \n44  ...                      NaN                      NaN   \n45  ...                 1.314945                 0.110908   \n47  ...                 1.736451                 0.822002   \n48  ...                      NaN                      NaN   \n49  ...                 1.148876                 0.065224   \n\n                      disparate_impact_06_ci disparate_impact_08_mean  \\\n12  (0.8188442563563496, 0.8944327502821539)                      inf   \n13                                (nan, nan)                      NaN   \n15                                (nan, nan)                      NaN   \n16  (0.9333420557721496, 1.5054630136303855)                      inf   \n17                                (nan, nan)                      NaN   \n19                                (nan, nan)                      NaN   \n20  (0.8084076131365296, 1.4762634791990161)                      inf   \n21                                (nan, nan)                      NaN   \n23                                (nan, nan)                      NaN   \n1                                 (nan, nan)                      NaN   \n2   (1.6382492846163017, 1.8766758280603493)                 2.507590   \n3                                 (nan, nan)                      NaN   \n5                                 (nan, nan)                      NaN   \n6    (1.359585089673893, 1.6093359280251855)                 2.070144   \n7                                 (nan, nan)                      NaN   \n9                                 (nan, nan)                      NaN   \n10   (1.2622069849227628, 1.528437971842096)                 1.886746   \n11                                (nan, nan)                      NaN   \n24                                (nan, nan)                      inf   \n25                                (nan, nan)                      NaN   \n26                                (nan, nan)                      inf   \n28                                (nan, nan)                      NaN   \n29   (1.418527037234916, 1.5883528662050364)                      inf   \n30                                (nan, nan)                      NaN   \n31    (45.51933526788563, 61.85316574180741)                      inf   \n33                                (nan, nan)                      NaN   \n34  (1.5300901852478757, 1.6860836228390288)                      inf   \n35                                (nan, nan)                      NaN   \n36    (39.80076077659822, 55.16901574467264)                      inf   \n38                                (nan, nan)                      NaN   \n39  (1.0176524195040277, 1.8268859027651339)                      inf   \n40                                (nan, nan)                      NaN   \n41  (1.2431365385628228, 1.3816505491772186)                 1.604506   \n43     (1.04870648399513, 1.321058150887188)                      inf   \n44                                (nan, nan)                      NaN   \n45   (1.2462035176620634, 1.383685913577819)                 1.617468   \n47   (1.2269691864052354, 2.245933650046182)                      inf   \n48                                (nan, nan)                      NaN   \n49  (1.1084497942979241, 1.1893017272230977)                 1.425536   \n\n    disparate_impact_08_std                    disparate_impact_08_ci  \\\n12                      NaN                                (nan, nan)   \n13                      NaN                                (nan, nan)   \n15                      NaN                                (nan, nan)   \n16                      NaN                                (nan, nan)   \n17                      NaN                                (nan, nan)   \n19                      NaN                                (nan, nan)   \n20                      NaN                                (nan, nan)   \n21                      NaN                                (nan, nan)   \n23                      NaN                                (nan, nan)   \n1                       NaN                                (nan, nan)   \n2                  0.451256  (2.2278989080454092, 2.7872813465869815)   \n3                       NaN                                (nan, nan)   \n5                       NaN                                (nan, nan)   \n6                  0.510267   (1.753876940510465, 2.3864110749132044)   \n7                       NaN                                (nan, nan)   \n9                       NaN                                (nan, nan)   \n10                 0.465513  (1.5982180553720318, 2.1752740423674437)   \n11                      NaN                                (nan, nan)   \n24                      NaN                                (nan, nan)   \n25                      NaN                                (nan, nan)   \n26                      NaN                                (nan, nan)   \n28                      NaN                                (nan, nan)   \n29                      NaN                                (nan, nan)   \n30                      NaN                                (nan, nan)   \n31                      NaN                                (nan, nan)   \n33                      NaN                                (nan, nan)   \n34                      NaN                                (nan, nan)   \n35                      NaN                                (nan, nan)   \n36                      NaN                                (nan, nan)   \n38                      NaN                                (nan, nan)   \n39                      NaN                                (nan, nan)   \n40                      NaN                                (nan, nan)   \n41                 0.102379   (1.5410506382865614, 1.667961196666625)   \n43                      NaN                                (nan, nan)   \n44                      NaN                                (nan, nan)   \n45                 0.223165  (1.4791492612021604, 1.7557876735994413)   \n47                      NaN                                (nan, nan)   \n48                      NaN                                (nan, nan)   \n49                 0.130200  (1.3448370255274684, 1.5062350348675102)   \n\n   priv_n_06  priv_n_08  unpriv_n_06 unpriv_n_08  \n12       3.0        1.0       1657.0      1659.0  \n13       NaN        NaN          NaN         NaN  \n15       NaN        NaN          NaN         NaN  \n16       3.0        1.0       1657.0      1659.0  \n17       NaN        NaN          NaN         NaN  \n19       NaN        NaN          NaN         NaN  \n20       3.0        1.0       1657.0      1659.0  \n21       NaN        NaN          NaN         NaN  \n23       NaN        NaN          NaN         NaN  \n1        NaN        NaN          NaN         NaN  \n2      525.0       64.0       9904.0     10365.0  \n3        NaN        NaN          NaN         NaN  \n5        NaN        NaN          NaN         NaN  \n6      525.0       64.0       9904.0     10365.0  \n7        NaN        NaN          NaN         NaN  \n9        NaN        NaN          NaN         NaN  \n10     525.0       64.0       9904.0     10365.0  \n11       NaN        NaN          NaN         NaN  \n24       3.0        1.0       1657.0      1659.0  \n25       NaN        NaN          NaN         NaN  \n26     525.0       64.0       9904.0     10365.0  \n28       NaN        NaN          NaN         NaN  \n29       3.0        1.0       1657.0      1659.0  \n30       NaN        NaN          NaN         NaN  \n31     525.0       64.0       9904.0     10365.0  \n33       NaN        NaN          NaN         NaN  \n34       3.0        1.0       1657.0      1659.0  \n35       NaN        NaN          NaN         NaN  \n36     525.0       64.0       9904.0     10365.0  \n38       NaN        NaN          NaN         NaN  \n39       3.0        1.0       1657.0      1659.0  \n40       NaN        NaN          NaN         NaN  \n41     525.0       64.0       9904.0     10365.0  \n43       3.0        1.0       1657.0      1659.0  \n44       NaN        NaN          NaN         NaN  \n45     525.0       64.0       9904.0     10365.0  \n47       3.0        1.0       1657.0      1659.0  \n48       NaN        NaN          NaN         NaN  \n49     525.0       64.0       9904.0     10365.0  \n\n[39 rows x 36 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>task</th>\n      <th>acc_mean</th>\n      <th>acc_std</th>\n      <th>acc_ci</th>\n      <th>auc_roc_mean</th>\n      <th>auc_roc_std</th>\n      <th>auc_roc_ci</th>\n      <th>f1_mean</th>\n      <th>f1_std</th>\n      <th>...</th>\n      <th>disparate_impact_06_mean</th>\n      <th>disparate_impact_06_std</th>\n      <th>disparate_impact_06_ci</th>\n      <th>disparate_impact_08_mean</th>\n      <th>disparate_impact_08_std</th>\n      <th>disparate_impact_08_ci</th>\n      <th>priv_n_06</th>\n      <th>priv_n_08</th>\n      <th>unpriv_n_06</th>\n      <th>unpriv_n_08</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>12</th>\n      <td>twitter_es_reg_nb0_h1_bal_seed_</td>\n      <td>gab</td>\n      <td>0.628976</td>\n      <td>0.036343</td>\n      <td>(0.6064502124205815, 0.651501594808334)</td>\n      <td>0.818889</td>\n      <td>0.007008</td>\n      <td>(0.8145454343478087, 0.8232331002209861)</td>\n      <td>0.276995</td>\n      <td>0.014425</td>\n      <td>...</td>\n      <td>0.856639</td>\n      <td>0.060978</td>\n      <td>(0.8188442563563496, 0.8944327502821539)</td>\n      <td>inf</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>1657.0</td>\n      <td>1659.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>twitter_es_reg_nb0_h1_bal_seed_</td>\n      <td>nyt</td>\n      <td>0.692862</td>\n      <td>0.067703</td>\n      <td>(0.6508996380141923, 0.7348249996669673)</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>(0.0, 0.0)</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>twitter_es_reg_nb0_h1_bal_seed_</td>\n      <td>ws</td>\n      <td>0.742009</td>\n      <td>0.025167</td>\n      <td>(0.7264106936761919, 0.7576075711639908)</td>\n      <td>0.748519</td>\n      <td>0.014860</td>\n      <td>(0.739308099673421, 0.7577289373636157)</td>\n      <td>0.333568</td>\n      <td>0.027191</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>twitter_es_reg_nb5_h5_is_bal_pos_seed_</td>\n      <td>gab</td>\n      <td>0.697771</td>\n      <td>0.047310</td>\n      <td>(0.6684477917724448, 0.7270943769022539)</td>\n      <td>0.821897</td>\n      <td>0.006244</td>\n      <td>(0.8180272449425315, 0.8257673052161579)</td>\n      <td>0.310001</td>\n      <td>0.022413</td>\n      <td>...</td>\n      <td>1.219403</td>\n      <td>0.461532</td>\n      <td>(0.9333420557721496, 1.5054630136303855)</td>\n      <td>inf</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>1657.0</td>\n      <td>1659.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>twitter_es_reg_nb5_h5_is_bal_pos_seed_</td>\n      <td>nyt</td>\n      <td>0.794993</td>\n      <td>0.068235</td>\n      <td>(0.7527000530041628, 0.8372854542422141)</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>(0.0, 0.0)</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>twitter_es_reg_nb5_h5_is_bal_pos_seed_</td>\n      <td>ws</td>\n      <td>0.771081</td>\n      <td>0.030103</td>\n      <td>(0.7524226540514041, 0.7897386853702091)</td>\n      <td>0.750957</td>\n      <td>0.017452</td>\n      <td>(0.740140144293877, 0.7617734359530367)</td>\n      <td>0.336322</td>\n      <td>0.026036</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>twitter_es_vanilla_bal_seed_</td>\n      <td>gab</td>\n      <td>0.766506</td>\n      <td>0.026450</td>\n      <td>(0.7501121545689884, 0.7828998936237828)</td>\n      <td>0.856527</td>\n      <td>0.003998</td>\n      <td>(0.8540483260302403, 0.8590049000279665)</td>\n      <td>0.365528</td>\n      <td>0.015665</td>\n      <td>...</td>\n      <td>1.142336</td>\n      <td>0.538762</td>\n      <td>(0.8084076131365296, 1.4762634791990161)</td>\n      <td>inf</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>1657.0</td>\n      <td>1659.0</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>twitter_es_vanilla_bal_seed_</td>\n      <td>nyt</td>\n      <td>0.639087</td>\n      <td>0.088046</td>\n      <td>(0.5845155413088085, 0.6936583717346699)</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>(0.0, 0.0)</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>twitter_es_vanilla_bal_seed_</td>\n      <td>ws</td>\n      <td>0.770015</td>\n      <td>0.025544</td>\n      <td>(0.7541827073545508, 0.7858477340457535)</td>\n      <td>0.781363</td>\n      <td>0.007915</td>\n      <td>(0.7764569630741037, 0.7862685829847756)</td>\n      <td>0.367121</td>\n      <td>0.020248</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>majority_gab_es_reg_nb0_h1_bal_seed_</td>\n      <td>nyt</td>\n      <td>0.917362</td>\n      <td>0.024158</td>\n      <td>(0.9023890204927413, 0.9323356171884182)</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>(0.0, 0.0)</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>majority_gab_es_reg_nb0_h1_bal_seed_</td>\n      <td>twitter</td>\n      <td>0.799079</td>\n      <td>0.017829</td>\n      <td>(0.7880290003327614, 0.8101299794351934)</td>\n      <td>0.739081</td>\n      <td>0.009118</td>\n      <td>(0.7334297289437248, 0.7447327526196015)</td>\n      <td>0.310914</td>\n      <td>0.016020</td>\n      <td>...</td>\n      <td>1.757463</td>\n      <td>0.192340</td>\n      <td>(1.6382492846163017, 1.8766758280603493)</td>\n      <td>2.507590</td>\n      <td>0.451256</td>\n      <td>(2.2278989080454092, 2.7872813465869815)</td>\n      <td>525.0</td>\n      <td>64.0</td>\n      <td>9904.0</td>\n      <td>10365.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>majority_gab_es_reg_nb0_h1_bal_seed_</td>\n      <td>ws</td>\n      <td>0.872146</td>\n      <td>0.009383</td>\n      <td>(0.8663306797820927, 0.8779615576608297)</td>\n      <td>0.828538</td>\n      <td>0.010412</td>\n      <td>(0.822084203132161, 0.8349908206095297)</td>\n      <td>0.462081</td>\n      <td>0.043819</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>majority_gab_es_reg_nb5_h5_is_bal_pos_seed_</td>\n      <td>nyt</td>\n      <td>0.872833</td>\n      <td>0.039768</td>\n      <td>(0.848184690859489, 0.8974819758071777)</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>(0.0, 0.0)</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>majority_gab_es_reg_nb5_h5_is_bal_pos_seed_</td>\n      <td>twitter</td>\n      <td>0.827117</td>\n      <td>0.020782</td>\n      <td>(0.8142356392423945, 0.8399977484266054)</td>\n      <td>0.742117</td>\n      <td>0.008340</td>\n      <td>(0.7369475537143811, 0.7472862318210093)</td>\n      <td>0.338319</td>\n      <td>0.016135</td>\n      <td>...</td>\n      <td>1.484461</td>\n      <td>0.201475</td>\n      <td>(1.359585089673893, 1.6093359280251855)</td>\n      <td>2.070144</td>\n      <td>0.510267</td>\n      <td>(1.753876940510465, 2.3864110749132044)</td>\n      <td>525.0</td>\n      <td>64.0</td>\n      <td>9904.0</td>\n      <td>10365.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>majority_gab_es_reg_nb5_h5_is_bal_pos_seed_</td>\n      <td>ws</td>\n      <td>0.866667</td>\n      <td>0.012307</td>\n      <td>(0.8590387528229122, 0.874294580510421)</td>\n      <td>0.831201</td>\n      <td>0.010391</td>\n      <td>(0.8247609941413466, 0.8376416649279793)</td>\n      <td>0.456342</td>\n      <td>0.021947</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>majority_gab_es_vanilla_bal_seed_</td>\n      <td>nyt</td>\n      <td>0.783710</td>\n      <td>0.082726</td>\n      <td>(0.7324361957562131, 0.8349840940988593)</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>(0.0, 0.0)</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>majority_gab_es_vanilla_bal_seed_</td>\n      <td>twitter</td>\n      <td>0.826139</td>\n      <td>0.024281</td>\n      <td>(0.8110894393905235, 0.8411878642819284)</td>\n      <td>0.765980</td>\n      <td>0.012306</td>\n      <td>(0.7583530118646027, 0.7736074387796548)</td>\n      <td>0.364111</td>\n      <td>0.023082</td>\n      <td>...</td>\n      <td>1.395322</td>\n      <td>0.214769</td>\n      <td>(1.2622069849227628, 1.528437971842096)</td>\n      <td>1.886746</td>\n      <td>0.465513</td>\n      <td>(1.5982180553720318, 2.1752740423674437)</td>\n      <td>525.0</td>\n      <td>64.0</td>\n      <td>9904.0</td>\n      <td>10365.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>majority_gab_es_vanilla_bal_seed_</td>\n      <td>ws</td>\n      <td>0.855251</td>\n      <td>0.019379</td>\n      <td>(0.8432400574146646, 0.8672622256903582)</td>\n      <td>0.817381</td>\n      <td>0.014362</td>\n      <td>(0.8084793695094268, 0.8262832135864895)</td>\n      <td>0.444361</td>\n      <td>0.033555</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>twitter_harass_es_reg_nb0_h1_bal_seed_</td>\n      <td>gab</td>\n      <td>0.379699</td>\n      <td>0.095714</td>\n      <td>(0.3203747184857717, 0.4390228718756741)</td>\n      <td>0.742436</td>\n      <td>0.068906</td>\n      <td>(0.6997275726981227, 0.785144647868619)</td>\n      <td>0.206410</td>\n      <td>0.020160</td>\n      <td>...</td>\n      <td>inf</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>inf</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>1657.0</td>\n      <td>1659.0</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>twitter_harass_es_reg_nb0_h1_bal_seed_</td>\n      <td>nyt</td>\n      <td>0.514942</td>\n      <td>0.152156</td>\n      <td>(0.4206346927711272, 0.6092493651998875)</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>(0.0, 0.0)</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>twitter_harass_es_reg_nb0_h1_bal_seed_</td>\n      <td>twitter</td>\n      <td>0.406118</td>\n      <td>0.105845</td>\n      <td>(0.3405144276676427, 0.4717206859578248)</td>\n      <td>0.632587</td>\n      <td>0.054127</td>\n      <td>(0.5990382481337116, 0.6661351030052333)</td>\n      <td>0.258826</td>\n      <td>0.024589</td>\n      <td>...</td>\n      <td>inf</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>inf</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>525.0</td>\n      <td>64.0</td>\n      <td>9904.0</td>\n      <td>10365.0</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>twitter_harass_es_reg_nb0_h1_bal_seed_</td>\n      <td>ws</td>\n      <td>0.446119</td>\n      <td>0.117335</td>\n      <td>(0.3733935018879902, 0.5188439410343842)</td>\n      <td>0.675195</td>\n      <td>0.030385</td>\n      <td>(0.6563619978598194, 0.6940273658628775)</td>\n      <td>0.249156</td>\n      <td>0.021532</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>twitter_harass_es_reg_nb5_h5_is_bal_pos_seed_</td>\n      <td>gab</td>\n      <td>0.560843</td>\n      <td>0.039372</td>\n      <td>(0.5364404975067922, 0.5852462494811594)</td>\n      <td>0.777038</td>\n      <td>0.012195</td>\n      <td>(0.7694790245808799, 0.7845960585478834)</td>\n      <td>0.247210</td>\n      <td>0.010643</td>\n      <td>...</td>\n      <td>1.503440</td>\n      <td>0.136999</td>\n      <td>(1.418527037234916, 1.5883528662050364)</td>\n      <td>inf</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>1657.0</td>\n      <td>1659.0</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>twitter_harass_es_reg_nb5_h5_is_bal_pos_seed_</td>\n      <td>nyt</td>\n      <td>0.788420</td>\n      <td>0.074252</td>\n      <td>(0.7423986963211718, 0.8344418833889732)</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>(0.0, 0.0)</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>twitter_harass_es_reg_nb5_h5_is_bal_pos_seed_</td>\n      <td>twitter</td>\n      <td>0.509243</td>\n      <td>0.014008</td>\n      <td>(0.5005610762980869, 0.517925835198701)</td>\n      <td>0.665595</td>\n      <td>0.009027</td>\n      <td>(0.6600004388941796, 0.671190202289641)</td>\n      <td>0.283021</td>\n      <td>0.006467</td>\n      <td>...</td>\n      <td>53.686251</td>\n      <td>13.176558</td>\n      <td>(45.51933526788563, 61.85316574180741)</td>\n      <td>inf</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>525.0</td>\n      <td>64.0</td>\n      <td>9904.0</td>\n      <td>10365.0</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>twitter_harass_es_reg_nb5_h5_is_bal_pos_seed_</td>\n      <td>ws</td>\n      <td>0.638661</td>\n      <td>0.030009</td>\n      <td>(0.6200609537697843, 0.6572602030034271)</td>\n      <td>0.700591</td>\n      <td>0.027587</td>\n      <td>(0.6834927972414768, 0.7176895389408593)</td>\n      <td>0.277852</td>\n      <td>0.022509</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>twitter_harass_es_vanilla_bal_seed_</td>\n      <td>gab</td>\n      <td>0.602169</td>\n      <td>0.036257</td>\n      <td>(0.5796961682181324, 0.6246411811794578)</td>\n      <td>0.804706</td>\n      <td>0.014344</td>\n      <td>(0.7958156887433998, 0.8135964265347919)</td>\n      <td>0.274922</td>\n      <td>0.013678</td>\n      <td>...</td>\n      <td>1.608087</td>\n      <td>0.125840</td>\n      <td>(1.5300901852478757, 1.6860836228390288)</td>\n      <td>inf</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>1657.0</td>\n      <td>1659.0</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>twitter_harass_es_vanilla_bal_seed_</td>\n      <td>nyt</td>\n      <td>0.670174</td>\n      <td>0.136414</td>\n      <td>(0.5856235273886329, 0.7547242986983235)</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>(0.0, 0.0)</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>twitter_harass_es_vanilla_bal_seed_</td>\n      <td>twitter</td>\n      <td>0.517413</td>\n      <td>0.016805</td>\n      <td>(0.5069968279531226, 0.5278291381030668)</td>\n      <td>0.671612</td>\n      <td>0.005114</td>\n      <td>(0.6684420221495045, 0.6747810040427719)</td>\n      <td>0.290563</td>\n      <td>0.006767</td>\n      <td>...</td>\n      <td>47.484888</td>\n      <td>12.397625</td>\n      <td>(39.80076077659822, 55.16901574467264)</td>\n      <td>inf</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>525.0</td>\n      <td>64.0</td>\n      <td>9904.0</td>\n      <td>10365.0</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>twitter_harass_es_vanilla_bal_seed_</td>\n      <td>ws</td>\n      <td>0.645662</td>\n      <td>0.045367</td>\n      <td>(0.6175434173891281, 0.6737807835241136)</td>\n      <td>0.752339</td>\n      <td>0.027014</td>\n      <td>(0.7355953062433136, 0.7690818067671328)</td>\n      <td>0.310706</td>\n      <td>0.014215</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>ws_es_reg_nb0_h1_bal_seed_</td>\n      <td>gab</td>\n      <td>0.864157</td>\n      <td>0.015398</td>\n      <td>(0.8546125512364103, 0.8737007017756379)</td>\n      <td>0.831959</td>\n      <td>0.009972</td>\n      <td>(0.8257782144034154, 0.8381394088943963)</td>\n      <td>0.389587</td>\n      <td>0.016350</td>\n      <td>...</td>\n      <td>1.422269</td>\n      <td>0.652811</td>\n      <td>(1.0176524195040277, 1.8268859027651339)</td>\n      <td>inf</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>1657.0</td>\n      <td>1659.0</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>ws_es_reg_nb0_h1_bal_seed_</td>\n      <td>nyt</td>\n      <td>0.950290</td>\n      <td>0.018182</td>\n      <td>(0.9390205514168576, 0.96155915872807)</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>(0.0, 0.0)</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>ws_es_reg_nb0_h1_bal_seed_</td>\n      <td>twitter</td>\n      <td>0.837789</td>\n      <td>0.016418</td>\n      <td>(0.8276130445855631, 0.8479646713987116)</td>\n      <td>0.703172</td>\n      <td>0.011715</td>\n      <td>(0.6959110560752069, 0.7104336283354482)</td>\n      <td>0.240423</td>\n      <td>0.018180</td>\n      <td>...</td>\n      <td>1.312394</td>\n      <td>0.111740</td>\n      <td>(1.2431365385628228, 1.3816505491772186)</td>\n      <td>1.604506</td>\n      <td>0.102379</td>\n      <td>(1.5410506382865614, 1.667961196666625)</td>\n      <td>525.0</td>\n      <td>64.0</td>\n      <td>9904.0</td>\n      <td>10365.0</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>ws_es_reg_nb5_h5_is_bal_pos_seed_</td>\n      <td>gab</td>\n      <td>0.876506</td>\n      <td>0.017684</td>\n      <td>(0.8655451389050631, 0.887466909287708)</td>\n      <td>0.820443</td>\n      <td>0.007849</td>\n      <td>(0.8155782147433719, 0.8253083659329152)</td>\n      <td>0.404088</td>\n      <td>0.018860</td>\n      <td>...</td>\n      <td>1.184882</td>\n      <td>0.219707</td>\n      <td>(1.04870648399513, 1.321058150887188)</td>\n      <td>inf</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>1657.0</td>\n      <td>1659.0</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>ws_es_reg_nb5_h5_is_bal_pos_seed_</td>\n      <td>nyt</td>\n      <td>0.946913</td>\n      <td>0.021891</td>\n      <td>(0.933344683125569, 0.960481403830953)</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>(0.0, 0.0)</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>ws_es_reg_nb5_h5_is_bal_pos_seed_</td>\n      <td>twitter</td>\n      <td>0.839908</td>\n      <td>0.015874</td>\n      <td>(0.8300692747146365, 0.8497466232621589)</td>\n      <td>0.668893</td>\n      <td>0.013680</td>\n      <td>(0.6604144330821795, 0.6773719489549745)</td>\n      <td>0.236558</td>\n      <td>0.030968</td>\n      <td>...</td>\n      <td>1.314945</td>\n      <td>0.110908</td>\n      <td>(1.2462035176620634, 1.383685913577819)</td>\n      <td>1.617468</td>\n      <td>0.223165</td>\n      <td>(1.4791492612021604, 1.7557876735994413)</td>\n      <td>525.0</td>\n      <td>64.0</td>\n      <td>9904.0</td>\n      <td>10365.0</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>ws_es_vanilla_bal_seed_</td>\n      <td>gab</td>\n      <td>0.886506</td>\n      <td>0.009150</td>\n      <td>(0.880834729090929, 0.8921773191018424)</td>\n      <td>0.824919</td>\n      <td>0.014433</td>\n      <td>(0.8159736343584921, 0.8338643650644545)</td>\n      <td>0.411479</td>\n      <td>0.013811</td>\n      <td>...</td>\n      <td>1.736451</td>\n      <td>0.822002</td>\n      <td>(1.2269691864052354, 2.245933650046182)</td>\n      <td>inf</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>1657.0</td>\n      <td>1659.0</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>ws_es_vanilla_bal_seed_</td>\n      <td>nyt</td>\n      <td>0.925312</td>\n      <td>0.032900</td>\n      <td>(0.9049199483400787, 0.9457032400657184)</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>(0.0, 0.0)</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>(nan, nan)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>ws_es_vanilla_bal_seed_</td>\n      <td>twitter</td>\n      <td>0.852622</td>\n      <td>0.011199</td>\n      <td>(0.8456814051444388, 0.8595635847874818)</td>\n      <td>0.682889</td>\n      <td>0.021370</td>\n      <td>(0.6696437944150544, 0.6961348786190702)</td>\n      <td>0.254986</td>\n      <td>0.025921</td>\n      <td>...</td>\n      <td>1.148876</td>\n      <td>0.065224</td>\n      <td>(1.1084497942979241, 1.1893017272230977)</td>\n      <td>1.425536</td>\n      <td>0.130200</td>\n      <td>(1.3448370255274684, 1.5062350348675102)</td>\n      <td>525.0</td>\n      <td>64.0</td>\n      <td>9904.0</td>\n      <td>10365.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>39 rows × 36 columns</p>\n</div>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_tasks_results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "task_to_learner_results.to_csv('../data/contextualize_results/task_to_learner.csv', index=False)\n",
    "other_tasks_results.to_csv('../data/contextualize_results/other_tasks_with_learner.csv', index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}