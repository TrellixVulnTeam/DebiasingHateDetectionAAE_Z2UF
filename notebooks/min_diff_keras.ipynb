{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "min_diff_keras.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "pycharm-7db20ed5",
   "language": "python",
   "display_name": "PyCharm (DelayedFlights)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "moGQn-psFggi"
   },
   "source": [
    "##### Copyright 2020 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form",
    "id": "cUGG66UTFwJ-"
   },
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YpbnPF_MEv4h"
   },
   "source": [
    "# Model Remediation Case Study\n",
    "\n",
    "<div class=\"devsite-table-wrapper\"><table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td><a target=\"_blank\" href=\"https://tensorflow.org/responsible_ai/model_remediation/min_diff/tutorials/min_diff_keras\">\n",
    "  <img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "</td>\n",
    "<td>\n",
    "  <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/model-remediation/blob/master/docs/min_diff/tutorials/min_diff_keras.ipynb\">\n",
    "  <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Run in Google Colab</a>\n",
    "</td>\n",
    "<td>\n",
    "  <a target=\"_blank\" href=\"https://github.com/tensorflow/model-remediation/blob/master/docs/min_diff/tutorials/min_diff_keras.ipynb\">\n",
    "  <img width=32px src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">View source on GitHub</a>\n",
    "</td>\n",
    "<td>\n",
    "  <a target=\"_blank\" href=\"https://storage.googleapis.com/tensorflow_docs/model-remediation/docs/min_diff/tutorials/min_diff_keras.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "</td>\n",
    "</table></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yMcQGRPHnjP9"
   },
   "source": [
    "In this notebook, we’ll train a text classifier to identify written content that could be considered toxic or harmful, and apply MinDiff to remediate some fairness concerns. In our workflow, we will:\n",
    "1.   Evaluate our baseline model’s performance on text containing references to sensitive groups. \n",
    "2.   Improve performance on any underperforming groups by training with MinDiff. \n",
    "3.   Evaluate the new model’s performance on our chosen metric.\n",
    "\n",
    "Our purpose is to demonstrate usage of the MinDiff technique with a very minimal workflow, not to lay out a principled approach to fairness in machine learning. As such, our evaluation will only focus on one sensitive category and a single metric. We also don’t address potential shortcomings in the dataset, nor tune our configurations. In a production setting, you would want to approach each of these with rigor. For more information on evaluating for fairness, see [this guide](https://www.tensorflow.org/responsible_ai/fairness_indicators/guidance).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_FCDIaf8wsll"
   },
   "source": [
    "## Setup\n",
    "\n",
    "We begin by installing Fairness Indicators and TensorFlow Model Remediation.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form",
    "id": "WoA7i_6ShG6Y"
   },
   "source": [
    "#@title Installs\n",
    "!pip install --upgrade tensorflow-model-remediation\n",
    "!pip install --upgrade fairness-indicators\n",
    "!pip install --upgrade protobuf"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: tensorflow-model-remediation in c:\\users\\matan\\anaconda3\\lib\\site-packages (0.1.2)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow>=2.0.0 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from tensorflow-model-remediation) (2.3.1)\n",
      "Requirement already satisfied, skipping upgrade: six in c:\\users\\matan\\anaconda3\\lib\\site-packages (from tensorflow-model-remediation) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from tensorflow>=2.0.0->tensorflow-model-remediation) (0.11.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy<1.19.0,>=1.16.0 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from tensorflow>=2.0.0->tensorflow-model-remediation) (1.17.5)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from tensorflow>=2.0.0->tensorflow-model-remediation) (0.34.2)\n",
      "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.8 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from tensorflow>=2.0.0->tensorflow-model-remediation) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.4.0,>=2.3.0 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from tensorflow>=2.0.0->tensorflow-model-remediation) (2.3.0)\n",
      "Requirement already satisfied, skipping upgrade: gast==0.3.3 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from tensorflow>=2.0.0->tensorflow-model-remediation) (0.3.3)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard<3,>=2.3.0 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from tensorflow>=2.0.0->tensorflow-model-remediation) (2.4.0)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.9.2 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from tensorflow>=2.0.0->tensorflow-model-remediation) (3.12.3)\n",
      "Requirement already satisfied, skipping upgrade: astunparse==1.6.3 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from tensorflow>=2.0.0->tensorflow-model-remediation) (1.6.3)\n",
      "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from tensorflow>=2.0.0->tensorflow-model-remediation) (1.12.1)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from tensorflow>=2.0.0->tensorflow-model-remediation) (1.34.0)\n",
      "Requirement already satisfied, skipping upgrade: keras-preprocessing<1.2,>=1.1.1 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from tensorflow>=2.0.0->tensorflow-model-remediation) (1.1.2)\n",
      "Requirement already satisfied, skipping upgrade: h5py<2.11.0,>=2.10.0 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from tensorflow>=2.0.0->tensorflow-model-remediation) (2.10.0)\n",
      "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from tensorflow>=2.0.0->tensorflow-model-remediation) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from tensorflow>=2.0.0->tensorflow-model-remediation) (3.3.0)\n",
      "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.0.0->tensorflow-model-remediation) (1.23.0)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.0.0->tensorflow-model-remediation) (3.3.3)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.0.0->tensorflow-model-remediation) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.0.0->tensorflow-model-remediation) (2.25.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.0.0->tensorflow-model-remediation) (46.4.0.post20200518)\n",
      "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.0.0->tensorflow-model-remediation) (0.4.2)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.0.0->tensorflow-model-remediation) (1.7.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.0.0->tensorflow-model-remediation) (0.2.7)\n",
      "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.0.0->tensorflow-model-remediation) (4.1.0)\n",
      "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3.5\" in c:\\users\\matan\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.0.0->tensorflow-model-remediation) (4.0)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in c:\\users\\matan\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=2.0.0->tensorflow-model-remediation) (1.6.0)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=2.0.0->tensorflow-model-remediation) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.27,>=1.21.1 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=2.0.0->tensorflow-model-remediation) (1.25.8)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=2.0.0->tensorflow-model-remediation) (2020.12.5)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=2.0.0->tensorflow-model-remediation) (2.9)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=2.0.0->tensorflow-model-remediation) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.0.0->tensorflow-model-remediation) (0.4.8)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=2.0.0->tensorflow-model-remediation) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=2.0.0->tensorflow-model-remediation) (3.0.1)\n",
      "Requirement already up-to-date: fairness-indicators in c:\\users\\matan\\anaconda3\\lib\\site-packages (0.25.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-data-validation<0.26,>=0.25 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from fairness-indicators) (0.25.0)\n",
      "Requirement already satisfied, skipping upgrade: witwidget<2,>=1.4.4 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from fairness-indicators) (1.7.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow!=2.0.*,!=2.1.*,!=2.2.*,<3,>=1.15.2 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from fairness-indicators) (2.3.1)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-model-analysis<0.26,>=0.25 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from fairness-indicators) (0.25.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-transform<0.26,>=0.25 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from tensorflow-data-validation<0.26,>=0.25->fairness-indicators) (0.25.0)\n",
      "Requirement already satisfied, skipping upgrade: tfx-bsl<0.26,>=0.25 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from tensorflow-data-validation<0.26,>=0.25->fairness-indicators) (0.25.0)\n",
      "Requirement already satisfied, skipping upgrade: six<2,>=1.12 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from tensorflow-data-validation<0.26,>=0.25->fairness-indicators) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: pyarrow<0.18,>=0.17 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from tensorflow-data-validation<0.26,>=0.25->fairness-indicators) (0.17.1)\n",
      "Requirement already satisfied, skipping upgrade: pandas<2,>=1.0 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from tensorflow-data-validation<0.26,>=0.25->fairness-indicators) (1.1.5)\n",
      "Requirement already satisfied, skipping upgrade: numpy<2,>=1.16 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from tensorflow-data-validation<0.26,>=0.25->fairness-indicators) (1.17.5)\n",
      "Requirement already satisfied, skipping upgrade: joblib<0.15,>=0.12 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from tensorflow-data-validation<0.26,>=0.25->fairness-indicators) (0.13.2)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-metadata<0.26,>=0.25 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from tensorflow-data-validation<0.26,>=0.25->fairness-indicators) (0.25.0)\n",
      "Collecting absl-py<0.11,>=0.9\n",
      "  Downloading absl_py-0.10.0-py3-none-any.whl (127 kB)\n",
      "Requirement already satisfied, skipping upgrade: protobuf<4,>=3.9.2 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from tensorflow-data-validation<0.26,>=0.25->fairness-indicators) (3.12.3)\n",
      "Requirement already satisfied, skipping upgrade: apache-beam[gcp]<3,>=2.25 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from tensorflow-data-validation<0.26,>=0.25->fairness-indicators) (2.25.0)\n",
      "Requirement already satisfied, skipping upgrade: ipywidgets>=7.0.0 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from witwidget<2,>=1.4.4->fairness-indicators) (7.5.1)\n",
      "Requirement already satisfied, skipping upgrade: jupyter<2,>=1.0 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from witwidget<2,>=1.4.4->fairness-indicators) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: google-api-python-client>=1.7.8 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from witwidget<2,>=1.4.4->fairness-indicators) (1.12.8)\n",
      "Requirement already satisfied, skipping upgrade: oauth2client>=4.1.3 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from witwidget<2,>=1.4.4->fairness-indicators) (4.1.3)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,<3,>=1.15.2->fairness-indicators) (0.34.2)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,<3,>=1.15.2->fairness-indicators) (1.34.0)\n",
      "Requirement already satisfied, skipping upgrade: keras-preprocessing<1.2,>=1.1.1 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,<3,>=1.15.2->fairness-indicators) (1.1.2)\n",
      "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.8 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,<3,>=1.15.2->fairness-indicators) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,<3,>=1.15.2->fairness-indicators) (1.12.1)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard<3,>=2.3.0 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,<3,>=1.15.2->fairness-indicators) (2.4.0)\n",
      "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,<3,>=1.15.2->fairness-indicators) (3.3.0)\n",
      "Requirement already satisfied, skipping upgrade: astunparse==1.6.3 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,<3,>=1.15.2->fairness-indicators) (1.6.3)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.4.0,>=2.3.0 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,<3,>=1.15.2->fairness-indicators) (2.3.0)\n",
      "Requirement already satisfied, skipping upgrade: h5py<2.11.0,>=2.10.0 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,<3,>=1.15.2->fairness-indicators) (2.10.0)\n",
      "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,<3,>=1.15.2->fairness-indicators) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: gast==0.3.3 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,<3,>=1.15.2->fairness-indicators) (0.3.3)\n",
      "Requirement already satisfied, skipping upgrade: scipy<2,>=1.4.1 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from tensorflow-model-analysis<0.26,>=0.25->fairness-indicators) (1.5.4)\n",
      "Requirement already satisfied, skipping upgrade: ipython<8,>=7 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from tensorflow-model-analysis<0.26,>=0.25->fairness-indicators) (7.19.0)\n",
      "Requirement already satisfied, skipping upgrade: pydot<2,>=1.2 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from tensorflow-transform<0.26,>=0.25->tensorflow-data-validation<0.26,>=0.25->fairness-indicators) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-serving-api!=2.0.*,!=2.1.*,!=2.2.*,<3,>=1.15 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from tfx-bsl<0.26,>=0.25->tensorflow-data-validation<0.26,>=0.25->fairness-indicators) (2.3.0)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from pandas<2,>=1.0->tensorflow-data-validation<0.26,>=0.25->fairness-indicators) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from pandas<2,>=1.0->tensorflow-data-validation<0.26,>=0.25->fairness-indicators) (2020.1)\n",
      "Requirement already satisfied, skipping upgrade: googleapis-common-protos<2,>=1.52.0 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from tensorflow-metadata<0.26,>=0.25->tensorflow-data-validation<0.26,>=0.25->fairness-indicators) (1.52.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in c:\\users\\matan\\anaconda3\\lib\\site-packages (from protobuf<4,>=3.9.2->tensorflow-data-validation<0.26,>=0.25->fairness-indicators) (46.4.0.post20200518)\n",
      "Requirement already satisfied, skipping upgrade: dill<0.3.2,>=0.3.1.1 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from apache-beam[gcp]<3,>=2.25->tensorflow-data-validation<0.26,>=0.25->fairness-indicators) (0.3.1.1)\n",
      "Requirement already satisfied, skipping upgrade: avro-python3!=1.9.2,<1.10.0,>=1.8.1; python_version >= \"3.0\" in c:\\users\\matan\\anaconda3\\lib\\site-packages (from apache-beam[gcp]<3,>=2.25->tensorflow-data-validation<0.26,>=0.25->fairness-indicators) (1.9.2.1)\n",
      "Requirement already satisfied, skipping upgrade: httplib2<0.18.0,>=0.8 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from apache-beam[gcp]<3,>=2.25->tensorflow-data-validation<0.26,>=0.25->fairness-indicators) (0.17.4)\n",
      "Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.24.0 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from apache-beam[gcp]<3,>=2.25->tensorflow-data-validation<0.26,>=0.25->fairness-indicators) (2.25.0)\n",
      "Requirement already satisfied, skipping upgrade: future<1.0.0,>=0.18.2 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from apache-beam[gcp]<3,>=2.25->tensorflow-data-validation<0.26,>=0.25->fairness-indicators) (0.18.2)\n",
      "Requirement already satisfied, skipping upgrade: typing-extensions<3.8.0,>=3.7.0 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from apache-beam[gcp]<3,>=2.25->tensorflow-data-validation<0.26,>=0.25->fairness-indicators) (3.7.4.3)\n",
      "Requirement already satisfied, skipping upgrade: mock<3.0.0,>=1.0.1 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from apache-beam[gcp]<3,>=2.25->tensorflow-data-validation<0.26,>=0.25->fairness-indicators) (2.0.0)\n",
      "Requirement already satisfied, skipping upgrade: pymongo<4.0.0,>=3.8.0 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from apache-beam[gcp]<3,>=2.25->tensorflow-data-validation<0.26,>=0.25->fairness-indicators) (3.11.2)\n",
      "Requirement already satisfied, skipping upgrade: crcmod<2.0,>=1.7 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from apache-beam[gcp]<3,>=2.25->tensorflow-data-validation<0.26,>=0.25->fairness-indicators) (1.7)\n",
      "Requirement already satisfied, skipping upgrade: fastavro<2,>=0.21.4 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from apache-beam[gcp]<3,>=2.25->tensorflow-data-validation<0.26,>=0.25->fairness-indicators) (1.2.1)\n",
      "Requirement already satisfied, skipping upgrade: hdfs<3.0.0,>=2.1.0 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from apache-beam[gcp]<3,>=2.25->tensorflow-data-validation<0.26,>=0.25->fairness-indicators) (2.5.8)\n",
      "Requirement already satisfied, skipping upgrade: google-cloud-bigquery<2,>=1.6.0; extra == \"gcp\" in c:\\users\\matan\\anaconda3\\lib\\site-packages (from apache-beam[gcp]<3,>=2.25->tensorflow-data-validation<0.26,>=0.25->fairness-indicators) (1.28.0)\n",
      "Requirement already satisfied, skipping upgrade: google-cloud-build<3,>=2.0.0; python_version >= \"3.6\" and extra == \"gcp\" in c:\\users\\matan\\anaconda3\\lib\\site-packages (from apache-beam[gcp]<3,>=2.25->tensorflow-data-validation<0.26,>=0.25->fairness-indicators) (2.0.0)\n",
      "Requirement already satisfied, skipping upgrade: grpcio-gcp<1,>=0.2.2; extra == \"gcp\" in c:\\users\\matan\\anaconda3\\lib\\site-packages (from apache-beam[gcp]<3,>=2.25->tensorflow-data-validation<0.26,>=0.25->fairness-indicators) (0.2.2)\n",
      "Requirement already satisfied, skipping upgrade: google-cloud-spanner<2,>=1.13.0; extra == \"gcp\" in c:\\users\\matan\\anaconda3\\lib\\site-packages (from apache-beam[gcp]<3,>=2.25->tensorflow-data-validation<0.26,>=0.25->fairness-indicators) (1.19.1)\n",
      "Requirement already satisfied, skipping upgrade: google-cloud-videointelligence<2,>=1.8.0; extra == \"gcp\" in c:\\users\\matan\\anaconda3\\lib\\site-packages (from apache-beam[gcp]<3,>=2.25->tensorflow-data-validation<0.26,>=0.25->fairness-indicators) (1.16.1)\n",
      "Requirement already satisfied, skipping upgrade: google-apitools<0.5.32,>=0.5.31; extra == \"gcp\" in c:\\users\\matan\\anaconda3\\lib\\site-packages (from apache-beam[gcp]<3,>=2.25->tensorflow-data-validation<0.26,>=0.25->fairness-indicators) (0.5.31)\n",
      "Requirement already satisfied, skipping upgrade: google-cloud-pubsub<2,>=0.39.0; extra == \"gcp\" in c:\\users\\matan\\anaconda3\\lib\\site-packages (from apache-beam[gcp]<3,>=2.25->tensorflow-data-validation<0.26,>=0.25->fairness-indicators) (1.7.0)\n",
      "Requirement already satisfied, skipping upgrade: cachetools<5,>=3.1.0; extra == \"gcp\" in c:\\users\\matan\\anaconda3\\lib\\site-packages (from apache-beam[gcp]<3,>=2.25->tensorflow-data-validation<0.26,>=0.25->fairness-indicators) (4.1.0)\n",
      "Requirement already satisfied, skipping upgrade: google-cloud-core<2,>=0.28.1; extra == \"gcp\" in c:\\users\\matan\\anaconda3\\lib\\site-packages (from apache-beam[gcp]<3,>=2.25->tensorflow-data-validation<0.26,>=0.25->fairness-indicators) (1.4.4)\n",
      "Requirement already satisfied, skipping upgrade: google-cloud-language<2,>=1.3.0; extra == \"gcp\" in c:\\users\\matan\\anaconda3\\lib\\site-packages (from apache-beam[gcp]<3,>=2.25->tensorflow-data-validation<0.26,>=0.25->fairness-indicators) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: google-cloud-datastore<2,>=1.7.1; extra == \"gcp\" in c:\\users\\matan\\anaconda3\\lib\\site-packages (from apache-beam[gcp]<3,>=2.25->tensorflow-data-validation<0.26,>=0.25->fairness-indicators) (1.15.3)\n",
      "Requirement already satisfied, skipping upgrade: google-cloud-vision<2,>=0.38.0; extra == \"gcp\" in c:\\users\\matan\\anaconda3\\lib\\site-packages (from apache-beam[gcp]<3,>=2.25->tensorflow-data-validation<0.26,>=0.25->fairness-indicators) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: google-cloud-bigtable<2,>=0.31.1; extra == \"gcp\" in c:\\users\\matan\\anaconda3\\lib\\site-packages (from apache-beam[gcp]<3,>=2.25->tensorflow-data-validation<0.26,>=0.25->fairness-indicators) (1.6.1)\n",
      "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.18.0; extra == \"gcp\" in c:\\users\\matan\\anaconda3\\lib\\site-packages (from apache-beam[gcp]<3,>=2.25->tensorflow-data-validation<0.26,>=0.25->fairness-indicators) (1.23.0)\n",
      "Requirement already satisfied, skipping upgrade: google-cloud-dlp<2,>=0.12.0; extra == \"gcp\" in c:\\users\\matan\\anaconda3\\lib\\site-packages (from apache-beam[gcp]<3,>=2.25->tensorflow-data-validation<0.26,>=0.25->fairness-indicators) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: widgetsnbextension~=3.5.0 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from ipywidgets>=7.0.0->witwidget<2,>=1.4.4->fairness-indicators) (3.5.1)\n",
      "Requirement already satisfied, skipping upgrade: nbformat>=4.2.0 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from ipywidgets>=7.0.0->witwidget<2,>=1.4.4->fairness-indicators) (5.0.6)\n",
      "Requirement already satisfied, skipping upgrade: ipykernel>=4.5.1 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from ipywidgets>=7.0.0->witwidget<2,>=1.4.4->fairness-indicators) (5.1.4)\n",
      "Requirement already satisfied, skipping upgrade: traitlets>=4.3.1 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from ipywidgets>=7.0.0->witwidget<2,>=1.4.4->fairness-indicators) (4.3.3)\n",
      "Requirement already satisfied, skipping upgrade: qtconsole in c:\\users\\matan\\anaconda3\\lib\\site-packages (from jupyter<2,>=1.0->witwidget<2,>=1.4.4->fairness-indicators) (4.7.4)\n",
      "Requirement already satisfied, skipping upgrade: jupyter-console in c:\\users\\matan\\anaconda3\\lib\\site-packages (from jupyter<2,>=1.0->witwidget<2,>=1.4.4->fairness-indicators) (6.1.0)\n",
      "Requirement already satisfied, skipping upgrade: notebook in c:\\users\\matan\\anaconda3\\lib\\site-packages (from jupyter<2,>=1.0->witwidget<2,>=1.4.4->fairness-indicators) (6.0.3)\n",
      "Requirement already satisfied, skipping upgrade: nbconvert in c:\\users\\matan\\anaconda3\\lib\\site-packages (from jupyter<2,>=1.0->witwidget<2,>=1.4.4->fairness-indicators) (5.6.1)\n",
      "Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from google-api-python-client>=1.7.8->witwidget<2,>=1.4.4->fairness-indicators) (0.0.4)\n",
      "Requirement already satisfied, skipping upgrade: google-api-core<2dev,>=1.21.0 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from google-api-python-client>=1.7.8->witwidget<2,>=1.4.4->fairness-indicators) (1.23.0)\n",
      "Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from google-api-python-client>=1.7.8->witwidget<2,>=1.4.4->fairness-indicators) (3.0.1)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.7 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from oauth2client>=4.1.3->witwidget<2,>=1.4.4->fairness-indicators) (0.4.8)\n",
      "Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from oauth2client>=4.1.3->witwidget<2,>=1.4.4->fairness-indicators) (4.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.0.5 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from oauth2client>=4.1.3->witwidget<2,>=1.4.4->fairness-indicators) (0.2.7)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,<3,>=1.15.2->fairness-indicators) (1.7.0)\n",
      "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,<3,>=1.15.2->fairness-indicators) (0.4.2)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,<3,>=1.15.2->fairness-indicators) (3.3.3)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,<3,>=1.15.2->fairness-indicators) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: pygments in c:\\users\\matan\\anaconda3\\lib\\site-packages (from ipython<8,>=7->tensorflow-model-analysis<0.26,>=0.25->fairness-indicators) (2.6.1)\n",
      "Requirement already satisfied, skipping upgrade: colorama; sys_platform == \"win32\" in c:\\users\\matan\\anaconda3\\lib\\site-packages (from ipython<8,>=7->tensorflow-model-analysis<0.26,>=0.25->fairness-indicators) (0.4.3)\n",
      "Requirement already satisfied, skipping upgrade: pickleshare in c:\\users\\matan\\anaconda3\\lib\\site-packages (from ipython<8,>=7->tensorflow-model-analysis<0.26,>=0.25->fairness-indicators) (0.7.5)\n",
      "Requirement already satisfied, skipping upgrade: decorator in c:\\users\\matan\\anaconda3\\lib\\site-packages (from ipython<8,>=7->tensorflow-model-analysis<0.26,>=0.25->fairness-indicators) (4.4.2)\n",
      "Requirement already satisfied, skipping upgrade: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from ipython<8,>=7->tensorflow-model-analysis<0.26,>=0.25->fairness-indicators) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: backcall in c:\\users\\matan\\anaconda3\\lib\\site-packages (from ipython<8,>=7->tensorflow-model-analysis<0.26,>=0.25->fairness-indicators) (0.1.0)\n",
      "Requirement already satisfied, skipping upgrade: jedi>=0.10 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from ipython<8,>=7->tensorflow-model-analysis<0.26,>=0.25->fairness-indicators) (0.17.0)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing>=2.1.4 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from pydot<2,>=1.2->tensorflow-transform<0.26,>=0.25->tensorflow-data-validation<0.26,>=0.25->fairness-indicators) (2.4.7)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.25->tensorflow-data-validation<0.26,>=0.25->fairness-indicators) (2020.12.5)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.25->tensorflow-data-validation<0.26,>=0.25->fairness-indicators) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.27,>=1.21.1 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.25->tensorflow-data-validation<0.26,>=0.25->fairness-indicators) (1.25.8)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.25->tensorflow-data-validation<0.26,>=0.25->fairness-indicators) (2.9)\n",
      "Requirement already satisfied, skipping upgrade: pbr>=0.11 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from mock<3.0.0,>=1.0.1->apache-beam[gcp]<3,>=2.25->tensorflow-data-validation<0.26,>=0.25->fairness-indicators) (5.5.1)\n",
      "Requirement already satisfied, skipping upgrade: docopt in c:\\users\\matan\\anaconda3\\lib\\site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam[gcp]<3,>=2.25->tensorflow-data-validation<0.26,>=0.25->fairness-indicators) (0.6.2)\n",
      "Requirement already satisfied, skipping upgrade: google-resumable-media<2.0dev,>=0.6.0 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from google-cloud-bigquery<2,>=1.6.0; extra == \"gcp\"->apache-beam[gcp]<3,>=2.25->tensorflow-data-validation<0.26,>=0.25->fairness-indicators) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: libcst>=0.2.5 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from google-cloud-build<3,>=2.0.0; python_version >= \"3.6\" and extra == \"gcp\"->apache-beam[gcp]<3,>=2.25->tensorflow-data-validation<0.26,>=0.25->fairness-indicators) (0.3.15)\n",
      "Requirement already satisfied, skipping upgrade: proto-plus>=0.4.0 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from google-cloud-build<3,>=2.0.0; python_version >= \"3.6\" and extra == \"gcp\"->apache-beam[gcp]<3,>=2.25->tensorflow-data-validation<0.26,>=0.25->fairness-indicators) (1.13.0)\n",
      "Requirement already satisfied, skipping upgrade: grpc-google-iam-v1<0.13dev,>=0.12.3 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from google-cloud-spanner<2,>=1.13.0; extra == \"gcp\"->apache-beam[gcp]<3,>=2.25->tensorflow-data-validation<0.26,>=0.25->fairness-indicators) (0.12.3)\n",
      "Requirement already satisfied, skipping upgrade: fasteners>=0.14 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from google-apitools<0.5.32,>=0.5.31; extra == \"gcp\"->apache-beam[gcp]<3,>=2.25->tensorflow-data-validation<0.26,>=0.25->fairness-indicators) (0.15)\n",
      "Requirement already satisfied, skipping upgrade: ipython-genutils in c:\\users\\matan\\anaconda3\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->witwidget<2,>=1.4.4->fairness-indicators) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: jupyter-core in c:\\users\\matan\\anaconda3\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->witwidget<2,>=1.4.4->fairness-indicators) (4.6.3)\n",
      "Requirement already satisfied, skipping upgrade: jsonschema!=2.5.0,>=2.4 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->witwidget<2,>=1.4.4->fairness-indicators) (3.2.0)\n",
      "Requirement already satisfied, skipping upgrade: tornado>=4.2 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->witwidget<2,>=1.4.4->fairness-indicators) (6.0.4)\n",
      "Requirement already satisfied, skipping upgrade: jupyter-client in c:\\users\\matan\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->witwidget<2,>=1.4.4->fairness-indicators) (6.1.3)\n",
      "Requirement already satisfied, skipping upgrade: qtpy in c:\\users\\matan\\anaconda3\\lib\\site-packages (from qtconsole->jupyter<2,>=1.0->witwidget<2,>=1.4.4->fairness-indicators) (1.9.0)\n",
      "Requirement already satisfied, skipping upgrade: pyzmq>=17.1 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from qtconsole->jupyter<2,>=1.0->witwidget<2,>=1.4.4->fairness-indicators) (18.1.1)\n",
      "Requirement already satisfied, skipping upgrade: jinja2 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from notebook->jupyter<2,>=1.0->witwidget<2,>=1.4.4->fairness-indicators) (2.11.2)\n",
      "Requirement already satisfied, skipping upgrade: terminado>=0.8.1 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from notebook->jupyter<2,>=1.0->witwidget<2,>=1.4.4->fairness-indicators) (0.8.3)\n",
      "Requirement already satisfied, skipping upgrade: prometheus-client in c:\\users\\matan\\anaconda3\\lib\\site-packages (from notebook->jupyter<2,>=1.0->witwidget<2,>=1.4.4->fairness-indicators) (0.7.1)\n",
      "Requirement already satisfied, skipping upgrade: Send2Trash in c:\\users\\matan\\anaconda3\\lib\\site-packages (from notebook->jupyter<2,>=1.0->witwidget<2,>=1.4.4->fairness-indicators) (1.5.0)\n",
      "Requirement already satisfied, skipping upgrade: bleach in c:\\users\\matan\\anaconda3\\lib\\site-packages (from nbconvert->jupyter<2,>=1.0->witwidget<2,>=1.4.4->fairness-indicators) (3.1.4)\n",
      "Requirement already satisfied, skipping upgrade: testpath in c:\\users\\matan\\anaconda3\\lib\\site-packages (from nbconvert->jupyter<2,>=1.0->witwidget<2,>=1.4.4->fairness-indicators) (0.4.4)\n",
      "Requirement already satisfied, skipping upgrade: defusedxml in c:\\users\\matan\\anaconda3\\lib\\site-packages (from nbconvert->jupyter<2,>=1.0->witwidget<2,>=1.4.4->fairness-indicators) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: mistune<2,>=0.8.1 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from nbconvert->jupyter<2,>=1.0->witwidget<2,>=1.4.4->fairness-indicators) (0.8.4)\n",
      "Requirement already satisfied, skipping upgrade: entrypoints>=0.2.2 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from nbconvert->jupyter<2,>=1.0->witwidget<2,>=1.4.4->fairness-indicators) (0.3)\n",
      "Requirement already satisfied, skipping upgrade: pandocfilters>=1.4.1 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from nbconvert->jupyter<2,>=1.0->witwidget<2,>=1.4.4->fairness-indicators) (1.4.2)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,<3,>=1.15.2->fairness-indicators) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in c:\\users\\matan\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,<3,>=1.15.2->fairness-indicators) (1.6.0)\n",
      "Requirement already satisfied, skipping upgrade: wcwidth in c:\\users\\matan\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython<8,>=7->tensorflow-model-analysis<0.26,>=0.25->fairness-indicators) (0.1.9)\n",
      "Requirement already satisfied, skipping upgrade: parso>=0.7.0 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from jedi>=0.10->ipython<8,>=7->tensorflow-model-analysis<0.26,>=0.25->fairness-indicators) (0.7.0)\n",
      "Requirement already satisfied, skipping upgrade: google-crc32c<2.0dev,>=1.0; python_version >= \"3.5\" in c:\\users\\matan\\anaconda3\\lib\\site-packages (from google-resumable-media<2.0dev,>=0.6.0->google-cloud-bigquery<2,>=1.6.0; extra == \"gcp\"->apache-beam[gcp]<3,>=2.25->tensorflow-data-validation<0.26,>=0.25->fairness-indicators) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: pyyaml>=5.2 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from libcst>=0.2.5->google-cloud-build<3,>=2.0.0; python_version >= \"3.6\" and extra == \"gcp\"->apache-beam[gcp]<3,>=2.25->tensorflow-data-validation<0.26,>=0.25->fairness-indicators) (5.3.1)\n",
      "Requirement already satisfied, skipping upgrade: typing-inspect>=0.4.0 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from libcst>=0.2.5->google-cloud-build<3,>=2.0.0; python_version >= \"3.6\" and extra == \"gcp\"->apache-beam[gcp]<3,>=2.25->tensorflow-data-validation<0.26,>=0.25->fairness-indicators) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: monotonic>=0.1 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from fasteners>=0.14->google-apitools<0.5.32,>=0.5.31; extra == \"gcp\"->apache-beam[gcp]<3,>=2.25->tensorflow-data-validation<0.26,>=0.25->fairness-indicators) (1.5)\n",
      "Requirement already satisfied, skipping upgrade: pywin32>=1.0; sys_platform == \"win32\" in c:\\users\\matan\\anaconda3\\lib\\site-packages (from jupyter-core->nbformat>=4.2.0->ipywidgets>=7.0.0->witwidget<2,>=1.4.4->fairness-indicators) (227)\n",
      "Requirement already satisfied, skipping upgrade: pyrsistent>=0.14.0 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.0.0->witwidget<2,>=1.4.4->fairness-indicators) (0.16.0)\n",
      "Requirement already satisfied, skipping upgrade: attrs>=17.4.0 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.0.0->witwidget<2,>=1.4.4->fairness-indicators) (19.3.0)\n",
      "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from jinja2->notebook->jupyter<2,>=1.0->witwidget<2,>=1.4.4->fairness-indicators) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: webencodings in c:\\users\\matan\\anaconda3\\lib\\site-packages (from bleach->nbconvert->jupyter<2,>=1.0->witwidget<2,>=1.4.4->fairness-indicators) (0.5.1)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,<3,>=1.15.2->fairness-indicators) (3.0.1)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,<3,>=1.15.2->fairness-indicators) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: cffi>=1.0.0 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from google-crc32c<2.0dev,>=1.0; python_version >= \"3.5\"->google-resumable-media<2.0dev,>=0.6.0->google-cloud-bigquery<2,>=1.6.0; extra == \"gcp\"->apache-beam[gcp]<3,>=2.25->tensorflow-data-validation<0.26,>=0.25->fairness-indicators) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: mypy-extensions>=0.3.0 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from typing-inspect>=0.4.0->libcst>=0.2.5->google-cloud-build<3,>=2.0.0; python_version >= \"3.6\" and extra == \"gcp\"->apache-beam[gcp]<3,>=2.25->tensorflow-data-validation<0.26,>=0.25->fairness-indicators) (0.4.3)\n",
      "Requirement already satisfied, skipping upgrade: pycparser in c:\\users\\matan\\anaconda3\\lib\\site-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0; python_version >= \"3.5\"->google-resumable-media<2.0dev,>=0.6.0->google-cloud-bigquery<2,>=1.6.0; extra == \"gcp\"->apache-beam[gcp]<3,>=2.25->tensorflow-data-validation<0.26,>=0.25->fairness-indicators) (2.20)\n",
      "Installing collected packages: absl-py\n",
      "  Attempting uninstall: absl-py\n",
      "    Found existing installation: absl-py 0.11.0\n",
      "    Uninstalling absl-py-0.11.0:\n",
      "      Successfully uninstalled absl-py-0.11.0\n",
      "Successfully installed absl-py-0.10.0\n",
      "Collecting protobuf\n",
      "  Downloading protobuf-3.14.0-cp37-cp37m-win_amd64.whl (798 kB)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.9 in c:\\users\\matan\\anaconda3\\lib\\site-packages (from protobuf) (1.14.0)\n",
      "Installing collected packages: protobuf\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.12.3\n",
      "    Uninstalling protobuf-3.12.3:\n",
      "      Successfully uninstalled protobuf-3.12.3\n",
      "Successfully installed protobuf-3.14.0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SlyU3HZpob8i"
   },
   "source": [
    "Import all necessary components, including MinDiff and Fairness Indicators for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form",
    "id": "JYLW8UIsIMrE"
   },
   "source": [
    "#@title Imports\n",
    "import copy\n",
    "import os\n",
    "import requests\n",
    "import tempfile\n",
    "import urllib\n",
    "import zipfile\n",
    "\n",
    "import tensorflow_model_remediation.min_diff as md\n",
    "from google.protobuf import text_format\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "# import tensorflow_hub as hub\n",
    "# import tensorflow_model_analysis as tfma\n",
    "# import tensorflow_data_validation as tfdv\n",
    "# from tensorflow_model_analysis.addons.fairness.post_export_metrics import fairness_indicators\n",
    "# from tensorflow_model_analysis.addons.fairness.view import widget_view"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form",
    "id": "Zo3Dkbtsqx-e"
   },
   "source": [
    "#@title Import Util\n",
    "! curl -O https://raw.githubusercontent.com/tensorflow/model-remediation/master/tools/tutorials_utils/min_diff_keras_utils.py\n",
    "! python min_diff_keras_utils.py -h\n",
    "import min_diff_keras_utils"
   ],
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100  5100  100  5100    0     0   5100      0  0:00:01 --:--:--  0:00:01 12085\n",
      "2020-12-12 15:26:42.892243: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found\n",
      "2020-12-12 15:26:42.892290: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "Traceback (most recent call last):\n",
      "  File \"min_diff_keras_utils.py\", line 24, in <module>\n",
      "    import tensorflow_hub as hub\n",
      "ModuleNotFoundError: No module named 'tensorflow_hub'\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_hub'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-9-d7d7c680f23e>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mget_ipython\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msystem\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m' curl -O https://raw.githubusercontent.com/tensorflow/model-remediation/master/tools/tutorials_utils/min_diff_keras_utils.py'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mget_ipython\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msystem\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m' python min_diff_keras_utils.py -h'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m \u001B[1;32mimport\u001B[0m \u001B[0mmin_diff_keras_utils\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\OneDrive\\Documents\\OMSCS\\Thesis\\Code\\HateSpeech\\notebooks\\min_diff_keras_utils.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     22\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mpandas\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mtensorflow\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 24\u001B[1;33m \u001B[1;32mimport\u001B[0m \u001B[0mtensorflow_hub\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mhub\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     25\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mtensorflow_model_analysis\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mtfma\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     26\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mgoogle\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprotobuf\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mtext_format\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'tensorflow_hub'"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zPkyRv5_ozdC"
   },
   "source": [
    "We use a utility function to download the preprocessed data and prepare the labels to match the model’s output shape. The function also downloads the data as TFRecords to make later evaluation quicker. Alternatively, you may convert the Pandas DataFrame into TFRecords with any available utility conversion function.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-Hw5HdppwuBs"
   },
   "source": [
    "# We use a helper utility to preprocessed data for convenience and speed.\n",
    "data_train, data_validate, validate_tfrecord_file, labels_train, labels_validate = min_diff_keras_utils.download_and_process_civil_comments_data()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LGum4JXSo-Qu"
   },
   "source": [
    "We define a few useful constants.  We will train the model on the `’comment_text’` feature, with our target label as `’toxicity’`. Note that the batch size here is chosen arbitrarily, but in a production setting you would need to tune it for best performance."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Ular7EPMU_Y1"
   },
   "source": [
    "TEXT_FEATURE = 'comment_text'\n",
    "LABEL = 'toxicity'\n",
    "BATCH_SIZE = 512"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tyRduaSapFqt"
   },
   "source": [
    "Set random seeds. (Note that this does not fully stabilize results.)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "taGEqZGB_FWN"
   },
   "source": [
    "#@title Seeds\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D_r-uFyQpbkW"
   },
   "source": [
    "## Define and train the baseline model\n",
    "\n",
    "To reduce runtime, we use a pretrained model by default. It is a simple Keras sequential model with an initial embedding and convolution layers, outputting a toxicity prediction. If you prefer, you can change this and train from scratch using our utility function to create the model. (Note that since your environment is likely different from ours, you would need to customize the tuning and evaluation thresholds.)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KcRceFceKyE_"
   },
   "source": [
    "use_pretrained_model = True #@param {type:\"boolean\"}\n",
    "\n",
    "if use_pretrained_model:\n",
    "  URL = 'https://storage.googleapis.com/civil_comments_model/baseline_model.zip'\n",
    "  ZIPPATH = 'baseline_model.zip'\n",
    "  DIRPATH = '/tmp/baseline_model'\n",
    "  r = requests.get(URL, allow_redirects=True)\n",
    "  open(ZIPPATH, 'wb').write(r.content)\n",
    "\n",
    "  with zipfile.ZipFile(ZIPPATH, 'r') as zip_ref:\n",
    "    zip_ref.extractall('/')\n",
    "  baseline_model = tf.keras.models.load_model(\n",
    "      DIRPATH, custom_objects={'KerasLayer' : hub.KerasLayer})\n",
    "else:\n",
    "  optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "  loss = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "  baseline_model = min_diff_keras_utils.create_keras_sequential_model()\n",
    "  \n",
    "  baseline_model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "\n",
    "  baseline_model.fit(x=data_train[TEXT_FEATURE],\n",
    "                     y=labels_train,\n",
    "                     batch_size=BATCH_SIZE,\n",
    "                     epochs=20)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m8nsimBdp-lh"
   },
   "source": [
    "We save the model in order to evaluate using [Fairness Indicators](https://www.tensorflow.org/responsible_ai/fairness_indicators)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "DRLTXwDfN6a7"
   },
   "source": [
    "base_dir = tempfile.mkdtemp(prefix='saved_models')\n",
    "baseline_model_location = os.path.join(base_dir, 'model_export_baseline')\n",
    "baseline_model.save(baseline_model_location, save_format='tf')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ZRoxj-iqNqm"
   },
   "source": [
    "Next we run Fairness Indicators. As a reminder, we’re just going to perform sliced evaluation for comments referencing one category, *religious groups*. In a production environment, we recommend taking a thoughtful approach to determining which categories and metrics to evaluate across. \n",
    "\n",
    "To compute model performance, the utility function makes a few convenient choices for metrics, slices, and classifier thresholds."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4d6CZj2d-jrw"
   },
   "source": [
    "\n",
    "# We use a helper utility to hide the evaluation logic for readability.\n",
    "base_dir = tempfile.mkdtemp(prefix='eval') \n",
    "eval_subdir = 'eval_results_baseline'\n",
    "eval_result = min_diff_keras_utils.get_eval_results(\n",
    "    baseline_model_location, base_dir, eval_subdir, validate_tfrecord_file)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S1X0wtRXmHPX"
   },
   "source": [
    "###  Render Evaluation Results"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ynbJR3Qc-j0D"
   },
   "source": [
    "widget_view.render_fairness_indicator(eval_result)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o2cYxsxNqT_P"
   },
   "source": [
    "Let’s look at the evaluation results. Try selecting the metric false positive rate (FPR) with threshold 0.450. We can see that the model does not perform as well for some religious groups as for others, displaying a much higher FPR. Note the wide confidence intervals on some groups because they have too few examples. This makes it difficult to say with certainty that there is a significant difference in performance for these slices. We may want to collect more examples to address this issue. We can, however, attempt to apply MinDiff for the two groups that we are confident are underperforming.\n",
    "\n",
    "We’ve chosen to focus on FPR, because a higher FPR means that comments referencing these identity groups are more likely to be incorrectly flagged as toxic than other comments. This could lead to inequitable outcomes for users engaging in dialogue about religion, but note that disparities in other metrics can lead to other types of harm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CRG6SHR8ryMV"
   },
   "source": [
    "## Define and Train the MinDiff Model\n",
    "\n",
    "Now, we’ll try to improve the FPR for underperforming religious groups. We’ll attempt to do so using [MinDiff](https://arxiv.org/abs/1910.11779), a remediation technique that seeks to balance error rates across slices of your data by penalizing disparities in performance during training. When we apply MinDiff, model performance may degrade slightly on other slices. As such, our goals with MinDiff will be:\n",
    "*   Improved performance for underperforming groups\n",
    "*   Limited degradation for other groups and overall performance\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "opFCpJjadf7g"
   },
   "source": [
    "### Prepare your data\n",
    "\n",
    "To use MinDiff, we create two additional data splits:\n",
    "* A split for non-toxic examples referencing minority groups: In our case, this will include comments with references to our underperforming identity terms.  We don’t include some of the groups because there are too few examples, leading to higher uncertainty with wide confidence interval ranges.\n",
    "* A split for non-toxic examples referencing the majority group.\n",
    "\n",
    "It’s important to have sufficient examples belonging to the underperforming classes. Based on your model architecture, data distribution, and MinDiff configuration, the amount of data needed can vary significantly. In past applications, we have seen MinDiff work well with 5,000 examples in each data split.\n",
    "\n",
    "In our case, the groups in the minority splits have example quantities of 9,688 and 3,906. Note the class imbalances in the dataset; in practice, this could be cause for concern, but we won’t seek to address them in this notebook since our intention is just to demonstrate MinDiff.  \n",
    "\n",
    "We select only negative examples for these groups, so that MinDiff can optimize on getting these examples right. It may seem counterintuitive to carve out sets of ground truth *negative* examples if we’re primarily concerned with disparities in *false positive rate*, but remember that a false positive prediction is a ground truth negative example that’s incorrectly classified as positive, which is the issue we’re trying to address."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1QilngDumRfI"
   },
   "source": [
    "#### Create MinDiff DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jj4dychpyrqM"
   },
   "source": [
    "# Create masks for the sensitive and nonsensitive groups\n",
    "minority_mask = data_train.religion.apply(\n",
    "    lambda x: any(religion in x for religion in ('jewish', 'muslim')))\n",
    "majority_mask = data_train.religion.apply(lambda x: x == \"['christian']\")\n",
    "\n",
    "# Select nontoxic examples, so MinDiff will be able to reduce sensitive FP rate.\n",
    "true_negative_mask = data_train['toxicity'] == 0\n",
    "\n",
    "data_train_main = copy.copy(data_train)\n",
    "data_train_sensitive = data_train[minority_mask & true_negative_mask]\n",
    "data_train_nonsensitive = data_train[majority_mask & true_negative_mask]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3lR_w3LHt6QK"
   },
   "source": [
    "We also need to convert our Pandas DataFrames into Tensorflow Datasets for MinDiff input.  Note that unlike the Keras model API for Pandas DataFrames, using Datasets means that we need to provide the model’s input features and labels together in one Dataset. Here we provide the `'comment_text'` as an input feature and reshape the label to match the model's expected output. \n",
    "\n",
    "We batch the Dataset at this stage, too, since MinDiff requires batched Datasets.  Note that we tune the batch size selection the same way it is tuned for the baseline model, taking into account training speed and hardware considerations while balancing with model performance. Here we have chosen the same batch size for all three datasets but this is not a requirement, although it’s good practice to have the two MinDiff batch sizes be equivalent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yA4Kw9tsmopa"
   },
   "source": [
    "#### Create MinDiff Datasets"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "C0DkFMTOuIQT"
   },
   "source": [
    "# Convert the pandas DataFrames to Datasets.\n",
    "dataset_train_main = tf.data.Dataset.from_tensor_slices(\n",
    "    (data_train_main['comment_text'].values, \n",
    "     data_train_main.pop(LABEL).values.reshape(-1,1) * 1.0)).batch(BATCH_SIZE)\n",
    "dataset_train_sensitive = tf.data.Dataset.from_tensor_slices(\n",
    "    (data_train_sensitive['comment_text'].values, \n",
    "     data_train_sensitive.pop(LABEL).values.reshape(-1,1) * 1.0)).batch(BATCH_SIZE)\n",
    "dataset_train_nonsensitive = tf.data.Dataset.from_tensor_slices(\n",
    "    (data_train_nonsensitive['comment_text'].values, \n",
    "     data_train_nonsensitive.pop(LABEL).values.reshape(-1,1) * 1.0)).batch(BATCH_SIZE)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XRGvjZ8VuBvz"
   },
   "source": [
    "### Train and evaluate the model\n",
    "\n",
    "To train with MinDiff, simply take the original model and wrap it in a MinDiffModel with a corresponding `loss` and `loss_weight`.  We are using 1.5 as the default `loss_weight`, but this is a parameter that needs to be tuned for your use case, since it depends on your model and product requirements.  You can experiment with changing the value to see how it impacts the model, noting that increasing it pushes the performance of the minority and majority groups closer together but may come with more pronounced tradeoffs.\n",
    "\n",
    "Then we compile the model normally (using the regular non-MinDiff loss) and fit to train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eP_eTUpYm6U-"
   },
   "source": [
    "#### Train MinDiffModel"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xutVGl9fyikP"
   },
   "source": [
    "use_pretrained_model = True #@param {type:\"boolean\"}\n",
    "\n",
    "base_dir = tempfile.mkdtemp(prefix='saved_models')\n",
    "min_diff_model_location = os.path.join(base_dir, 'model_export_min_diff')\n",
    "\n",
    "if use_pretrained_model:\n",
    "  MIN_DIFF_URL = 'https://storage.googleapis.com/civil_comments_model/min_diff_model.zip'\n",
    "  ZIPPATH = 'min_diff_model.zip'\n",
    "  DIRPATH = '/tmp/min_diff_model'\n",
    "  r = requests.get(MIN_DIFF_URL, allow_redirects=True)\n",
    "  open(ZIPPATH, 'wb').write(r.content)\n",
    "\n",
    "  with zipfile.ZipFile(ZIPPATH, 'r') as zip_ref:\n",
    "    zip_ref.extractall('/')\n",
    "  min_diff_model = tf.keras.models.load_model(\n",
    "      DIRPATH, custom_objects={'KerasLayer' : hub.KerasLayer})\n",
    "  \n",
    "  min_diff_model.save(min_diff_model_location, save_format='tf')\n",
    "\n",
    "else:\n",
    "  min_diff_weight = 1.5 #@param {type:\"number\"}\n",
    "\n",
    "  # Create the dataset that will be passed to the MinDiffModel during training.\n",
    "  dataset = md.keras.utils.input_utils.pack_min_diff_data(\n",
    "      dataset_train_main, dataset_train_sensitive, dataset_train_nonsensitive)\n",
    "\n",
    "  # Create the original model.\n",
    "  original_model = min_diff_keras_utils.create_keras_sequential_model()\n",
    "  \n",
    "  # Wrap the original model in a MinDiffModel, passing in one of the MinDiff\n",
    "  # losses and using the set loss_weight.\n",
    "  min_diff_loss = md.losses.MMDLoss()\n",
    "  min_diff_model = md.keras.MinDiffModel(original_model,\n",
    "                                         min_diff_loss,\n",
    "                                         min_diff_weight)\n",
    "\n",
    "  # Compile the model normally after wrapping the original model.  Note that\n",
    "  # this means we use the baseline's model's loss here.\n",
    "  optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "  loss = tf.keras.losses.BinaryCrossentropy()\n",
    "  min_diff_model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "\n",
    "  min_diff_model.fit(dataset, epochs=20)\n",
    "\n",
    "  min_diff_model.save_original_model(min_diff_model_location, save_format='tf')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "doJhbIKVwQdp"
   },
   "source": [
    "Next we evaluate the results.  "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0CBdOQCH5IR6"
   },
   "source": [
    "min_diff_eval_subdir = 'eval_results_min_diff'\n",
    "min_diff_eval_result = min_diff_keras_utils.get_eval_results(min_diff_model_location,\n",
    "                                                            base_dir,\n",
    "                                                            min_diff_eval_subdir,\n",
    "                                                            validate_tfrecord_file,\n",
    "                                                            slice_selection='religion')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JObiq-mVwUzL"
   },
   "source": [
    "To ensure we evaluate a new model correctly, we need to select a threshold the same way that we would the baseline model. In a production setting, this would mean ensuring that evaluation metrics meet launch standards. In our case, we will pick the threshold that results in a similar overall FPR to the baseline model. This threshold may be different from the one you selected for the baseline model.  Try selecting false positive rate with threshold 0.400.  (Note that the subgroups with very low quantity examples have very wide confidence range intervals and don’t have predictable results.)   "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "A3_PEjYBO3Dq"
   },
   "source": [
    "widget_view.render_fairness_indicator(min_diff_eval_result)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sVRurkbZwYMj"
   },
   "source": [
    "Reviewing these results, you may notice that the FPRs for our target groups have improved. The gap between our lowest performing group and the majority group has improved from .024 to .006. Given the improvements we’ve observed and the continued strong performance for the majority group, we’ve satisfied both of our goals. Depending on the product, further improvements may be necessary, but this approach has gotten our model one step closer to performing equitably for all users."
   ]
  }
 ]
}